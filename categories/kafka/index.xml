<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Kafka on HoCode</title>
        <link>https://hollisho.github.io/categories/kafka/</link>
        <description>Recent content in Kafka on HoCode</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Hollis Ho</copyright>
        <lastBuildDate>Wed, 10 Jan 2024 11:34:49 +0800</lastBuildDate><atom:link href="https://hollisho.github.io/categories/kafka/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Kafka知识整理</title>
        <link>https://hollisho.github.io/p/kafka%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</link>
        <pubDate>Wed, 10 Jan 2024 11:34:49 +0800</pubDate>
        
        <guid>https://hollisho.github.io/p/kafka%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</guid>
        <description>&lt;h2 id=&#34;kafka-简介&#34;&gt;Kafka 简介
&lt;/h2&gt;&lt;p&gt;Kafka 是一个分布式的流处理平台，最初由 LinkedIn 开发，后来成为 Apache 项目。它具有高吞吐量、可靠性和可扩展性的特点，被广泛应用于日志收集、消息系统、活动追踪、流式处理等场景。&lt;/p&gt;
&lt;h2 id=&#34;kafka-架构设计&#34;&gt;Kafka 架构设计
&lt;/h2&gt;&lt;p&gt;Kafka 的核心架构包含以下几个关键组件：&lt;/p&gt;
&lt;h3 id=&#34;broker&#34;&gt;Broker
&lt;/h3&gt;&lt;p&gt;Broker 是 Kafka 集群中的服务器节点，负责接收和处理客户端请求，存储消息数据。每个 Broker 都有一个唯一的 ID，可以独立运行。&lt;/p&gt;
&lt;h3 id=&#34;producer&#34;&gt;Producer
&lt;/h3&gt;&lt;p&gt;Producer 是消息生产者，负责将消息发送到 Kafka 集群中的特定 Topic。Producer 可以选择同步或异步的方式发送消息。&lt;/p&gt;
&lt;h3 id=&#34;consumer&#34;&gt;Consumer
&lt;/h3&gt;&lt;p&gt;Consumer 是消息消费者，负责从 Kafka 集群中订阅并消费消息。Consumer 可以单独消费，也可以组成 Consumer Group 共同消费。&lt;/p&gt;
&lt;h3 id=&#34;topic&#34;&gt;Topic
&lt;/h3&gt;&lt;p&gt;Topic 是消息的逻辑分类，每个 Topic 可以有多个 Partition。Producer 发送消息到特定的 Topic，Consumer 从特定的 Topic 消费消息。&lt;/p&gt;
&lt;h3 id=&#34;partition&#34;&gt;Partition
&lt;/h3&gt;&lt;p&gt;Partition 是 Topic 的物理分区，每个 Partition 是一个有序的、不可变的消息序列。Partition 的引入使得 Kafka 可以实现水平扩展和并行处理。&lt;/p&gt;
&lt;h3 id=&#34;segment&#34;&gt;Segment
&lt;/h3&gt;&lt;p&gt;Segment 是 Partition 的物理存储单元，每个 Partition 由多个 Segment 组成。当 Segment 达到一定大小或时间阈值时，会创建新的 Segment。&lt;/p&gt;
&lt;h3 id=&#34;log&#34;&gt;Log
&lt;/h3&gt;&lt;p&gt;Log 是 Kafka 中最基本的数据存储单元，每个 Partition 对应一个 Log，Log 由多个 Segment 文件组成。&lt;/p&gt;
&lt;h3 id=&#34;zookeeper&#34;&gt;ZooKeeper
&lt;/h3&gt;&lt;p&gt;ZooKeeper 用于管理和协调 Kafka 集群，存储元数据信息，如 Broker 节点、Topic 配置、消费者偏移量等。（注：新版本 Kafka 正在逐步减少对 ZooKeeper 的依赖）&lt;/p&gt;
&lt;h2 id=&#34;kafka-副本同步方式&#34;&gt;Kafka 副本同步方式
&lt;/h2&gt;&lt;p&gt;Kafka 提供了三种不同的副本同步方式，通过 &lt;code&gt;acks&lt;/code&gt; 参数控制：&lt;/p&gt;
&lt;h3 id=&#34;1-ack0-半同步复制&#34;&gt;1. ack=0 (半同步复制)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Producer 发送消息后不等待任何确认&lt;/li&gt;
&lt;li&gt;最高的吞吐量，但无法保证消息已被接收&lt;/li&gt;
&lt;li&gt;可能导致消息丢失&lt;/li&gt;
&lt;li&gt;适用于对数据一致性要求不高的场景，如日志收集&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-ack1-异步复制&#34;&gt;2. ack=1 (异步复制)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Producer 发送消息后，等待 Leader 副本确认&lt;/li&gt;
&lt;li&gt;不等待 Follower 副本同步完成&lt;/li&gt;
&lt;li&gt;在 Leader 崩溃时可能丢失数据&lt;/li&gt;
&lt;li&gt;吞吐量和可靠性的折中方案&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-ackall-1-同步复制&#34;&gt;3. ack=all/-1 (同步复制)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Producer 发送消息后，等待所有 ISR 中的副本确认&lt;/li&gt;
&lt;li&gt;最高的可靠性，但吞吐量最低&lt;/li&gt;
&lt;li&gt;只要有一个 ISR 中的副本存活，就不会丢失数据&lt;/li&gt;
&lt;li&gt;适用于对数据一致性要求高的场景，如金融交易&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;isr-机制-in-sync-replicas&#34;&gt;ISR 机制 (In-Sync Replicas)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;ISR 是与 Leader 保持同步的副本集合&lt;/li&gt;
&lt;li&gt;AR (Assigned Replicas) = ISR (In-Sync Replicas) + OSR (Out-of-Sync Replicas)&lt;/li&gt;
&lt;li&gt;副本滞后超过 &lt;code&gt;replica.lag.time.max.ms&lt;/code&gt; 会被踢出 ISR&lt;/li&gt;
&lt;li&gt;当副本重新追上 Leader 时，会被重新加入 ISR&lt;/li&gt;
&lt;li&gt;ISR 机制是 Kafka 实现高可用和数据一致性的核心&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-消息发送流程&#34;&gt;Kafka 消息发送流程
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Producer 创建 ProducerRecord，指定 Topic 和消息内容&lt;/li&gt;
&lt;li&gt;消息经过序列化器、分区器处理&lt;/li&gt;
&lt;li&gt;分区器根据 Key 或轮询方式选择目标 Partition&lt;/li&gt;
&lt;li&gt;消息被添加到内存中的批次 (Batch)&lt;/li&gt;
&lt;li&gt;Sender 线程定期将批次发送到对应的 Broker&lt;/li&gt;
&lt;li&gt;Broker 接收消息并写入对应 Partition 的 Leader 副本&lt;/li&gt;
&lt;li&gt;根据 acks 配置，等待副本同步完成&lt;/li&gt;
&lt;li&gt;返回响应给 Producer&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;kafka-消息存储流程&#34;&gt;Kafka 消息存储流程
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Broker 接收到消息后，将其追加到对应 Partition 的当前活跃 Segment 中&lt;/li&gt;
&lt;li&gt;消息以追加写的方式写入磁盘，提高写入效率&lt;/li&gt;
&lt;li&gt;消息按照 Offset 顺序存储，每条消息有唯一的 Offset&lt;/li&gt;
&lt;li&gt;当 Segment 达到配置的大小或时间阈值，创建新的 Segment&lt;/li&gt;
&lt;li&gt;旧的 Segment 会在配置的保留时间后被删除或压缩&lt;/li&gt;
&lt;li&gt;Kafka 使用页缓存和零拷贝技术优化 I/O 性能&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;kafka-消息消费流程&#34;&gt;Kafka 消息消费流程
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Consumer 向 Coordinator 发送 JoinGroup 请求加入消费组&lt;/li&gt;
&lt;li&gt;Coordinator 选择一个 Consumer 作为 Leader，进行分区分配&lt;/li&gt;
&lt;li&gt;分配结果通过 SyncGroup 请求同步给所有 Consumer&lt;/li&gt;
&lt;li&gt;Consumer 向对应的 Broker 发送 Fetch 请求获取消息&lt;/li&gt;
&lt;li&gt;Broker 返回消息给 Consumer&lt;/li&gt;
&lt;li&gt;Consumer 处理消息并定期提交消费位移 (Offset)&lt;/li&gt;
&lt;li&gt;位移提交可以是自动的或手动的，保存在内部 Topic &lt;code&gt;__consumer_offsets&lt;/code&gt; 中&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;主从同步&#34;&gt;主从同步
&lt;/h2&gt;&lt;p&gt;Kafka 的主从同步基于 Leader-Follower 模型：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个 Partition 有一个 Leader 和多个 Follower&lt;/li&gt;
&lt;li&gt;所有读写请求都由 Leader 处理&lt;/li&gt;
&lt;li&gt;Follower 通过 Fetch 请求从 Leader 拉取消息&lt;/li&gt;
&lt;li&gt;HW (High Watermark) 表示所有 ISR 副本都已复制的位置&lt;/li&gt;
&lt;li&gt;LEO (Log End Offset) 表示每个副本的日志末端位置&lt;/li&gt;
&lt;li&gt;消费者只能消费到 HW 位置的消息，保证数据一致性&lt;/li&gt;
&lt;li&gt;当 Leader 失效时，从 ISR 中选举新的 Leader&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;高可用&#34;&gt;高可用
&lt;/h2&gt;&lt;p&gt;Kafka 通过以下机制实现高可用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;多副本机制&lt;/strong&gt;：每个 Partition 可以配置多个副本，分布在不同的 Broker 上&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leader 选举&lt;/strong&gt;：当 Leader 失效时，Controller 会从 ISR 中选择一个 Follower 成为新的 Leader&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Controller 选举&lt;/strong&gt;：集群中的一个 Broker 会被选为 Controller，负责分区分配和故障转移&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rebalance 机制&lt;/strong&gt;：当 Consumer 加入或离开消费组时，会触发 Rebalance，重新分配分区&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自动平衡&lt;/strong&gt;：Kafka 支持自动平衡 Leader 分区，避免单个 Broker 负载过高&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;消息顺序&#34;&gt;消息顺序
&lt;/h2&gt;&lt;p&gt;Kafka 对消息顺序的保证：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单个 Partition 内的消息是有序的&lt;/li&gt;
&lt;li&gt;不同 Partition 之间的消息无法保证顺序&lt;/li&gt;
&lt;li&gt;如果需要全局顺序，可以使用只有一个 Partition 的 Topic&lt;/li&gt;
&lt;li&gt;如果需要按 Key 顺序，可以确保相同 Key 的消息路由到同一个 Partition&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;消息重复&#34;&gt;消息重复
&lt;/h2&gt;&lt;p&gt;消息重复的原因和处理：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;原因&lt;/strong&gt;：网络问题、Broker 崩溃、Consumer 崩溃等导致重试或重新消费&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Producer 端&lt;/strong&gt;：启用幂等性 (&lt;code&gt;enable.idempotence=true&lt;/code&gt;) 和事务功能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consumer 端&lt;/strong&gt;：实现幂等消费，如使用唯一标识、状态检查、分布式锁等&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最佳实践&lt;/strong&gt;：设计业务逻辑时考虑幂等性，确保多次处理同一消息不会产生副作用&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;消息丢失&#34;&gt;消息丢失
&lt;/h2&gt;&lt;p&gt;消息丢失的场景和防止措施：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Producer 端&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;acks=all&lt;/code&gt; 确保所有 ISR 副本都收到消息&lt;/li&gt;
&lt;li&gt;启用重试机制 (&lt;code&gt;retries&lt;/code&gt; 参数)&lt;/li&gt;
&lt;li&gt;使用回调机制确认消息发送结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Broker 端&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;配置足够的副本数 (&lt;code&gt;replication.factor&amp;gt;=3&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;配置最小 ISR 数量 (&lt;code&gt;min.insync.replicas&amp;gt;=2&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;合理配置刷盘策略 (&lt;code&gt;log.flush.*&lt;/code&gt; 参数)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Consumer 端&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;手动提交位移，确保消息处理成功后再提交&lt;/li&gt;
&lt;li&gt;使用事务确保消息处理和位移提交的原子性&lt;/li&gt;
&lt;li&gt;避免长时间处理单条消息，防止会话超时&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;消息积压&#34;&gt;消息积压
&lt;/h2&gt;&lt;p&gt;消息积压的原因和解决方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;原因&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consumer 处理能力不足&lt;/li&gt;
&lt;li&gt;突发流量高峰&lt;/li&gt;
&lt;li&gt;Consumer 异常或宕机&lt;/li&gt;
&lt;li&gt;网络问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;增加 Consumer 实例和 Partition 数量&lt;/li&gt;
&lt;li&gt;优化 Consumer 处理逻辑，提高处理效率&lt;/li&gt;
&lt;li&gt;实现背压机制，控制生产速度&lt;/li&gt;
&lt;li&gt;使用更高性能的硬件&lt;/li&gt;
&lt;li&gt;临时将消息转储到其他存储，离线处理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;消息延迟&#34;&gt;消息延迟
&lt;/h2&gt;&lt;p&gt;Kafka 中的延迟消息实现：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Kafka 原生不支持延迟消息，但可以通过以下方式实现：
&lt;ul&gt;
&lt;li&gt;使用定时任务扫描特定 Topic&lt;/li&gt;
&lt;li&gt;使用时间轮算法在应用层实现&lt;/li&gt;
&lt;li&gt;创建多个 Topic 代表不同的延迟级别&lt;/li&gt;
&lt;li&gt;使用外部组件如 Apache Pulsar 或 RocketMQ 的延迟功能&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;零拷贝&#34;&gt;零拷贝
&lt;/h2&gt;&lt;p&gt;Kafka 使用零拷贝技术提高性能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;传统 I/O 模型&lt;/strong&gt;：数据在磁盘、内核空间、用户空间和网络之间多次拷贝&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;零拷贝技术&lt;/strong&gt;：利用 &lt;code&gt;sendfile()&lt;/code&gt; 系统调用，直接从磁盘到网络接口传输数据&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;减少数据拷贝次数&lt;/li&gt;
&lt;li&gt;减少上下文切换&lt;/li&gt;
&lt;li&gt;降低 CPU 使用率&lt;/li&gt;
&lt;li&gt;提高吞吐量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用场景&lt;/strong&gt;：Kafka 的日志文件传输、Consumer 消费消息&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;kafka-调优&#34;&gt;Kafka 调优
&lt;/h2&gt;&lt;h3 id=&#34;broker-调优&#34;&gt;Broker 调优
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;合理设置 &lt;code&gt;num.network.threads&lt;/code&gt; 和 &lt;code&gt;num.io.threads&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;优化 JVM 参数，如堆大小、GC 策略&lt;/li&gt;
&lt;li&gt;配置适当的 &lt;code&gt;log.retention.hours&lt;/code&gt; 和 &lt;code&gt;log.segment.bytes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;使用 RAID 10 磁盘阵列提高 I/O 性能&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;producer-调优&#34;&gt;Producer 调优
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;增大 &lt;code&gt;batch.size&lt;/code&gt; 和 &lt;code&gt;linger.ms&lt;/code&gt; 提高批量发送效率&lt;/li&gt;
&lt;li&gt;配置合适的 &lt;code&gt;buffer.memory&lt;/code&gt; 避免内存溢出&lt;/li&gt;
&lt;li&gt;根据场景选择合适的 &lt;code&gt;compression.type&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;调整 &lt;code&gt;max.in.flight.requests.per.connection&lt;/code&gt; 平衡吞吐量和顺序性&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;consumer-调优&#34;&gt;Consumer 调优
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;合理设置 &lt;code&gt;fetch.min.bytes&lt;/code&gt; 和 &lt;code&gt;fetch.max.wait.ms&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;优化 &lt;code&gt;max.poll.records&lt;/code&gt; 控制单次拉取的消息数量&lt;/li&gt;
&lt;li&gt;调整 &lt;code&gt;max.poll.interval.ms&lt;/code&gt; 避免消费者被踢出消费组&lt;/li&gt;
&lt;li&gt;实现并行处理提高消费效率&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-存储结构详解&#34;&gt;Kafka 存储结构详解
&lt;/h2&gt;&lt;p&gt;Kafka 的存储结构是其高性能的关键因素之一，它采用了分层的存储设计，从上到下依次为：Topic、Partition、Segment、Index 和 Log。&lt;/p&gt;
&lt;h3 id=&#34;topic-与-partition&#34;&gt;Topic 与 Partition
&lt;/h3&gt;&lt;p&gt;Topic 是消息的逻辑分类，而 Partition 是 Topic 的物理分区。每个 Topic 可以有多个 Partition，这些 Partition 分布在不同的 Broker 上，实现了数据的分布式存储和并行处理。&lt;/p&gt;
&lt;p&gt;Partition 的数量决定了 Topic 的并行度，增加 Partition 数量可以提高吞吐量，但也会增加系统开销和复杂性。Partition 的数量一旦设定，通常不建议减少，因为这可能导致数据丢失。&lt;/p&gt;
&lt;h3 id=&#34;segment-文件&#34;&gt;Segment 文件
&lt;/h3&gt;&lt;p&gt;每个 Partition 由多个 Segment 文件组成，Segment 是 Kafka 存储的基本单位。当 Segment 达到一定大小（默认 1GB）或时间阈值时，会创建新的 Segment。&lt;/p&gt;
&lt;p&gt;Segment 文件命名规则为：&lt;code&gt;[baseOffset].[index|log|timeindex]&lt;/code&gt;，其中 &lt;code&gt;baseOffset&lt;/code&gt; 是该 Segment 中第一条消息的 Offset。&lt;/p&gt;
&lt;p&gt;每个 Segment 包含以下文件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.log&lt;/code&gt; 文件：存储实际的消息数据&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.index&lt;/code&gt; 文件：存储消息的物理位置索引&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.timeindex&lt;/code&gt; 文件：存储时间戳索引（Kafka 0.10.0 版本后引入）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;索引机制&#34;&gt;索引机制
&lt;/h3&gt;&lt;p&gt;Kafka 使用稀疏索引来提高查找效率。索引文件中并不是每条消息都有索引项，而是每隔一定字节数（默认 4KB）的消息才会创建一个索引项。&lt;/p&gt;
&lt;p&gt;索引项包含两个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;相对 Offset：消息的 Offset 相对于 Segment 基准 Offset 的值&lt;/li&gt;
&lt;li&gt;物理位置：消息在 &lt;code&gt;.log&lt;/code&gt; 文件中的物理位置（字节偏移量）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当需要查找特定 Offset 的消息时，Kafka 首先找到该 Offset 所在的 Segment，然后在索引文件中找到小于等于目标 Offset 的最大索引项，从该位置开始顺序扫描 &lt;code&gt;.log&lt;/code&gt; 文件，直到找到目标消息。&lt;/p&gt;
&lt;h3 id=&#34;日志清理&#34;&gt;日志清理
&lt;/h3&gt;&lt;p&gt;Kafka 提供了两种日志清理策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;基于时间的删除&lt;/strong&gt;：通过 &lt;code&gt;log.retention.hours&lt;/code&gt; 配置，删除超过保留时间的旧 Segment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于大小的删除&lt;/strong&gt;：通过 &lt;code&gt;log.retention.bytes&lt;/code&gt; 配置，当 Partition 大小超过阈值时，删除最旧的 Segment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;日志压缩&lt;/strong&gt;：通过 &lt;code&gt;log.cleanup.policy=compact&lt;/code&gt; 配置，保留每个 Key 的最新值，删除旧值&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;日志压缩特别适用于需要保留最新状态的场景，如配置更新、状态变更等。&lt;/p&gt;
&lt;h3 id=&#34;文件系统与页缓存&#34;&gt;文件系统与页缓存
&lt;/h3&gt;&lt;p&gt;Kafka 直接使用文件系统存储数据，而不是使用数据库。它充分利用操作系统的页缓存（Page Cache）来提高 I/O 性能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;写入操作：追加写入文件系统，由操作系统负责刷盘&lt;/li&gt;
&lt;li&gt;读取操作：优先从页缓存读取，命中率高时可以避免磁盘 I/O&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这种设计使得 Kafka 在处理大量数据时仍能保持高性能，同时简化了系统架构。&lt;/p&gt;
&lt;h3 id=&#34;存储格式&#34;&gt;存储格式
&lt;/h3&gt;&lt;p&gt;Kafka 消息的存储格式经过精心设计，包含以下字段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;8 字节 Offset&lt;/li&gt;
&lt;li&gt;4 字节消息大小&lt;/li&gt;
&lt;li&gt;4 字节 CRC32 校验和&lt;/li&gt;
&lt;li&gt;1 字节魔数（Magic Byte）&lt;/li&gt;
&lt;li&gt;1 字节属性（压缩类型等）&lt;/li&gt;
&lt;li&gt;4 字节 Key 长度（-1 表示没有 Key）&lt;/li&gt;
&lt;li&gt;Key 数据（如果存在）&lt;/li&gt;
&lt;li&gt;4 字节 Value 长度&lt;/li&gt;
&lt;li&gt;Value 数据（实际消息内容）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种格式设计既保证了数据完整性，又兼顾了存储效率。&lt;/p&gt;
&lt;h3 id=&#34;批量写入与压缩&#34;&gt;批量写入与压缩
&lt;/h3&gt;&lt;p&gt;Kafka 支持消息批量写入和压缩，以提高存储效率和网络传输效率：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;批量写入&lt;/strong&gt;：多条消息组成一个批次（Batch），一次性写入磁盘&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;压缩&lt;/strong&gt;：支持 GZIP、Snappy、LZ4、ZStandard 等压缩算法&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;端到端压缩&lt;/strong&gt;：Producer 压缩，Broker 保持压缩状态存储，Consumer 解压&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;压缩率取决于消息内容的特性，对于文本类数据，通常可以达到 3-5 倍的压缩比。&lt;/p&gt;
&lt;h2 id=&#34;存储优化最佳实践&#34;&gt;存储优化最佳实践
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;合理设置 Partition 数量&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;考虑并行度需求和资源限制&lt;/li&gt;
&lt;li&gt;一般建议每个 Broker 的 Partition 数不超过 2000-4000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;优化磁盘配置&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 SSD 提高随机读写性能&lt;/li&gt;
&lt;li&gt;使用 RAID 10 而非 RAID 5/6&lt;/li&gt;
&lt;li&gt;分离操作系统和数据目录&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;调整 Segment 大小&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;较小的 Segment 有利于及时清理过期数据&lt;/li&gt;
&lt;li&gt;较大的 Segment 减少文件数量，降低管理开销&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;合理配置保留策略&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据业务需求设置 &lt;code&gt;log.retention.hours&lt;/code&gt; 和 &lt;code&gt;log.retention.bytes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;对不同 Topic 设置不同的保留策略&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;监控磁盘使用率&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保持足够的磁盘空间（至少 20% 空闲）&lt;/li&gt;
&lt;li&gt;设置磁盘使用率告警&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;Kafka 作为一个高性能、分布式的流处理平台，通过精心设计的架构和机制，实现了高吞吐量、可靠性和可扩展性。理解 Kafka 的核心概念和工作原理，对于构建高效、可靠的消息系统至关重要。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
