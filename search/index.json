[{"content":"缓存雪崩 定义 缓存雪崩是指在短时间内，大量缓存键集中过期或缓存服务崩溃，导致大量请求直接访问数据库，使数据库瞬间压力激增，可能引起整个系统崩溃的现象。\n产生原因 大量缓存同时过期：系统中大量缓存使用了相同的过期时间 缓存服务器宕机：Redis实例发生故障或重启 高并发请求：在缓存失效的同时有大量请求涌入 解决方案 过期时间差异化 随机过期时间：在固定过期时间基础上增加随机值 1 2 int expireTime = baseExpireTime + new Random().nextInt(RANDOM_RANGE); redisTemplate.opsForValue().set(key, value, expireTime, TimeUnit.SECONDS); 缓存高可用 Redis集群：使用Redis Sentinel或Redis Cluster确保高可用 多级缓存：本地缓存 + 分布式缓存，降低Redis压力 1 2 3 4 5 6 7 8 9 // 使用Caffeine作为本地缓存 @Bean public CacheManager cacheManager() { CaffeineCacheManager cacheManager = new CaffeineCacheManager(); cacheManager.setCaffeine(Caffeine.newBuilder() .expireAfterWrite(5, TimeUnit.MINUTES) .maximumSize(10000)); return cacheManager; } 熔断降级 限流：使用令牌桶或漏桶算法限制请求流量 熔断机制：当检测到异常时，暂停部分服务 1 2 3 4 5 6 7 8 9 10 11 12 // 使用Sentinel实现熔断 @SentinelResource(value = \u0026#34;getProductInfo\u0026#34;, fallback = \u0026#34;getProductInfoFallback\u0026#34;) public Product getProductInfo(Long productId) { String key = \u0026#34;product:\u0026#34; + productId; // 查询缓存... // 缓存未命中查询数据库... } public Product getProductInfoFallback(Long productId) { // 返回默认值或基础数据 return new Product(productId, \u0026#34;默认商品\u0026#34;, 0); } 预热机制 系统启动时加载热点数据到缓存 定时刷新即将过期的缓存 适用场景 电商秒杀：提前预热商品数据，设置差异化过期时间 促销活动：活动开始前预加载数据，避免活动开始时缓存雪崩 系统重启：实现缓存预热机制，避免重启后请求全部落到数据库 缓存穿透 定义 缓存穿透是指查询一个根本不存在的数据，缓存中没有，数据库中也没有，导致请求每次都要穿透到数据库，增加数据库压力。\n产生原因 业务误操作：查询不存在的数据 恶意攻击：专门查询不存在的数据，绕过缓存压垮数据库 解决方案 空值缓存 缓存空结果：对不存在的数据也进行缓存，但过期时间较短 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public Product getProduct(Long id) { String key = \u0026#34;product:\u0026#34; + id; // 查询缓存 String productJson = redisTemplate.opsForValue().get(key); // 判断是否为空值标记 if (\u0026#34;__NULL__\u0026#34;.equals(productJson)) { return null; } if (productJson != null) { return JSON.parseObject(productJson, Product.class); } // 查询数据库 Product product = productMapper.selectById(id); // 数据库中不存在，缓存空值 if (product == null) { redisTemplate.opsForValue().set(key, \u0026#34;__NULL__\u0026#34;, 5, TimeUnit.MINUTES); return null; } // 数据库中存在，缓存结果 redisTemplate.opsForValue().set(key, JSON.toJSONString(product), 30, TimeUnit.MINUTES); return product; } 布隆过滤器 原理：使用布隆过滤器快速判断数据是否存在 实现：将所有可能存在的数据哈希到布隆过滤器中 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 使用Redisson实现布隆过滤器 @Bean public RBloomFilter\u0026lt;String\u0026gt; bloomFilter(RedissonClient redissonClient) { RBloomFilter\u0026lt;String\u0026gt; bloomFilter = redissonClient.getBloomFilter(\u0026#34;productBloomFilter\u0026#34;); // 初始化布隆过滤器，预计元素数量为100万，误判率为0.01 bloomFilter.tryInit(1000000L, 0.01); return bloomFilter; } // 使用布隆过滤器判断商品是否存在 public Product getProduct(Long id) { String key = \u0026#34;product:\u0026#34; + id; String idStr = id.toString(); // 通过布隆过滤器判断是否存在 if (!bloomFilter.contains(idStr)) { return null; // 布隆过滤器中不存在，直接返回 } // 查询缓存和数据库的逻辑... } 请求参数校验 接口层校验：对参数进行合法性校验 限流策略：对同一用户频繁访问进行限制 适用场景 用户信息查询：使用布隆过滤器预先加载所有用户ID 商品目录：对不存在的商品ID进行空值缓存 API接口防护：对外部接口使用参数校验和限流保护 缓存击穿 定义 缓存击穿是指一个热点key在过期的瞬间，同时有大量请求并发访问该key，导致所有请求都落到数据库上，造成数据库瞬间压力激增。\n产生原因 热点数据过期：高访问量的热点数据在某一时刻过期 并发请求：大量并发请求同时到达 解决方案 互斥锁（分布式锁） 原理：获取锁的线程负责查询数据库并更新缓存，其他线程等待或重试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 public Product getProduct(Long id) { String key = \u0026#34;product:\u0026#34; + id; String lockKey = \u0026#34;lock:product:\u0026#34; + id; // 查询缓存 String productJson = redisTemplate.opsForValue().get(key); if (productJson != null) { return JSON.parseObject(productJson, Product.class); } // 获取分布式锁 boolean locked = redisTemplate.opsForValue().setIfAbsent(lockKey, \u0026#34;1\u0026#34;, 10, TimeUnit.SECONDS); try { if (locked) { // 双重检查 productJson = redisTemplate.opsForValue().get(key); if (productJson != null) { return JSON.parseObject(productJson, Product.class); } // 查询数据库 Product product = productMapper.selectById(id); if (product != null) { // 更新缓存，设置较长的过期时间 redisTemplate.opsForValue().set(key, JSON.toJSONString(product), 1, TimeUnit.HOURS); } return product; } else { // 未获取到锁，短暂休眠后重试 Thread.sleep(50); return getProduct(id); } } catch (Exception e) { log.error(\u0026#34;获取商品信息异常\u0026#34;, e); return null; } finally { // 释放锁 if (locked) { redisTemplate.delete(lockKey); } } } 永不过期策略 逻辑过期：不设置实际过期时间，而是在value中维护一个逻辑过期时间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 public Product getProduct(Long id) { String key = \u0026#34;product:\u0026#34; + id; // 查询缓存 String productJsonWithExpire = redisTemplate.opsForValue().get(key); if (productJsonWithExpire != null) { ProductWithExpire productWithExpire = JSON.parseObject(productJsonWithExpire, ProductWithExpire.class); // 判断是否逻辑过期 if (productWithExpire.getExpireTime() \u0026gt; System.currentTimeMillis()) { // 未过期，直接返回 return productWithExpire.getProduct(); } // 已过期，尝试获取锁进行更新 String lockKey = \u0026#34;lock:product:\u0026#34; + id; boolean locked = redisTemplate.opsForValue().setIfAbsent(lockKey, \u0026#34;1\u0026#34;, 10, TimeUnit.SECONDS); if (locked) { try { // 异步更新缓存 threadPool.submit(() -\u0026gt; { // 查询数据库 Product newProduct = productMapper.selectById(id); if (newProduct != null) { // 设置新的过期时间 ProductWithExpire newProductWithExpire = new ProductWithExpire(); newProductWithExpire.setProduct(newProduct); newProductWithExpire.setExpireTime(System.currentTimeMillis() + TimeUnit.HOURS.toMillis(1)); // 更新缓存 redisTemplate.opsForValue().set(key, JSON.toJSONString(newProductWithExpire)); } }); } finally { // 释放锁 redisTemplate.delete(lockKey); } } // 返回过期的数据 return productWithExpire.getProduct(); } // 缓存未命中，查询数据库并设置缓存 // ... } 提前刷新缓存 定时任务：对热点数据定时刷新，避免过期 异步更新：在即将过期前异步更新缓存 适用场景 商品详情页：高流量商品使用互斥锁或永不过期策略 首页数据：使用定时任务提前刷新缓存 热门活动：活动期间对热点数据设置永不过期 缓存预热 定义 缓存预热是指在系统启动或者预计流量高峰前，提前将热点数据加载到缓存中，避免用户请求时再加载导致的性能问题。\n实现方案 系统启动预热 启动时加载：系统启动时，主动查询数据库并加载热点数据到缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Component public class CachePreheater implements ApplicationRunner { @Autowired private ProductService productService; @Override public void run(ApplicationArguments args) { log.info(\u0026#34;开始预热商品缓存...\u0026#34;); // 加载热门商品 List\u0026lt;Long\u0026gt; hotProductIds = productService.getHotProductIds(); for (Long id : hotProductIds) { productService.preloadProductCache(id); } log.info(\u0026#34;商品缓存预热完成，共预热{}个商品\u0026#34;, hotProductIds.size()); } } 定时刷新 定时任务：使用定时任务定期刷新即将过期的缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Component @EnableScheduling public class CacheRefresher { @Autowired private ProductService productService; // 每天凌晨2点执行 @Scheduled(cron = \u0026#34;0 0 2 * * ?\u0026#34;) public void refreshHotProductCache() { log.info(\u0026#34;开始刷新热门商品缓存...\u0026#34;); List\u0026lt;Long\u0026gt; hotProductIds = productService.getHotProductIds(); for (Long id : hotProductIds) { productService.preloadProductCache(id); } log.info(\u0026#34;热门商品缓存刷新完成\u0026#34;); } } 手动触发 管理接口：提供管理接口，允许运维人员手动触发缓存预热 适用场景 电商秒杀：活动开始前预热商品数据 系统重启：重启后立即预热核心数据 促销活动：活动前预热相关商品和活动规则 缓存降级 定义 缓存降级是指在Redis缓存异常或者流量剧增的情况下，暂时屏蔽部分功能或返回默认值，保证核心业务的正常运行。\n实现方案 返回默认值 异常时返回兜底数据：当缓存和数据库都无法访问时，返回预设的默认值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public List\u0026lt;Product\u0026gt; getRecommendProducts(Long userId) { try { // 尝试从缓存获取 String key = \u0026#34;recommend:user:\u0026#34; + userId; String productsJson = redisTemplate.opsForValue().get(key); if (productsJson != null) { return JSON.parseArray(productsJson, Product.class); } // 缓存未命中，查询推荐系统 List\u0026lt;Product\u0026gt; products = recommendService.getRecommendProducts(userId); if (!products.isEmpty()) { redisTemplate.opsForValue().set(key, JSON.toJSONString(products), 1, TimeUnit.HOURS); return products; } // 推荐系统未返回结果，查询默认推荐 return getDefaultRecommendProducts(); } catch (Exception e) { log.error(\u0026#34;获取推荐商品异常，返回默认推荐\u0026#34;, e); return getDefaultRecommendProducts(); } } private List\u0026lt;Product\u0026gt; getDefaultRecommendProducts() { // 返回预设的热门商品列表 return productService.getHotProducts(10); } 功能降级 关闭非核心功能：在系统压力大时，暂时关闭一些非核心功能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Service public class ProductServiceWithDegradation { @Autowired private ConfigService configService; public ProductDetail getProductDetail(Long productId) { ProductDetail detail = new ProductDetail(); // 基础信息（核心功能，必须保留） Product product = getProductBasicInfo(productId); detail.setProduct(product); // 判断是否开启了降级 boolean isDegraded = configService.isFeatureDegraded(\u0026#34;product_detail\u0026#34;); if (!isDegraded) { // 非降级状态，加载完整信息 detail.setComments(getProductComments(productId)); detail.setRecommendations(getRelatedProducts(productId)); detail.setDetailImages(getProductDetailImages(productId)); } else { // 降级状态，只保留核心功能 detail.setComments(Collections.emptyList()); detail.setRecommendations(Collections.emptyList()); detail.setDetailImages(Collections.singletonList(product.getMainImage())); } return detail; } } 本地缓存兜底 使用本地缓存：当Redis不可用时，使用本地缓存提供服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Service public class CacheDegradationService { @Autowired private StringRedisTemplate redisTemplate; // 本地缓存 private LoadingCache\u0026lt;String, String\u0026gt; localCache = CacheBuilder.newBuilder() .maximumSize(1000) .expireAfterWrite(5, TimeUnit.MINUTES) .build(new CacheLoader\u0026lt;String, String\u0026gt;() { @Override public String load(String key) { // 从数据库加载数据 return loadFromDatabase(key); } }); public String getData(String key) { try { // 优先从Redis获取 String value = redisTemplate.opsForValue().get(key); if (value != null) { // 同步更新本地缓存 localCache.put(key, value); return value; } } catch (Exception e) { log.warn(\u0026#34;Redis访问异常，降级使用本地缓存\u0026#34;, e); // Redis异常，使用本地缓存 } // 从本地缓存获取 try { return localCache.get(key); } catch (ExecutionException e) { log.error(\u0026#34;本地缓存获取数据异常\u0026#34;, e); return null; } } } 适用场景 促销活动：大促期间对非核心功能进行降级 系统故障：Redis故障时使用本地缓存提供基础服务 流量高峰：返回静态默认推荐，减轻推荐系统压力 缓存并发竞争 定义 缓存并发竞争是指多个线程或进程同时操作缓存中的同一个key，可能导致数据不一致或更新丢失的问题。\n解决方案 分布式锁 互斥访问：使用Redis分布式锁确保同一时间只有一个线程能更新缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public boolean updateProductStock(Long productId, int deductAmount) { String lockKey = \u0026#34;lock:product_stock:\u0026#34; + productId; String stockKey = \u0026#34;product_stock:\u0026#34; + productId; // 获取分布式锁 boolean locked = redisTemplate.opsForValue().setIfAbsent(lockKey, \u0026#34;1\u0026#34;, 10, TimeUnit.SECONDS); if (!locked) { // 未获取到锁，稍后重试 return false; } try { // 获取当前库存 String stockStr = redisTemplate.opsForValue().get(stockKey); int currentStock = stockStr != null ? Integer.parseInt(stockStr) : 0; // 判断库存是否足够 if (currentStock \u0026lt; deductAmount) { return false; } // 更新缓存中的库存 int newStock = currentStock - deductAmount; redisTemplate.opsForValue().set(stockKey, String.valueOf(newStock)); // 异步更新数据库 threadPool.submit(() -\u0026gt; updateProductStockInDb(productId, newStock)); return true; } finally { // 释放锁 redisTemplate.delete(lockKey); } } 原子操作 使用Redis原子操作：利用Redis的原子操作如INCR、DECR等 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public boolean deductStock(Long productId, int amount) { String stockKey = \u0026#34;product_stock:\u0026#34; + productId; // 使用Redis的原子操作扣减库存 Long result = redisTemplate.opsForValue().decrement(stockKey, amount); // 判断扣减后的库存是否合法 if (result != null \u0026amp;\u0026amp; result \u0026gt;= 0) { // 异步更新数据库 threadPool.submit(() -\u0026gt; updateProductStockInDb(productId, result.intValue())); return true; } else if (result != null \u0026amp;\u0026amp; result \u0026lt; 0) { // 库存不足，恢复缓存中的库存 redisTemplate.opsForValue().increment(stockKey, amount); return false; } return false; } 乐观锁 版本号控制：使用版本号或CAS操作控制并发更新 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public boolean updateProductInfo(Product product) { String productKey = \u0026#34;product:\u0026#34; + product.getId(); String versionKey = \u0026#34;product_version:\u0026#34; + product.getId(); // 获取当前版本号 String versionStr = redisTemplate.opsForValue().get(versionKey); int currentVersion = versionStr != null ? Integer.parseInt(versionStr) : 0; // 设置新版本号 int newVersion = currentVersion + 1; product.setVersion(newVersion); // 使用Lua脚本实现原子操作 String script = \u0026#34;if redis.call(\u0026#39;get\u0026#39;, KEYS[2]) == ARGV[1] then \u0026#34; + \u0026#34; redis.call(\u0026#39;set\u0026#39;, KEYS[1], ARGV[2]); \u0026#34; + \u0026#34; redis.call(\u0026#39;set\u0026#39;, KEYS[2], ARGV[3]); \u0026#34; + \u0026#34; return 1; \u0026#34; + \u0026#34;else \u0026#34; + \u0026#34; return 0; \u0026#34; + \u0026#34;end\u0026#34;; List\u0026lt;String\u0026gt; keys = Arrays.asList(productKey, versionKey); List\u0026lt;String\u0026gt; args = Arrays.asList( String.valueOf(currentVersion), JSON.toJSONString(product), String.valueOf(newVersion) ); Long result = (Long) redisTemplate.execute(new DefaultRedisScript\u0026lt;\u0026gt;(script, Long.class), keys, args.toArray()); return result != null \u0026amp;\u0026amp; result == 1; } 适用场景 库存管理：使用原子操作或分布式锁控制库存扣减 计数器服务：点赞、评论计数使用原子操作 配置更新：使用乐观锁控制配置信息更新 缓存更新策略 定义 缓存更新策略是指在数据发生变化时，如何保证缓存数据与数据库数据的一致性。\n常见策略 Cache-Aside（旁路缓存） 读操作：先查缓存，缓存没有则查数据库，并将结果放入缓存 写操作：先更新数据库，再删除缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 读取数据 public Product getProduct(Long id) { String key = \u0026#34;product:\u0026#34; + id; // 查询缓存 String productJson = redisTemplate.opsForValue().get(key); if (productJson != null) { return JSON.parseObject(productJson, Product.class); } // 缓存未命中，查询数据库 Product product = productMapper.selectById(id); if (product != null) { // 将结果放入缓存 redisTemplate.opsForValue().set(key, JSON.toJSONString(product), 1, TimeUnit.HOURS); } return product; } // 更新数据 public void updateProduct(Product product) { // 先更新数据库 productMapper.updateById(product); // 再删除缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.delete(key); } Read-Through/Write-Through（读写穿透） 读操作：应用程序从缓存读取，缓存负责从数据库加载 写操作：应用程序写入缓存，缓存负责更新数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 使用Spring Cache实现Read-Through/Write-Through @Service public class ProductServiceImpl implements ProductService { @Autowired private ProductMapper productMapper; @Cacheable(value = \u0026#34;products\u0026#34;, key = \u0026#34;#id\u0026#34;) public Product getProduct(Long id) { // 缓存未命中时自动调用此方法加载数据 return productMapper.selectById(id); } @CachePut(value = \u0026#34;products\u0026#34;, key = \u0026#34;#product.id\u0026#34;) public Product updateProduct(Product product) { // 更新数据库 productMapper.updateById(product); // 返回的对象会被自动放入缓存 return product; } @CacheEvict(value = \u0026#34;products\u0026#34;, key = \u0026#34;#id\u0026#34;) public void deleteProduct(Long id) { // 删除数据库中的数据 productMapper.deleteById(id); // 缓存会被自动删除 } } Write-Behind（异步写入） 写操作：先更新缓存，异步批量更新数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @Service public class ProductWriteBehindService { @Autowired private StringRedisTemplate redisTemplate; @Autowired private ProductMapper productMapper; // 写入队列 private BlockingQueue\u0026lt;Product\u0026gt; writeQueue = new LinkedBlockingQueue\u0026lt;\u0026gt;(1000); @PostConstruct public void init() { // 启动异步写入线程 new Thread(() -\u0026gt; { List\u0026lt;Product\u0026gt; batch = new ArrayList\u0026lt;\u0026gt;(); while (true) { try { // 收集批量更新的数据 Product product = writeQueue.poll(100, TimeUnit.MILLISECONDS); if (product != null) { batch.add(product); } // 达到批量大小或等待超时，执行批量更新 if (batch.size() \u0026gt;= 100 || (!batch.isEmpty() \u0026amp;\u0026amp; product == null)) { updateBatch(batch); batch.clear(); } } catch (Exception e) { log.error(\u0026#34;异步写入数据库异常\u0026#34;, e); } } }).start(); } // 更新数据 public void updateProduct(Product product) { // 先更新缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product), 1, TimeUnit.HOURS); // 加入异步写入队列 writeQueue.offer(product); } // 批量更新数据库 private void updateBatch(List\u0026lt;Product\u0026gt; products) { if (products.isEmpty()) { return; } try { productMapper.batchUpdate(products); } catch (Exception e) { log.error(\u0026#34;批量更新数据库异常\u0026#34;, e); // 异常处理：记录失败的更新，定时重试等 } } } 适用场景 读多写少：Cache-Aside适合读多写少的场景 高并发写入：Write-Behind适合高并发写入场景，可以减轻数据库压力 框架集成：Read-Through/Write-Through适合与缓存框架集成的场景 缓存淘汰策略 定义 缓存淘汰策略是指当缓存空间不足时，如何选择删除哪些数据，为新数据腾出空间。\nRedis支持的淘汰策略 volatile-lru（默认） 策略：从设置了过期时间的键中，删除最近最少使用的键 适用场景：希望只淘汰有过期时间的键，且希望留下最常用的数据 allkeys-lru 策略：从所有键中，删除最近最少使用的键 适用场景：缓存访问符合幂律分布（少数键被频繁访问） volatile-lfu（Redis 0+） 策略：从设置了过期时间的键中，删除使用频率最少的键 适用场景：有些键虽然最近被访问，但访问频率很低 allkeys-lfu（Redis 0+） 策略：从所有键中，删除使用频率最少的键 适用场景：希望留下被访问次数最多的数据 volatile-random 策略：从设置了过期时间的键中，随机删除 适用场景：键的访问概率相同 allkeys-random 策略：从所有键中，随机删除 适用场景：键的访问概率相同 volatile-ttl 策略：从设置了过期时间的键中，删除即将过期的键 适用场景：希望留下过期时间更长的数据 noeviction 策略：不删除键，当内存不足时，新写入操作会报错 适用场景：不允许丢失数据，宁可写入失败 配置方法 配置文件设置 1 2 3 # 在redis.conf中设置 maxmemory 2gb maxmemory-policy allkeys-lru 命令行设置 1 2 CONFIG SET maxmemory 2gb CONFIG SET maxmemory-policy allkeys-lru 最佳实践 业务场景选择 热点数据：使用LRU或LFU策略 统计数据：使用LFU策略 时效性数据：使用TTL策略 内存规划 预留内存：maxmemory设置为总内存的70%-80% 监控内存：设置内存使用率告警 过期时间设置 差异化过期：根据数据重要性设置不同过期时间 避免同时过期：添加随机时间 缓存数据一致性 定义 缓存数据一致性是指缓存中的数据与数据库中的数据保持一致的程度。根据业务需求，可以分为强一致性、最终一致性和弱一致性。\n一致性级别 强一致性 特点：缓存与数据库中的数据始终保持一致 实现方式：双写操作放在一个事务中，或使用分布式事务 代价：性能较低，可用性降低 1 2 3 4 5 6 7 8 9 10 11 @Transactional public void updateProductWithStrongConsistency(Product product) { // 更新数据库 productMapper.updateById(product); // 更新缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product)); // 如果缓存更新失败，事务回滚 } 最终一致性 特点：缓存与数据库的数据在一定时间后达到一致 实现方式：异步更新、定时同步、消息队列 代价：存在短暂的不一致窗口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 使用消息队列实现最终一致性 public void updateProductWithEventualConsistency(Product product) { // 更新数据库 productMapper.updateById(product); // 发送消息到队列 CacheUpdateMessage message = new CacheUpdateMessage(); message.setKey(\u0026#34;product:\u0026#34; + product.getId()); message.setOperation(\u0026#34;update\u0026#34;); message.setData(JSON.toJSONString(product)); kafkaTemplate.send(\u0026#34;cache-update-topic\u0026#34;, JSON.toJSONString(message)); } // 消费者处理缓存更新 @KafkaListener(topics = \u0026#34;cache-update-topic\u0026#34;) public void handleCacheUpdate(String messageJson) { CacheUpdateMessage message = JSON.parseObject(messageJson, CacheUpdateMessage.class); if (\u0026#34;update\u0026#34;.equals(message.getOperation())) { redisTemplate.opsForValue().set(message.getKey(), message.getData()); } else if (\u0026#34;delete\u0026#34;.equals(message.getOperation())) { redisTemplate.delete(message.getKey()); } } 弱一致性 特点：允许缓存与数据库的数据存在一定程度的不一致 实现方式：设置缓存过期时间，过期后自动刷新 代价：可能读取到旧数据 1 2 3 4 5 6 7 8 9 10 // 设置较短的过期时间，接受一定程度的不一致 public void updateProductWithWeakConsistency(Product product) { // 更新数据库 productMapper.updateById(product); // 不主动更新缓存，等待缓存自动过期 // 或者设置较短的过期时间 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product), 5, TimeUnit.MINUTES); } 常见问题及解决方案 缓存与数据库双写不一致 问题：更新数据库成功，但更新缓存失败 解决方案： 重试机制：缓存更新失败时进行重试 消息队列：使用消息队列保证最终一致性 延迟双删：更新数据库后删除缓存，并在一定延迟后再次删除缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 延迟双删策略 public void updateProductWithDelayedDoubleDelete(Product product) { String key = \u0026#34;product:\u0026#34; + product.getId(); // 先删除缓存 redisTemplate.delete(key); // 更新数据库 productMapper.updateById(product); // 延迟一段时间后再次删除缓存 threadPool.schedule(() -\u0026gt; { redisTemplate.delete(key); }, 500, TimeUnit.MILLISECONDS); } 读写并发导致的不一致 问题：写操作和读操作并发执行，可能导致读取到旧数据 解决方案： 读写锁：对同一资源的读写操作加锁 先更新数据库，再删除缓存：减少不一致窗口 缓存穿透导致的不一致 问题：缓存未命中，多个请求同时查询数据库并更新缓存 解决方案： 分布式锁：获取锁的线程负责查询数据库并更新缓存 布隆过滤器：过滤不存在的数据 适用场景 强一致性：订单、支付等对一致性要求高的核心业务 最终一致性：商品详情、用户信息等允许短暂不一致的业务 弱一致性：推荐列表、热门商品等对实时性要求不高的业务 缓存性能优化 定义 缓存性能优化是指通过合理配置和使用Redis，提高缓存的响应速度、吞吐量和资源利用率。\n优化方向 数据结构优化 合理选择数据类型：根据业务场景选择合适的Redis数据类型 String：简单键值对，如用户信息 Hash：对象存储，如商品详情 List：有序列表，如消息队列 Set：无序集合，如用户标签 Sorted Set：有序集合，如排行榜 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // 使用Hash存储对象，减少内存占用 public void saveProductUsingHash(Product product) { String key = \u0026#34;product:\u0026#34; + product.getId(); Map\u0026lt;String, String\u0026gt; fields = new HashMap\u0026lt;\u0026gt;(); fields.put(\u0026#34;id\u0026#34;, product.getId().toString()); fields.put(\u0026#34;name\u0026#34;, product.getName()); fields.put(\u0026#34;price\u0026#34;, product.getPrice().toString()); fields.put(\u0026#34;stock\u0026#34;, product.getStock().toString()); // 其他字段... redisTemplate.opsForHash().putAll(key, fields); } // 获取部分字段，减少网络传输 public Product getProductBasicInfo(Long id) { String key = \u0026#34;product:\u0026#34; + id; List\u0026lt;String\u0026gt; fields = Arrays.asList(\u0026#34;id\u0026#34;, \u0026#34;name\u0026#34;, \u0026#34;price\u0026#34;); List\u0026lt;Object\u0026gt; values = redisTemplate.opsForHash().multiGet(key, fields); Product product = new Product(); product.setId(Long.valueOf(values.get(0).toString())); product.setName(values.get(1).toString()); product.setPrice(new BigDecimal(values.get(2).toString())); return product; } 内存优化 压缩数据：使用压缩算法减少内存占用 共享对象池：启用Redis的对象共享池 合理设置过期时间：避免长期占用内存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 使用压缩算法减少内存占用 public void saveCompressedData(String key, Object data) { try { // 序列化对象 ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(data); byte[] bytes = baos.toByteArray(); // 压缩数据 ByteArrayOutputStream compressedBaos = new ByteArrayOutputStream(); GZIPOutputStream gzipOutputStream = new GZIPOutputStream(compressedBaos); gzipOutputStream.write(bytes); gzipOutputStream.close(); byte[] compressedBytes = compressedBaos.toByteArray(); // 存储压缩后的数据 redisTemplate.opsForValue().set(key, Base6getEncoder().encodeToString(compressedBytes)); } catch (Exception e) { log.error(\u0026#34;压缩数据异常\u0026#34;, e); } } 连接优化 连接池配置：合理设置连接池大小和超时时间 Pipeline批量操作：使用Pipeline批量执行命令，减少网络往返 Lua脚本：使用Lua脚本将多个操作合并为一个原子操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // 使用Pipeline批量获取数据 public List\u0026lt;Product\u0026gt; batchGetProducts(List\u0026lt;Long\u0026gt; ids) { List\u0026lt;Product\u0026gt; products = new ArrayList\u0026lt;\u0026gt;(); // 使用Pipeline批量查询 List\u0026lt;Object\u0026gt; results = redisTemplate.executePipelined(new RedisCallback\u0026lt;Object\u0026gt;() { @Override public Object doInRedis(RedisConnection connection) throws DataAccessException { StringRedisConnection stringRedisConn = (StringRedisConnection) connection; // 批量发送命令 for (Long id : ids) { stringRedisConn.get(\u0026#34;product:\u0026#34; + id); } return null; // 返回值由Pipeline处理 } }); // 处理结果 for (int i = 0; i \u0026lt; results.size(); i++) { String productJson = (String) results.get(i); if (productJson != null) { products.add(JSON.parseObject(productJson, Product.class)); } else { // 缓存未命中，从数据库加载 Product product = productMapper.selectById(ids.get(i)); if (product != null) { products.add(product); // 异步更新缓存 final Long id = ids.get(i); final Product finalProduct = product; threadPool.submit(() -\u0026gt; { redisTemplate.opsForValue().set(\u0026#34;product:\u0026#34; + id, JSON.toJSONString(finalProduct)); }); } } } return products; } 读写分离 主从复制：读操作访问从节点，写操作访问主节点 读写分离：使用不同的连接池连接主从节点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, String\u0026gt; masterRedisTemplate() { RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate = new RedisTemplate\u0026lt;\u0026gt;(); redisTemplate.setConnectionFactory(masterConnectionFactory()); // 配置序列化器等 return redisTemplate; } @Bean public RedisTemplate\u0026lt;String, String\u0026gt; slaveRedisTemplate() { RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate = new RedisTemplate\u0026lt;\u0026gt;(); redisTemplate.setConnectionFactory(slaveConnectionFactory()); // 配置序列化器等 return redisTemplate; } // 读操作使用从节点 public Product getProduct(Long id) { String key = \u0026#34;product:\u0026#34; + id; String productJson = slaveRedisTemplate.opsForValue().get(key); // ... } // 写操作使用主节点 public void updateProduct(Product product) { String key = \u0026#34;product:\u0026#34; + id; masterRedisTemplate.opsForValue().set(key, JSON.toJSONString(product)); // ... } } 性能监控与调优 监控指标 命中率：缓存命中率是衡量缓存效率的重要指标 延迟：操作的响应时间 内存使用：内存使用率和碎片率 连接数：当前连接数和连接峰值 常见问题及解决方案 大key问题：拆分大key，使用Hash存储 热点key问题：本地缓存 + 分布式缓存 缓存穿透：布隆过滤器，空值缓存 缓存雪崩：随机过期时间，多级缓存 适用场景 高并发读取：商品详情、用户信息等 计数器服务：点赞、评论计数等 排行榜：使用Sorted Set实现实时排行 分布式锁：秒杀、库存控制等 缓存与数据库双写一致性 定义 缓存与数据库双写一致性是指在同时更新缓存和数据库时，如何保证两者数据的一致性，避免出现数据不一致的情况。\n常见更新模式 先更新数据库，再更新缓存 优点：数据库作为数据源，保证数据的可靠性 缺点：如果更新缓存失败，会导致数据不一致 1 2 3 4 5 6 7 8 public void updateProduct(Product product) { // 先更新数据库 productMapper.updateById(product); // 再更新缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product)); } 先更新缓存，再更新数据库 优点：用户可以立即看到更新后的数据 缺点：如果更新数据库失败，会导致数据不一致 1 2 3 4 5 6 7 8 public void updateProduct(Product product) { // 先更新缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product)); // 再更新数据库 productMapper.updateById(product); } 先删除缓存，再更新数据库 优点：避免缓存和数据库不一致的时间窗口 缺点：可能导致缓存穿透 1 2 3 4 5 6 7 8 public void updateProduct(Product product) { // 先删除缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.delete(key); // 再更新数据库 productMapper.updateById(product); } 先更新数据库，再删除缓存（推荐） 优点：不一致窗口较小，实现简单 缺点：在高并发下仍可能出现不一致 1 2 3 4 5 6 7 8 public void updateProduct(Product product) { // 先更新数据库 productMapper.updateById(product); // 再删除缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.delete(key); } 一致性保障方案 延迟双删策略 原理：更新数据库后删除缓存，并在一定延迟后再次删除缓存 目的：解决并发读写导致的数据不一致问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public void updateProductWithDelayedDoubleDelete(Product product) { String key = \u0026#34;product:\u0026#34; + product.getId(); // 先删除缓存 redisTemplate.delete(key); // 更新数据库 productMapper.updateById(product); // 延迟一段时间后再次删除缓存 threadPool.schedule(() -\u0026gt; { redisTemplate.delete(key); }, 500, TimeUnit.MILLISECONDS); } 消息队列保证最终一致性 原理：使用消息队列异步更新缓存，保证最终一致性 目的：解耦数据库和缓存操作，提高系统可用性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public void updateProductWithMessageQueue(Product product) { // 更新数据库 productMapper.updateById(product); // 发送消息到队列 CacheUpdateMessage message = new CacheUpdateMessage(); message.setKey(\u0026#34;product:\u0026#34; + product.getId()); message.setOperation(\u0026#34;delete\u0026#34;); // 或者\u0026#34;update\u0026#34; message.setData(JSON.toJSONString(product)); kafkaTemplate.send(\u0026#34;cache-update-topic\u0026#34;, JSON.toJSONString(message)); } // 消费者处理缓存更新 @KafkaListener(topics = \u0026#34;cache-update-topic\u0026#34;) public void handleCacheUpdate(String messageJson) { CacheUpdateMessage message = JSON.parseObject(messageJson, CacheUpdateMessage.class); if (\u0026#34;update\u0026#34;.equals(message.getOperation())) { redisTemplate.opsForValue().set(message.getKey(), message.getData()); } else if (\u0026#34;delete\u0026#34;.equals(message.getOperation())) { redisTemplate.delete(message.getKey()); } } 分布式事务 原理：使用分布式事务保证缓存和数据库操作的原子性 目的：强一致性保障，但性能较低 1 2 3 4 5 6 7 8 @Transactional public void updateProductWithTransaction(Product product) { // 在事务中更新数据库和缓存 productMapper.updateById(product); String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.delete(key); } 适用场景 核心业务：订单、支付等对一致性要求高的业务使用分布式事务 一般业务：商品、用户等允许短暂不一致的业务使用延迟双删或消息队列 非核心业务：推荐、统计等对一致性要求低的业务使用简单的更新策略 缓存与数据库异步双写一致性 定义 缓存与数据库异步双写一致性是指通过异步方式更新缓存和数据库，保证两者数据最终一致的方案。\n实现方案 基于消息队列的异步更新 原理：写操作发送消息到队列，消费者异步更新缓存或数据库 优点：解耦系统，提高吞吐量，保证最终一致性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 更新商品信息 public void updateProduct(Product product) { // 直接更新缓存，提供快速响应 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product)); // 发送消息到队列，异步更新数据库 kafkaTemplate.send(\u0026#34;db-update-topic\u0026#34;, JSON.toJSONString(product)); } // 消费者异步更新数据库 @KafkaListener(topics = \u0026#34;db-update-topic\u0026#34;) public void handleDatabaseUpdate(String productJson) { Product product = JSON.parseObject(productJson, Product.class); try { productMapper.updateById(product); } catch (Exception e) { log.error(\u0026#34;更新数据库失败\u0026#34;, e); // 重试机制或补偿机制 retryService.addRetryTask(\u0026#34;db-update\u0026#34;, productJson); } } 基于Binlog的异步同步 原理：监听数据库Binlog变更，异步更新缓存 优点：数据库作为单一数据源，减少不一致风险 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 // 使用Canal监听MySQL Binlog @Component public class BinlogCacheUpdater { @Autowired private StringRedisTemplate redisTemplate; @PostConstruct public void init() { // 配置Canal客户端 CanalConnector connector = CanalConnectors.newSingleConnector( new InetSocketAddress(\u0026#34;120.0.1\u0026#34;, 11111), \u0026#34;example\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;); // 启动监听线程 new Thread(() -\u0026gt; { connector.connect(); connector.subscribe(\u0026#34;.*\\\\..*\u0026#34;); while (true) { Message message = connector.getWithoutAck(100); long batchId = message.getId(); try { List\u0026lt;Entry\u0026gt; entries = message.getEntries(); for (Entry entry : entries) { if (entry.getEntryType() == EntryType.ROWDATA) { RowChange rowChange = RowChange.parseFrom(entry.getStoreValue()); // 处理数据变更 processRowChange(entry.getHeader().getTableName(), rowChange); } } connector.ack(batchId); } catch (Exception e) { log.error(\u0026#34;处理Binlog异常\u0026#34;, e); connector.rollback(batchId); } } }).start(); } private void processRowChange(String tableName, RowChange rowChange) { if (\u0026#34;product\u0026#34;.equals(tableName)) { for (RowData rowData : rowChange.getRowDatasList()) { if (rowChange.getEventType() == EventType.UPDATE || rowChange.getEventType() == EventType.INSERT) { // 获取变更后的数据 List\u0026lt;Column\u0026gt; columns = rowData.getAfterColumnsList(); Map\u0026lt;String, Object\u0026gt; data = new HashMap\u0026lt;\u0026gt;(); Long id = null; for (Column column : columns) { data.put(column.getName(), column.getValue()); if (\u0026#34;id\u0026#34;.equals(column.getName())) { id = Long.valueOf(column.getValue()); } } // 更新缓存 if (id != null) { String key = \u0026#34;product:\u0026#34; + id; redisTemplate.opsForValue().set(key, JSON.toJSONString(data)); } } else if (rowChange.getEventType() == EventType.DELETE) { // 处理删除操作 List\u0026lt;Column\u0026gt; columns = rowData.getBeforeColumnsList(); Long id = null; for (Column column : columns) { if (\u0026#34;id\u0026#34;.equals(column.getName())) { id = Long.valueOf(column.getValue()); break; } } // 删除缓存 if (id != null) { String key = \u0026#34;product:\u0026#34; + id; redisTemplate.delete(key); } } } } } } 定时任务同步 原理：定时从数据库加载数据更新缓存 优点：实现简单，适合对实时性要求不高的场景 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 @Component @EnableScheduling public class CacheSyncTask { @Autowired private ProductMapper productMapper; @Autowired private StringRedisTemplate redisTemplate; // 每天凌晨2点执行全量同步 @Scheduled(cron = \u0026#34;0 0 2 * * ?\u0026#34;) public void fullSync() { log.info(\u0026#34;开始全量同步商品缓存...\u0026#34;); // 分页查询所有商品 int pageSize = 1000; int pageNum = 1; Page\u0026lt;Product\u0026gt; page; do { page = productMapper.selectPage(new Page\u0026lt;\u0026gt;(pageNum, pageSize), null); List\u0026lt;Product\u0026gt; products = page.getRecords(); // 批量更新缓存 for (Product product : products) { String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product)); } pageNum++; } while (page.hasNext()); log.info(\u0026#34;商品缓存全量同步完成\u0026#34;); } // 每小时执行增量同步 @Scheduled(cron = \u0026#34;0 0 * * * ?\u0026#34;) public void incrementalSync() { log.info(\u0026#34;开始增量同步商品缓存...\u0026#34;); // 获取最近一小时更新的商品 Date oneHourAgo = new Date(System.currentTimeMillis() - 3600 * 1000); List\u0026lt;Product\u0026gt; products = productMapper.selectByUpdateTimeAfter(oneHourAgo); // 批量更新缓存 for (Product product : products) { String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product)); } log.info(\u0026#34;商品缓存增量同步完成，共同步{}个商品\u0026#34;, products.size()); } } 异常处理 重试机制 原理：操作失败时进行重试，直到成功或达到最大重试次数 实现：使用重试框架或自定义重试逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @Service public class RetryService { @Autowired private StringRedisTemplate redisTemplate; // 重试队列 private BlockingQueue\u0026lt;RetryTask\u0026gt; retryQueue = new LinkedBlockingQueue\u0026lt;\u0026gt;(); @PostConstruct public void init() { // 启动重试线程 new Thread(() -\u0026gt; { while (true) { try { RetryTask task = retryQueue.take(); // 判断是否达到最大重试次数 if (task.getRetryCount() \u0026gt;= task.getMaxRetryCount()) { log.error(\u0026#34;任务重试次数达到上限，放弃重试：{}\u0026#34;, task); continue; } // 执行重试 boolean success = executeRetry(task); if (!success) { // 重试失败，增加重试次数并重新加入队列 task.setRetryCount(task.getRetryCount() + 1); // 指数退避策略 long delay = (long) Math.pow(2, task.getRetryCount()) * 1000; Thread.sleep(delay); retryQueue.put(task); } } catch (Exception e) { log.error(\u0026#34;重试任务执行异常\u0026#34;, e); } } }).start(); } // 添加重试任务 public void addRetryTask(String type, String data) { RetryTask task = new RetryTask(); task.setType(type); task.setData(data); task.setRetryCount(0); task.setMaxRetryCount(5); task.setCreateTime(new Date()); retryQueue.offer(task); } // 执行重试 private boolean executeRetry(RetryTask task) { try { if (\u0026#34;cache-update\u0026#34;.equals(task.getType())) { // 重试更新缓存 CacheUpdateMessage message = JSON.parseObject(task.getData(), CacheUpdateMessage.class); if (\u0026#34;update\u0026#34;.equals(message.getOperation())) { redisTemplate.opsForValue().set(message.getKey(), message.getData()); } else if (\u0026#34;delete\u0026#34;.equals(message.getOperation())) { redisTemplate.delete(message.getKey()); } } else if (\u0026#34;db-update\u0026#34;.equals(task.getType())) { // 重试更新数据库 Product product = JSON.parseObject(task.getData(), Product.class); productMapper.updateById(product); } return true; } catch (Exception e) { log.error(\u0026#34;执行重试任务失败：{}\u0026#34;, task, e); return false; } } } 补偿机制 原理：定期检查数据一致性，发现不一致时进行修复 实现：定时任务或专门的补偿服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @Component @EnableScheduling public class CacheCompensationTask { @Autowired private ProductMapper productMapper; @Autowired private StringRedisTemplate redisTemplate; // 每天执行一次补偿任务 @Scheduled(cron = \u0026#34;0 0 3 * * ?\u0026#34;) public void compensate() { log.info(\u0026#34;开始执行缓存补偿任务...\u0026#34;); // 获取所有缓存的商品ID Set\u0026lt;String\u0026gt; keys = redisTemplate.keys(\u0026#34;product:*\u0026#34;); for (String key : keys) { try { // 提取商品ID Long productId = Long.valueOf(key.substring(\u0026#34;product:\u0026#34;.length())); // 获取缓存中的商品数据 String productJson = redisTemplate.opsForValue().get(key); Product cacheProduct = JSON.parseObject(productJson, Product.class); // 获取数据库中的商品数据 Product dbProduct = productMapper.selectById(productId); // 比较缓存和数据库中的数据 if (dbProduct == null) { // 数据库中不存在，删除缓存 redisTemplate.delete(key); log.info(\u0026#34;补偿删除不存在的商品缓存：{}\u0026#34;, key); } else if (!isProductEqual(cacheProduct, dbProduct)) { // 数据不一致，更新缓存 redisTemplate.opsForValue().set(key, JSON.toJSONString(dbProduct)); log.info(\u0026#34;补偿更新不一致的商品缓存：{}\u0026#34;, key); } } catch (Exception e) { log.error(\u0026#34;处理缓存补偿异常：{}\u0026#34;, key, e); } } log.info(\u0026#34;缓存补偿任务执行完成\u0026#34;); } // 比较两个商品对象是否相等 private boolean isProductEqual(Product p1, Product p2) { if (p1 == null || p2 == null) { return p1 == p2; } return Objects.equals(pgetId(), pgetId()) \u0026amp;\u0026amp; Objects.equals(pgetName(), pgetName()) \u0026amp;\u0026amp; Objects.equals(pgetPrice(), pgetPrice()) \u0026amp;\u0026amp; Objects.equals(pgetStock(), pgetStock()) \u0026amp;\u0026amp; Objects.equals(pgetVersion(), pgetVersion()); } } 适用场景 高并发写入：使用消息队列异步更新，提高系统吞吐量 数据库为主：使用Binlog同步，保证数据库作为单一数据源 定时统计：使用定时任务同步，适合对实时性要求不高的场景 缓存与数据库同步双写一致性 定义 缓存与数据库同步双写一致性是指在同一个事务中同时更新缓存和数据库，保证两者数据强一致的方案。\n实现方案 本地事务 原理：在同一个本地事务中更新数据库和缓存 局限性：只适用于数据库和缓存在同一个系统中的场景 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Service public class ProductService { @Autowired private ProductMapper productMapper; @Autowired private StringRedisTemplate redisTemplate; @Transactional public void updateProduct(Product product) { // 更新数据库 productMapper.updateById(product); // 更新缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product)); // 如果缓存更新失败，事务会回滚 } } 分布式事务 原理：使用分布式事务框架保证跨系统操作的原子性 实现：使用2PC、TCC、SAGA等分布式事务模式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // 使用Seata实现分布式事务 @GlobalTransactional public void updateProductWithDistributedTransaction(Product product) { // 更新数据库 productMapper.updateById(product); // 更新缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(product)); } // 使用TCC模式实现分布式事务 @Transactional public void updateProductWithTCC(Product product) { // Try阶段 // 锁定数据库记录 productMapper.lockById(product.getId()); // 准备缓存更新（设置临时标记） String key = \u0026#34;product:\u0026#34; + product.getId(); String tempKey = \u0026#34;temp:product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(tempKey, JSON.toJSONString(product)); try { // Confirm阶段 // 更新数据库 productMapper.updateById(product); // 更新缓存 redisTemplate.rename(tempKey, key); } catch (Exception e) { // Cancel阶段 // 解锁数据库记录 productMapper.unlockById(product.getId()); // 删除临时缓存 redisTemplate.delete(tempKey); throw e; } } 最终一致性方案 原理：使用补偿机制保证最终一致性 实现：使用可靠消息、定时任务等 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // 使用可靠消息保证最终一致性 public void updateProductWithReliableMessage(Product product) { // 发送预备消息 String messageId = UUID.randomUUID().toString(); Message message = new Message(); message.setId(messageId); message.setStatus(\u0026#34;PREPARING\u0026#34;); message.setContent(JSON.toJSONString(product)); messageMapper.insert(message); try { // 更新数据库 productMapper.updateById(product); // 将消息状态改为已发送 message.setStatus(\u0026#34;SENT\u0026#34;); messageMapper.updateById(message); // 发送消息到队列 kafkaTemplate.send(\u0026#34;cache-update-topic\u0026#34;, JSON.toJSONString(product)); } catch (Exception e) { // 异常处理：将消息状态改为失败 message.setStatus(\u0026#34;FAILED\u0026#34;); messageMapper.updateById(message); throw e; } } // 消费者处理缓存更新 @KafkaListener(topics = \u0026#34;cache-update-topic\u0026#34;) public void handleCacheUpdate(String productJson) { Product product = JSON.parseObject(productJson, Product.class); try { // 更新缓存 String key = \u0026#34;product:\u0026#34; + product.getId(); redisTemplate.opsForValue().set(key, productJson); } catch (Exception e) { log.error(\u0026#34;更新缓存失败\u0026#34;, e); // 重试机制 retryService.addRetryTask(\u0026#34;cache-update\u0026#34;, productJson); } } 一致性保障挑战 网络延迟和分区 问题：网络延迟可能导致缓存和数据库操作的时序不确定 解决方案：使用延迟双删、消息队列等机制 并发读写 问题：并发读写可能导致数据不一致 解决方案：使用分布式锁、版本控制等机制 系统故障 问题：系统故障可能导致部分操作失败 解决方案：使用补偿机制、重试机制等 适用场景 金融交易：使用分布式事务保证强一致性 订单系统：使用可靠消息保证最终一致性 用户信息：使用本地事务或延迟双删策略 总结 Redis作为高性能的缓存系统，在提升系统性能的同时也带来了一系列挑战，如缓存雪崩、穿透、击穿等问题。本文详细介绍了这些问题的定义、产生原因和解决方案，并针对不同的业务场景提供了最佳实践。\n在实际应用中，需要根据业务特点和一致性要求，选择合适的缓存策略和更新机制。对于核心业务，可能需要强一致性保障；而对于非核心业务，可以采用最终一致性方案，提高系统性能和可用性。\n无论采用何种方案，都需要做好监控和异常处理，确保系统在各种情况下都能正常运行，并保持数据的一致性。\n","date":"2025-04-10T17:19:18+08:00","permalink":"https://hollisho.github.io/p/redis%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/","title":"Redis知识整理"},{"content":"原理 Shopify App 本质上是一个 独立的 Web 应用，但可以嵌入到 Shopify 后台（Admin）或店铺前端（Online Store）。 你可以选择用 Remix + Node.js，或者 PHP（Laravel、Slim 等）。\n🔹 传统 PHP 实现 Shopify App 1️⃣ Shopify 后台 → 访问你的 PHP 服务器（Admin API / Storefront API） 2️⃣ PHP 处理请求，查询数据库 3️⃣ PHP 渲染 HTML，返回给 Shopify 手动创建应用 配置应用信息 让Shopify Cli识别现有项目 先创建 Shopify App 配置 在 PHP 项目根目录手动创建 shopify.app.toml 文件：\n1 touch shopify.app.toml 然后在 shopify.app.toml 里添加：\n1 2 name = \u0026#34;My Laravel Shopify App\u0026#34; scopes = \u0026#34;read_products, write_products\u0026#34; 初始化 package.json 文件 在根目录生成一个空壳 package.json：\n1 2 3 bash复制编辑cd ~/workspace/shopify-php echo \u0026#39;{}\u0026#39; \u0026gt; package.json 或者运行：\n1 npm init -y 这会生成：\n1 2 3 4 5 6 { \u0026#34;name\u0026#34;: \u0026#34;shopify-php\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;MIT\u0026#34; } 📌 这样 Shopify CLI 就能识别你的 PHP 项目是一个 Shopify App 了！\n然后，再运行：\n1 shopify app dev 选择测试商店 如何添加 Theme App Extension 什么是 Theme App Extension？ Theme App Extension 允许你的 Shopify App 自动在商店的 Liquid 主题里添加代码，比如 插入翻译 JS、按钮、HTML 片段 等，而无需商家手动修改代码。\nPHP Shopify App 添加 Theme App Extension 的步骤 🔹在 Shopify CLI 里创建 Theme App Extension 你的 PHP App 是后台，Theme App Extension 需要单独用 Shopify CLI 创建。\n1️⃣ 进入你的 PHP App 目录\n1 cd /your-laravel-shopify-app 2️⃣ 使用 Shopify CLI 创建 Theme App Extension\n1 shopify app generate extension 📌 这里选择 Theme app extension 主题扩展。然后根据提示输入扩展的名称\n3️⃣ 进入新创建的扩展目录\n1 cd extensions/theme-translation 4️⃣ 运行开发模式（用于本地预览）\n1 shopify app dev 📌 这样 Shopify 主题就可以加载你的 Theme App Extension 进行测试。\n🔹修改 Theme App Extension 的 Liquid 代码 创建扩展后，你会看到 blocks/ 目录，里面有 .liquid 文件。\n你可以添加 一个翻译切换组件，让用户点击切换语言：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 liquid复制编辑\u0026lt;div class=\u0026#34;translation-widget\u0026#34;\u0026gt; \u0026lt;button onclick=\u0026#34;switchLanguage(\u0026#39;en\u0026#39;)\u0026#34;\u0026gt;English\u0026lt;/button\u0026gt; \u0026lt;button onclick=\u0026#34;switchLanguage(\u0026#39;fr\u0026#39;)\u0026#34;\u0026gt;Français\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; function switchLanguage(lang) { fetch(\u0026#39;/apps/translation/switch\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify({ language: lang }) }).then(() =\u0026gt; location.reload()); } \u0026lt;/script\u0026gt; 📌 这段代码会被插入到店铺主题里，让用户可以点击按钮切换语言。\n🔹让 PHP 处理语言切换 在 Laravel 后端，添加一个 路由来处理翻译切换：\n📌 routes/web.php\n1 2 3 4 5 6 7 8 use Illuminate\\Http\\Request; use Illuminate\\Support\\Facades\\Session; Route::post(\u0026#39;/apps/translation/switch\u0026#39;, function (Request $request) { $language = $request-\u0026gt;input(\u0026#39;language\u0026#39;); Session::put(\u0026#39;shopify_locale\u0026#39;, $language); return response()-\u0026gt;json([\u0026#39;success\u0026#39; =\u0026gt; true]); }); 📌 这会在 Session 里存储语言信息，然后你的 Laravel API 就可以返回不同语言的数据。\n🔹在 PHP 里修改 API 响应 如果你的 PHP App 需要返回不同语言的数据，你可以在 API 里动态返回翻译内容：\n📌 routes/api.php\n1 2 3 4 5 6 7 8 9 10 Route::get(\u0026#39;/translations\u0026#39;, function () { $language = Session::get(\u0026#39;shopify_locale\u0026#39;, \u0026#39;en\u0026#39;); $translations = [ \u0026#39;en\u0026#39; =\u0026gt; [\u0026#39;welcome\u0026#39; =\u0026gt; \u0026#39;Welcome to our store!\u0026#39;], \u0026#39;fr\u0026#39; =\u0026gt; [\u0026#39;welcome\u0026#39; =\u0026gt; \u0026#39;Bienvenue dans notre magasin!\u0026#39;] ]; return response()-\u0026gt;json([\u0026#39;message\u0026#39; =\u0026gt; $translations[$language][\u0026#39;welcome\u0026#39;]]); }); 📌 这样，你的前端可以调用 /api/translations 来获取翻译后的内容。\n🔹部署 Theme App Extension 1️⃣ 构建扩展\n1 shopify extension build 2️⃣ 提交扩展\n1 shopify extension push 3️⃣ 在 Shopify Partner Dashboard 里发布\n进入 Shopify Partner Dashboard 进入你的 App 在 App Extensions 里找到 Theme App Extension 点击 发布 📌 这样，商家安装你的 App 后，扩展就会自动出现在他们的主题里！\n","date":"2025-04-08T15:20:25+08:00","permalink":"https://hollisho.github.io/p/%E4%BC%A0%E7%BB%9F-php-%E5%AE%9E%E7%8E%B0-shopify-app/","title":"传统 PHP 实现 Shopify App"},{"content":"Redis缓存一致性同步方案以及适用场景 常见同步方案 Cache-Aside（旁路缓存） 原理 读操作：先查询Redis，未命中则读取MySQL，并将结果回写到Redis 写操作：直接写入MySQL，然后删除Redis中对应的缓存（或更新） 详细实现方案 架构组件：\n应用层：负责协调缓存和数据库操作 缓存层：Redis集群 存储层：MySQL数据库 数据流向：\n读取流程：应用层 → Redis → (缓存未命中) → MySQL → 应用层 → Redis 写入流程：应用层 → MySQL → 应用层 → Redis(删除缓存) 一致性保障：\n采用「先更新数据库，后删除缓存」的策略 使用延迟双删策略：更新DB后立即删除缓存，并在一定延迟后再次删除缓存，避免并发问题 缓存删除操作失败时，通过重试队列进行补偿 异常处理：\n缓存删除失败：记录日志，加入重试队列 数据库操作失败：事务回滚，不执行缓存操作 缓存穿透防护：布隆过滤器 + 空值缓存 缓存击穿防护：热点数据互斥锁 优点 实现简单、灵活，适用于大部分场景 读写分离，互不影响 可根据业务需求灵活调整缓存策略 缺点 存在短暂不一致窗口（如删除缓存失败） 有缓存穿透/击穿风险 在高并发场景下可能出现「写-读」并发导致的不一致 适用场景 读多写少的业务（如用户信息、商品详情） 允许短暂不一致的业务场景 对缓存命中率要求较高的系统 Read/Write Through（穿透读写） 原理 读操作：请求先到缓存，未命中则由缓存层从MySQL加载并返回 写操作：应用直接写缓存，缓存层同步写MySQL 详细实现方案 架构组件：\n应用层：只与缓存层交互 缓存代理层：封装缓存与数据库的交互逻辑 缓存层：Redis集群 存储层：MySQL数据库 数据流向：\n读取流程：应用层 → 缓存代理层 → Redis → (缓存未命中) → 缓存代理层 → MySQL → 缓存代理层 → Redis → 应用层 写入流程：应用层 → 缓存代理层 → Redis → 缓存代理层 → MySQL 一致性保障：\n缓存代理层负责协调缓存和数据库的一致性 写操作可采用事务机制确保缓存和数据库的原子性更新 可实现为分布式缓存框架，如Spring Cache、Redisson等 异常处理：\n数据库写入失败：回滚缓存更新，返回错误 缓存更新失败：可选择回滚数据库或重试缓存更新 读取异常：降级为直接读取数据库 优点 对应用层透明，一致性较好 简化应用层逻辑，集中处理缓存逻辑 减少应用层与数据库的直接交互 缺点 需要实现或引入专门的缓存代理层 增加了系统复杂度 写操作性能可能受到影响（同步写入数据库） 适用场景 需要高一致性且缓存层支持自动回写的业务（如金融账户余额） 希望简化应用层缓存逻辑的系统 读写比例相对均衡的业务场景 Write Behind（异步回写） 原理 应用直接写Redis，Redis异步批量写入MySQL 详细实现方案 架构组件：\n应用层：只与缓存层交互 缓存层：Redis集群 异步写入服务：负责将缓存变更异步写入数据库 存储层：MySQL数据库 写入队列：存储待写入数据库的操作 数据流向：\n读取流程：应用层 → Redis 写入流程：应用层 → Redis → 写入队列 → 异步写入服务 → MySQL 一致性保障：\n采用写入队列持久化缓存变更操作 批量写入策略：按时间窗口或数据量阈值触发批量写入 写入确认机制：成功写入数据库后标记队列中的操作为已完成 异常处理：\n队列容错：使用持久化队列（如Redis Stream、Kafka）确保消息不丢失 写入失败：重试机制 + 告警通知 缓存宕机：从队列恢复未完成的写入操作 数据库宕机：队列堆积，设置最大重试次数和告警阈值 优点 高吞吐量，减少数据库写入压力 支持批量写入优化 应用层写入延迟低 缺点 数据丢失风险（缓存宕机时） 一致性较弱（最终一致性） 实现复杂度高 适用场景 写密集型且允许最终一致性的场景（如日志记录、计数器） 高并发写入场景（如社交媒体点赞、评论） 对写入性能要求高的系统 双写（Double Write） 原理 应用同时写Redis和MySQL，依赖事务或重试机制保证原子性 详细实现方案 架构组件：\n应用层：同时负责写入缓存和数据库 缓存层：Redis集群 存储层：MySQL数据库 分布式锁服务：确保并发安全 数据流向：\n读取流程：应用层 → Redis → (缓存未命中) → MySQL → 应用层 → Redis 写入流程：应用层 → [分布式锁] → MySQL + Redis（并行或串行） 一致性保障：\n使用分布式锁确保同一数据的写入串行化 采用本地事务 + 补偿机制：先写数据库，再写缓存，缓存写入失败则加入重试队列 可选择TCC（Try-Confirm-Cancel）模式实现跨资源的事务 异常处理：\n数据库写入成功但缓存失败：记录失败操作，异步重试或定时补偿 缓存写入成功但数据库失败：事务回滚，删除缓存 并发冲突：通过分布式锁避免，或使用乐观锁进行冲突检测 优点 实时性高，读取时数据一致性好 无需额外的异步组件 架构相对简单 缺点 需要处理写失败的不一致（如Redis成功但MySQL失败） 增加了写操作的延迟 分布式事务复杂度高 适用场景 对实时性要求高且写操作较少的业务（如配置信息） 对数据一致性要求较高的场景 读写比例相对均衡且并发不是特别高的系统 基于Binlog的异步同步 原理 通过监听MySQL的Binlog（如Canal、Debezium），解析变更后同步到Redis 详细实现方案 架构组件：\n应用层：只负责写入数据库，读取时优先读缓存 Binlog采集器：如Canal、Debezium等 变更处理服务：解析Binlog并转换为缓存操作 缓存层：Redis集群 存储层：MySQL数据库 数据流向：\n读取流程：应用层 → Redis → (缓存未命中) → MySQL → 应用层 写入流程：应用层 → MySQL → Binlog → Binlog采集器 → 变更处理服务 → Redis 一致性保障：\n利用Binlog的有序性和事务特性确保数据变更的顺序一致 变更处理服务保存处理位点，支持从断点续传 定期全量同步校验，修复不一致数据 异常处理：\nBinlog解析失败：记录错误位点，人工介入 网络中断：基于位点机制，恢复后从断点继续处理 Redis更新失败：重试机制，持久化失败记录 数据不一致检测：定期对比校验机制 优点 解耦应用层，对应用透明 保证最终一致性 可靠性高，基于数据库事务日志 缺点 架构复杂，需要额外组件 延迟较高（通常秒级） 需要处理Binlog格式变更等问题 适用场景 强一致性要求的业务（如订单状态、库存扣减） 希望减轻应用层负担的系统 已有成熟的Binlog采集基础设施的团队 消息队列异步处理 原理 写MySQL后发送消息到队列（如Kafka、RabbitMQ），消费者更新Redis 详细实现方案 架构组件：\n应用层：写入数据库并发送消息到队列 消息队列：如Kafka、RabbitMQ 缓存更新服务：消费消息并更新缓存 缓存层：Redis集群 存储层：MySQL数据库 数据流向：\n读取流程：应用层 → Redis → (缓存未命中) → MySQL → 应用层 写入流程：应用层 → MySQL → 应用层 → 消息队列 → 缓存更新服务 → Redis 一致性保障：\n本地事务确保数据库更新和消息发送的原子性（如本地消息表模式） 消息队列的可靠投递机制（如持久化、确认机制） 消费者的幂等处理，避免重复消费导致的问题 异常处理：\n消息发送失败：本地重试或消息表补偿 消息消费失败：重试策略 + 死信队列 缓存更新失败：记录失败操作，定时重试 消息堆积：监控告警，动态扩容消费者 优点 系统解耦，便于扩展 支持削峰填谷，提高系统稳定性 可以灵活处理复杂的缓存更新逻辑 缺点 需要容忍一定的延迟 可能因消息堆积导致不一致时间延长 需要处理消息重复消费问题 适用场景 异步处理高并发写入（如社交点赞、评论数更新） 需要解耦的分布式系统 允许最终一致性的业务场景 定时任务同步 原理 定时从MySQL拉取增量数据，批量更新Redis 详细实现方案 架构组件：\n应用层：只负责写入数据库，读取时优先读缓存 定时同步服务：定期从数据库读取数据并更新缓存 缓存层：Redis集群 存储层：MySQL数据库 数据流向：\n读取流程：应用层 → Redis → (缓存未命中) → MySQL → 应用层 写入流程：应用层 → MySQL 同步流程：定时同步服务 → MySQL → 定时同步服务 → Redis 一致性保障：\n基于时间戳或版本号识别增量数据 批量同步策略：全量同步 + 增量更新 同步任务的分片和并行处理，提高效率 异常处理：\n同步任务失败：记录失败点，下次继续 数据库负载过高：动态调整同步频率和批次大小 缓存更新冲突：基于版本号或时间戳解决 优点 实现简单，易于维护 对应用层完全透明 可控的同步频率，避免对数据库造成冲击 缺点 实时性差，存在较长的不一致窗口 可能重复更新相同数据 全量同步资源消耗大 适用场景 对实时性不敏感的数据（如每日排行榜） 数据变更频率低的业务 系统负载敏感，需要控制同步频率的场景 场景与方案匹配 场景类型 推荐方案 理由 高并发读，弱一致性 Cache-Aside + 过期时间 简单有效，缓存穿透可通过布隆过滤器或空值缓存优化。延迟双删策略可减少不一致窗口。 高并发写，允许最终一致性 Write Behind 或消息队列 降低数据库压力，通过异步批量写入保证吞吐量。写入队列可确保数据不丢失。 强一致性要求（如金融交易） Binlog 同步 + 事务机制 通过Binlog保证数据变更可靠性，结合事务避免中间状态。支持断点续传和全量校验。 读多写少，需高实时性 双写 + 分布式锁（或事务） 确保双写原子性，分布式锁避免并发问题。补偿机制处理异常情况。 数据更新低频，容忍延迟 定时任务同步 实现成本低，适合不频繁变更的数据。可控的同步频率减轻系统负担。 架构解耦，需高扩展性 消息队列 + Binlog 同步 结合消息队列的异步处理与Binlog的可靠性，适合分布式系统。支持多种消费者模式。 关键注意事项 一致性权衡 强一致性：通常牺牲性能和可用性，适用于金融交易等核心业务 最终一致性：提高系统吞吐量，但需业务容忍短暂的数据不一致 弱一致性：性能最佳，适用于对一致性要求不高的场景（如统计数据） 异常处理 双写失败：\n设计补偿机制（如重试队列、定时任务检查） 实现回滚机制，确保数据库和缓存的一致性 关键操作日志记录和告警通知 Binlog同步：\n处理网络中断后的数据追赶（位点管理） 处理Binlog格式变更和表结构变更 实现数据校验和修复机制 缓存策略 过期时间设置：\n根据数据更新频率和重要性设置差异化过期时间 避免冷数据长期占用内存 考虑使用LRU/LFU等淘汰策略 缓存防护：\n使用分布式锁防止缓存击穿（热点key失效） 布隆过滤器防止缓存穿透（查询不存在的数据） 限流熔断机制防止缓存雪崩（大量key同时失效） 性能监控 监控Redis和MySQL的延迟、命中率、连接数等指标 设置关键指标的告警阈值 根据监控数据动态调整缓存策略（如扩容、调整过期时间） 构建缓存预热机制，避免冷启动问题 典型案例 电商库存系统 方案：Binlog同步（强一致性）+ 缓存预扣减 实现细节： Redis存储商品当前库存，支持原子减操作 库存扣减先在Redis执行，成功后异步通知MySQL 通过Binlog同步确保MySQL和Redis最终一致 定期全量校验修复不一致数据 异常处理： 超卖防护：Redis分布式锁 + 库存校验 库存不足：快速失败，提升用户体验 数据不一致：告警 + 自动修复 社交媒体动态系统 方案：消息队列异步更新计数 实现细节： Redis存储点赞、评论等计数器 用户操作写入MySQL，同时发送消息到队列 消费者批量更新Redis计数器 定时任务校准计数，修正偏差 优化点： 消息批量处理提高吞吐量 计数器分片减少热点问题 容忍短暂不一致，提升用户体验 用户会话管理 方案：Cache-Aside + 短过期时间 实现细节： Redis存储用户会话信息，设置合理过期时间 读取优先从Redis获取，未命中则从MySQL加载 更新会话信息时先更新MySQL，再删除Redis缓存 采用延迟双删策略减少不一致窗口 安全考虑： 敏感信息加密存储 会话标识定期轮换 异常登录检测和防护 总结 选择缓存一致性方案时，需综合考虑以下因素：\n业务需求：一致性要求、实时性要求、读写比例 团队技术栈：现有基础设施、技术能力、维护成本 运维成本：监控、告警、故障恢复能力 在实际应用中，通常会混合使用多种策略：\n核心交易数据：使用Binlog同步或双写 + 分布式锁 高频读取数据：使用Cache-Aside + 合理过期时间 高并发写入数据：使用Write Behind或消息队列 统计类数据：使用定时任务同步或异步更新 最佳实践是根据数据特性和业务场景，为不同类型的数据选择最合适的缓存一致性策略，在保证系统可靠性的同时，最大化性能和用户体验。\n","date":"2025-03-28T14:55:52+08:00","permalink":"https://hollisho.github.io/p/redis%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88%E4%BB%A5%E5%8F%8A%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF/","title":"Redis缓存一致性同步方案以及适用场景"},{"content":"Shopify App开发知识整理 修订记录 日期 版本 说明 作者 2024-07-08 v1.0.0 Hollis 前期准备 相关网址 Shopify官网（https://www.shopify.com/）\nShopify开发文档（https://shopify.dev/）\nShopify合作伙伴（https://www.shopify.com/partners）\n相关概念 Partner （合作伙伴）\nShopify 开发者账号，用于开发App、Theme、Extension等 App （应用）\n扩展店铺的功能，可以发布到应用市场 Theme (主题)\n设计店铺的样式，可以发布到主题市场 Custom storefront （自定义店铺）\n商店 在合作伙伴后台添加开发商城，跟着设置指南完成商店设置\nShopify Cli 本地开发环境 安装 Node.js 20.15+ 安装Node.js包管理器 npm、Yarn 或 pnpm 安装 Ruby 2.7+ 安装 Git 2.44+ 安装Shopify Cli 1 npm install -g @shopify/cli@latest 具体安装依赖参考官方文档：https://shopify.dev/docs/api/shopify-cli\n应用 商店后台应用 您可以构建一个应用程序来为 Shopify 商店添加功能并扩展商家体验，或者为客户创造独特的购买体验。您还可以将 Shopify 商店数据提取到您的应用程序、平台或集成中。\n为了根据他们的特定需求定制体验，商家使用 Shopify 应用来帮助建立他们的业务，与外部服务集成，并向他们的 Shopify 后台添加功能。 官方文档：https://shopify.dev/docs/apps/build/scaffold-app\n创建新应用 1 shopify app init 本地运行应用 1 2 cd ho-app #进入应用目录 npm run dev #运行应用 通过控制台输出的Preview URL，查看App 商店前台应用 商店前台应用也叫：主题应用扩展Extension（应用程序块、应用程序嵌入块）\n主题应用程序扩展为您的应用程序提供了两种扩展在线商店主题的集成类型：应用程序块和应用程序嵌入块。您提交到 Shopify 应用商店的每个新应用都需要使用主题应用扩展来与在线商店主题集成。\n主题应用程序扩展允许商家轻松地将动态元素添加到他们的主题中，而无需与 Liquid 模板或代码进行交互。例如，动态元素可以包括产品评论、价格、评级或产品的交互式 3D 模型。\n优点\n主题应用程序扩展会自动在主题编辑器中公开您的应用程序。您可以利用编辑器的可视化编辑功能，而无需在您的应用程序中复制它们。 您可以同时将您的应用程序部署到使用它的所有在线商店。您还可以访问Shopify CDN 上的应用程序版本控制和资产托管的生命周期管理。 一组集成逻辑和指令适用于所有主题。 商家不需要手动编辑他们的主题代码。 该部分功能还未深入研究，构建步骤略。详情参考官方文档：https://shopify.dev/docs/apps/build/online-store\n主题 创建主题 1 shopify theme init 运行主题 1 2 3 cd ho-theme # 进入主题目录 # 运行shopify theme dev --store {store}（store为开发商店的名称）。 shopify theme dev --store quickstart-c1709595 运行成功之后，通过http://127.0.0.1:9292/访问主题\nAdmin API App需要获取shopify的信息如产品、订单、客户信息等，需要通过Admin API获取。\n还有App的授权和鉴权都是通过Admin API方式。\nAdmin API分为GraphQL Admin API、REST Admin API。\nGraphQL Admin API官方文档：https://shopify.dev/docs/api/admin-graphql\nREST Admin API官方文档：https://shopify.dev/docs/api/admin-rest\n特别说明：本报告中案例采用REST Admin API方式\nApp授权和鉴权 Shopify中有两种Token，分别是Session Token会话令牌和Access Token访问令牌。\n会话令牌用于身份验证，不能替代授权。详细了解身份验证和授权之间的区别。\n与 API 访问令牌不同，会话令牌不能用于向 Shopify API 发出经过身份验证的请求。API 访问令牌可用于从应用的后端向 Shopify 发送请求，以便从用户的商店中获取特定数据。\n例如，要向GraphQL Admin API发出经过身份验证的请求，您的应用必须存储其在 OAuth 流程中收到的访问令牌。相比之下，会话令牌由您的应用的后端用来验证来自您的应用前端的嵌入式请求。\n下图显示了使用会话令牌和 API 访问令牌的身份验证过程：\n官方文档：https://shopify.dev/docs/apps/build/authentication-authorization/session-tokens\n总结：Session Token是App 前端和后端交互的凭证；Access Token是App 后端和Shopify交互的凭证。\nOAuth授权 流程图 Access Token Shopify 的 Access Token 分为两种类型：在线 和 离线\nOnline Access Token 使用在线访问模式创建的访问令牌是临时的，并且一定会在一段时间后过期。访问令牌过期后，Shopify 会返回401 Unauthorized响应代码。\n用户可以随时撤销对您应用的访问权限，而不会影响其他用户访问令牌的有效性。当用户退出 Shopify 管理平台时，在同一网络会话期间创建的所有在线模式访问令牌都将被撤销。\nOffline Access Token 使用离线访问模式创建的访问令牌是永久性的。仅当从商店卸载应用程序时，它们才会被撤销。\n多次授权应用进行离线访问时，每次都会返回相同的访问令牌。获得商店的离线访问权限后，只有在卸载应用或需要其他访问范围时才需要重新授权应用。\n","date":"2025-03-26T10:10:47+08:00","permalink":"https://hollisho.github.io/p/shopify-app%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/","title":"Shopify App开发知识整理"},{"content":"微信支付签名（基于对称加密） 优点 性能高 对称加密算法（如MD5、HMAC-SHA256）计算速度快，适合高并发场景。 微信支付每天处理海量交易，性能是关键考量。 实现简单 只需要一个共享的API密钥（商户和微信支付平台都知道），实现和部署较为简单。 不需要管理复杂的公钥和私钥对。 适合短周期请求 微信支付的请求生命周期短，通常只需在请求和响应的短时间内保证数据完整性，对称加密足够满足需求。 兼容性强 对称加密算法广泛支持，各种编程语言和平台都能轻松实现。 缺点 密钥管理风险 API密钥需要共享，存在泄露风险。如果密钥泄露，攻击者可以伪造请求。 需要定期更换密钥以降低风险。 不支持不可否认性 对称加密无法证明请求的唯一来源，因为双方共享同一个密钥。 如果发生纠纷，无法通过签名证明请求是由某一方发起的。 安全性较低 相比非对称加密，对称加密的安全性较弱，尤其是在密钥泄露的情况下。 电子签名（基于非对称加密） 优点 安全性高 非对称加密使用公钥和私钥对，私钥无需共享，安全性更高。 即使公钥泄露，也无法伪造签名。 不可否认性 签名是用私钥生成的，只有持有私钥的一方才能生成签名，因此可以证明请求的唯一来源。 在法律和审计场景中非常重要。 数据完整性 电子签名不仅可以验证数据完整性，还可以验证数据的真实性。 缺点 性能低 非对称加密算法（如RSA、ECC）计算复杂度高，速度较慢。 在高并发场景下（如微信支付），性能可能成为瓶颈。 实现复杂 需要管理公钥和私钥对，密钥分发和管理复杂度高。 需要额外的基础设施（如证书颁发机构CA）来支持公钥的分发和验证。 不适合短周期请求 非对称加密更适合长期有效的数据签名（如合同、证书），而微信支付的请求生命周期短，使用非对称加密显得过于复杂。 微信支付为什么选择对称加密签名？ 业务场景需求 微信支付的核心需求是数据完整性和身份认证，而不是不可否认性。 支付请求的生命周期短，通常只需在短时间内保证数据安全。 性能优先 微信支付每天处理数十亿笔交易，性能是关键。对称加密的计算速度远快于非对称加密。 实现简单 对称加密的实现和部署更简单，适合快速迭代和扩展。 风险可控 虽然对称加密的密钥管理存在风险，但微信支付通过其他安全措施（如HTTPS、IP白名单、风控系统）来降低风险。 总结 特性 微信支付签名（对称加密） 电子签名（非对称加密） 性能 高 低 实现复杂度 简单 复杂 安全性 较低（依赖密钥管理） 高 不可否认性 不支持 支持 适用场景 高并发、短周期请求（如支付） 长期有效数据（如合同、证书） 微信支付选择对称加密签名是为了在性能、实现复杂度、业务需求之间找到最佳平衡。虽然对称加密的安全性较低，但通过其他安全措施可以弥补这一不足。而电子签名更适合对安全性和不可否认性要求更高的场景（如法律文件、合同签署）。\n","date":"2025-03-17T14:41:07+08:00","permalink":"https://hollisho.github.io/p/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98%E7%AD%BE%E5%90%8D%E5%9F%BA%E4%BA%8E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86vs%E7%94%B5%E5%AD%90%E7%AD%BE%E5%90%8D%E5%9F%BA%E4%BA%8E%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/","title":"微信支付签名（基于对称加密）vs电子签名（基于非对称加密）"},{"content":"PHP Helpers PHP Helpers 是一个简单易用的 PHP 工具集合，它提供了许多常用的辅助函数，可以帮助你更快速、更方便地完成 PHP 开发工作。无论你是 PHP 新手还是有经验的开发者，这个工具包都能让你的编码更加高效。\n安装 基本使用方法 1. 在项目中引入 安装完成后，你需要在你的 PHP 文件中引入 Composer 的自动加载文件：\n1 require_once \u0026#39;vendor/autoload.php\u0026#39;; 2. 使用辅助函数 PHP Helpers 提供了多种辅助函数，你可以直接调用它们：\n1 2 3 4 5 // 例如使用数组辅助函数 $result = \\Hollisho\\Helpers\\ArrayHelper::get($array, \u0026#39;user.name\u0026#39;, \u0026#39;默认值\u0026#39;); // 例如使用字符串辅助函数 $slug = \\Hollisho\\Helpers\\StringHelper::slug(\u0026#39;Hello World\u0026#39;); 常用功能示例 数组操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 从多维数组中安全获取值 $user = [ \u0026#39;profile\u0026#39; =\u0026gt; [ \u0026#39;name\u0026#39; =\u0026gt; \u0026#39;张三\u0026#39;, \u0026#39;age\u0026#39; =\u0026gt; 25 ] ]; // 获取用户名 $name = \\Hollisho\\Helpers\\ArrayHelper::get($user, \u0026#39;profile.name\u0026#39;); echo $name; // 输出: 张三 // 如果键不存在，返回默认值 $address = \\Hollisho\\Helpers\\ArrayHelper::get($user, \u0026#39;profile.address\u0026#39;, \u0026#39;未设置\u0026#39;); echo $address; // 输出: 未设置 1 2 3 4 5 6 7 8 9 10 ### 字符串处理 ```php // 生成URL友好的字符串 $slug = \\Hollisho\\Helpers\\StringHelper::slug(\u0026#39;你好 世界\u0026#39;); echo $slug; // 输出: ni-hao-shi-jie 或类似格式 // 随机字符串生成 $random = \\Hollisho\\Helpers\\StringHelper::random(8); echo $random; // 输出: 类似 a1b2c3d4 的8位随机字符串 日期时间处理 1 2 3 4 5 6 7 // 格式化日期 $formatted = \\Hollisho\\Helpers\\DateHelper::format(\u0026#39;2023-01-01\u0026#39;, \u0026#39;Y年m月d日\u0026#39;); echo $formatted; // 输出: 2023年01月01日 // 获取两个日期之间的天数 $days = \\Hollisho\\Helpers\\DateHelper::diffInDays(\u0026#39;2023-01-01\u0026#39;, \u0026#39;2023-01-10\u0026#39;); echo $days; // 输出: 9 环境变量功能 如果你需要使用环境变量功能（EnvHelper），需要额外安装 vlucas/phpdotenv 扩展：\n1 composer require vlucas/phpdotenv:^5.6 安装后，你可以这样使用：\n1 2 3 4 5 6 // 加载 .env 文件 \\Hollisho\\Helpers\\EnvHelper::load(\u0026#39;/path/to/your/project\u0026#39;); // 获取环境变量 $dbName = \\Hollisho\\Helpers\\EnvHelper::get(\u0026#39;DB_NAME\u0026#39;, \u0026#39;default_db\u0026#39;); echo $dbName; 如何测试 创建一个测试文件，例如 test.php ： 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;?php // 引入自动加载文件 require_once \u0026#39;vendor/autoload.php\u0026#39;; // 测试数组辅助函数 $array = [\u0026#39;user\u0026#39; =\u0026gt; [\u0026#39;name\u0026#39; =\u0026gt; \u0026#39;李四\u0026#39;, \u0026#39;email\u0026#39; =\u0026gt; \u0026#39;lisi@example.com\u0026#39;]]; $name = \\Hollisho\\Helpers\\ArrayHelper::get($array, \u0026#39;user.name\u0026#39;); echo \u0026#34;用户名: \u0026#34; . $name . \u0026#34;\\n\u0026#34;; // 测试字符串辅助函数 $random = \\Hollisho\\Helpers\\StringHelper::random(10); echo \u0026#34;随机字符串: \u0026#34; . $random . \u0026#34;\\n\u0026#34;; ","date":"2025-03-17T13:49:36+08:00","permalink":"https://hollisho.github.io/p/php%E5%B8%B8%E7%94%A8%E5%8A%A9%E6%89%8B%E7%B1%BB%E5%BA%93php-helpers-%E7%AE%80%E4%BB%8B%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","title":"PHP常用助手类库PHP Helpers 简介和使用方法"},{"content":"简介 hollisho/http-client 是一个功能强大且易于使用的PHP HTTP客户端库，旨在简化REST API的调用和集成。它提供了灵活的配置选项、中间件支持和基于注解的API定义，让开发者能够更高效地处理HTTP请求。\n主要特性 🚀 支持多种HTTP方法（GET, POST, PUT, DELETE等） 🔧 可扩展的中间件系统 🎯 基于注解的API定义 🛡️ 内置认证支持（Basic Auth） 📦 自动处理JSON请求/响应 ⚡ 兼容PHP 7.x 和 PHP 8.0+ 快速开始 安装 1 composer require hollisho/http-client 基本使用 1 2 3 4 use hollisho\\httpclient\\BaseClient; $httpClient = new BaseClient(\u0026#39;https://api.example.com\u0026#39;); $response = $httpClient-\u0026gt;httpGet(\u0026#39;/users\u0026#39;); 使用注解定义API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * @BaseUrl(host=\u0026#34;https://api.example.com\u0026#34;) */ interface UserService { /** * @Action( * method=@Get, * endpoint=@Endpoint(uri=\u0026#34;/users/{id}\u0026#34;) * ) */ public function getUser($id); } $client = FeignClientFactory::create(UserService::class); $user = $client-\u0026gt;getUser(123); 为什么选择 hollisho/http-client？ 简化开发 ：通过注解自动生成API客户端，减少样板代码 灵活扩展 ：支持自定义中间件，轻松添加日志、缓存等功能 现代PHP支持 ：全面支持PHP 8.0+的新特性 文档完善 ：提供详细的文档和示例代码 活跃维护 ：持续更新和维护，及时修复问题 获取更多信息 GitHub仓库 完整文档 示例代码 立即体验 hollisho/http-client ，让您的PHP HTTP请求处理更加高效便捷！ ","date":"2024-11-11T14:41:07+08:00","permalink":"https://hollisho.github.io/p/%E9%AB%98%E6%95%88php-http%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BA%93-hollisho/http-client/","title":"高效PHP HTTP客户端库 - hollisho/http-client"},{"content":"Webman框架请求验证器扩展包 本扩展包为Webman框架提供了一个优雅的请求验证解决方案，内置了ThinkPHP验证器，通过依赖注入方式自动生成请求对象，并对对象的字段进行校验。\n安装 通过Composer安装：\n1 composer require hollisho/webman-request 基本使用 定义请求类 首先，创建一个继承自WebmanRequest的请求类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026lt;?php namespace app\\request; use Hollisho\\WebmanRequest\\WebmanRequest; class MyRequest extends WebmanRequest { // 定义请求参数属性 public $id; public $status = 0; // 可以设置默认值 // 定义验证规则 public function rules() { return [ \u0026#39;id\u0026#39; =\u0026gt; \u0026#39;require|number\u0026#39;, \u0026#39;status\u0026#39; =\u0026gt; \u0026#39;require|number\u0026#39;, ]; } // 定义错误消息 protected function messages() { return [ \u0026#39;id.require\u0026#39; =\u0026gt; \u0026#39;id不能为空\u0026#39;, \u0026#39;id.number\u0026#39; =\u0026gt; \u0026#39;id必须为数字\u0026#39;, \u0026#39;status.require\u0026#39; =\u0026gt; \u0026#39;status不能为空\u0026#39;, \u0026#39;status.number\u0026#39; =\u0026gt; \u0026#39;status必须为数字\u0026#39;, ]; } } 在控制器中使用 在控制器中通过依赖注入方式使用请求类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;?php namespace app\\controller; use app\\request\\MyRequest; use support\\Response; class IndexController { public function index(MyRequest $request) { // 验证通过后，可以直接使用请求对象的属性 $id = $request-\u0026gt;id; $status = $request-\u0026gt;status; // 业务逻辑处理... return json([\u0026#39;code\u0026#39; =\u0026gt; 0, \u0026#39;msg\u0026#39; =\u0026gt; \u0026#39;success\u0026#39;, \u0026#39;data\u0026#39; =\u0026gt; [ \u0026#39;id\u0026#39; =\u0026gt; $id, \u0026#39;status\u0026#39; =\u0026gt; $status ]]); } } 常用验证规则 本扩展包内置了ThinkPHP验证器的所有验证规则，以下是一些常用的验证规则：\n规则 说明 示例 require 必须填写 \u0026rsquo;name\u0026rsquo; =\u0026gt; \u0026lsquo;require\u0026rsquo; number 必须是数字 \u0026lsquo;age\u0026rsquo; =\u0026gt; \u0026rsquo;number\u0026rsquo; integer 必须是整数 \u0026lsquo;count\u0026rsquo; =\u0026gt; \u0026lsquo;integer\u0026rsquo; float 必须是浮点数 \u0026lsquo;price\u0026rsquo; =\u0026gt; \u0026lsquo;float\u0026rsquo; boolean 必须是布尔值 \u0026lsquo;status\u0026rsquo; =\u0026gt; \u0026lsquo;boolean\u0026rsquo; email 必须是邮箱格式 \u0026rsquo;email\u0026rsquo; =\u0026gt; \u0026rsquo;email\u0026rsquo; array 必须是数组 \u0026rsquo;tags\u0026rsquo; =\u0026gt; \u0026lsquo;array\u0026rsquo; date 必须是日期格式 \u0026lsquo;birthday\u0026rsquo; =\u0026gt; \u0026lsquo;date\u0026rsquo; alpha 必须是字母 \u0026rsquo;name\u0026rsquo; =\u0026gt; \u0026lsquo;alpha\u0026rsquo; alphaNum 必须是字母和数字 \u0026lsquo;account\u0026rsquo; =\u0026gt; \u0026lsquo;alphaNum\u0026rsquo; alphaDash 必须是字母、数字、下划线或破折号 \u0026lsquo;username\u0026rsquo; =\u0026gt; \u0026lsquo;alphaDash\u0026rsquo; chs 必须是中文 \u0026rsquo;name\u0026rsquo; =\u0026gt; \u0026lsquo;chs\u0026rsquo; chsAlpha 必须是中文或字母 \u0026rsquo;name\u0026rsquo; =\u0026gt; \u0026lsquo;chsAlpha\u0026rsquo; chsAlphaNum 必须是中文、字母或数字 \u0026rsquo;name\u0026rsquo; =\u0026gt; \u0026lsquo;chsAlphaNum\u0026rsquo; chsDash 必须是中文、字母、数字、下划线或破折号 \u0026rsquo;name\u0026rsquo; =\u0026gt; \u0026lsquo;chsDash\u0026rsquo; url 必须是URL地址 \u0026lsquo;website\u0026rsquo; =\u0026gt; \u0026lsquo;url\u0026rsquo; ip 必须是IP地址 \u0026lsquo;ip\u0026rsquo; =\u0026gt; \u0026lsquo;ip\u0026rsquo; mobile 必须是手机号码 \u0026lsquo;mobile\u0026rsquo; =\u0026gt; \u0026lsquo;mobile\u0026rsquo; idCard 必须是身份证号码 \u0026lsquo;idcard\u0026rsquo; =\u0026gt; \u0026lsquo;idCard\u0026rsquo; zipCode 必须是邮政编码 \u0026lsquo;zipcode\u0026rsquo; =\u0026gt; \u0026lsquo;zipCode\u0026rsquo; in 必须在范围内 \u0026rsquo;type\u0026rsquo; =\u0026gt; \u0026lsquo;in:1,2,3\u0026rsquo; notIn 必须不在范围内 \u0026rsquo;type\u0026rsquo; =\u0026gt; \u0026rsquo;notIn:1,2,3\u0026rsquo; between 必须在范围内 \u0026lsquo;age\u0026rsquo; =\u0026gt; \u0026lsquo;between:18,60\u0026rsquo; notBetween 必须不在范围内 \u0026lsquo;age\u0026rsquo; =\u0026gt; \u0026rsquo;notBetween:0,17\u0026rsquo; length 长度必须在范围内 \u0026rsquo;name\u0026rsquo; =\u0026gt; \u0026rsquo;length:2,20\u0026rsquo; max 最大长度 \u0026rsquo;name\u0026rsquo; =\u0026gt; \u0026lsquo;max:20\u0026rsquo; min 最小长度 \u0026lsquo;password\u0026rsquo; =\u0026gt; \u0026lsquo;min:6\u0026rsquo; after 必须在日期之后 \u0026lsquo;begin_time\u0026rsquo; =\u0026gt; \u0026lsquo;after:2020-01-01\u0026rsquo; before 必须在日期之前 \u0026rsquo;end_time\u0026rsquo; =\u0026gt; \u0026lsquo;before:2030-01-01\u0026rsquo; confirm 必须和指定字段相同 \u0026lsquo;repassword\u0026rsquo; =\u0026gt; \u0026lsquo;confirm:password\u0026rsquo; different 必须和指定字段不同 \u0026rsquo;nickname\u0026rsquo; =\u0026gt; \u0026lsquo;different:username\u0026rsquo; eq 必须等于指定值 \u0026lsquo;status\u0026rsquo; =\u0026gt; \u0026rsquo;eq:1\u0026rsquo; neq 必须不等于指定值 \u0026lsquo;status\u0026rsquo; =\u0026gt; \u0026rsquo;neq:0\u0026rsquo; gt 必须大于指定值 \u0026lsquo;age\u0026rsquo; =\u0026gt; \u0026lsquo;gt:18\u0026rsquo; lt 必须小于指定值 \u0026lsquo;age\u0026rsquo; =\u0026gt; \u0026rsquo;lt:60\u0026rsquo; egt 必须大于等于指定值 \u0026lsquo;age\u0026rsquo; =\u0026gt; \u0026rsquo;egt:18\u0026rsquo; elt 必须小于等于指定值 \u0026lsquo;age\u0026rsquo; =\u0026gt; \u0026rsquo;elt:60\u0026rsquo; regex 必须满足正则表达式 \u0026lsquo;zip\u0026rsquo; =\u0026gt; \u0026lsquo;regex:/^\\d{6}$/\u0026rsquo; 总结 hollisho/webman-request扩展包为Webman框架提供了一个强大而灵活的请求验证解决方案，通过依赖注入的方式自动验证请求参数，使代码更加简洁和易于维护。它支持多种验证规则、自定义验证规则、验证场景等高级功能，能够满足各种复杂的验证需求。\n参考链接 Webman官方文档 ThinkPHP验证器文档 特别说明 由于thinkphp验证器的原因，本扩展包不支持php8.0以上的版本，请在使用前确认您的PHP版本。 本扩展包仅提供了基本的请求验证功能，对于更复杂的验证需求，您可以根据实际情况自行扩展。（例如场景的支持目前尚未支持） ","date":"2024-10-21T14:13:57+08:00","permalink":"https://hollisho.github.io/p/webman%E6%A1%86%E6%9E%B6%E8%AF%B7%E6%B1%82%E9%AA%8C%E8%AF%81%E5%99%A8%E6%89%A9%E5%B1%95%E5%8C%85/","title":"Webman框架请求验证器扩展包"},{"content":"插件目录结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 ./htranslate ├── db/ │ ├── migrations/ │ │ └── xxxxxx_migration.php //数据库迁移文件 ├── inc/ │ ├── Api/ //WordPress提供的API │ │ ├── CustomizeApi.php // 主题自定义API │ │ └── SettingsApi.php // 后台界面自定义API │ ├── Base/ │ │ ├── BaseAdminPage.php // WordPress后台页面基础类 │ │ └── Common.php // 插件公共信息 │ ├── Exceptions/ // 异常类 │ │ ├── InvalidArgumentException.php │ ├── Handlers/ │ │ ├── Activate.php // 插件启动执行脚本 │ │ └── Deactivate.php // 插件禁用执行脚本 │ ├── Helpers/ │ │ ├── ArrayHelper.php // 数组操作助手类 │ │ ├── AssetsHelper.php // Assets资源路径助手类 │ │ ├── DomHelper.php // DOM助手类 │ │ └── helpers.php // 插件公共方法 │ ├── Http/ │ │ ├── Controllers │ │ │ ├── BaseController.php // 控制器基类 │ │ │ ├── CommonController.php // 公共操作 │ │ │ ├── ImproveController.php // 翻译改进 │ │ │ ├── PageController.php // 后台页面 │ │ │ └── TestController.php // 测试操作 │ │ ├── Filters //HTTP过滤器 │ │ │ ├── AuthFilter.php // 授权过滤器 │ │ │ ├── FilterInterface.php │ │ │ └── FilterPipeline.php // 过滤器管道 │ │ ├── Views │ │ │ ├── Vo/ // ValueObject用于规范化输出结果 │ │ │ ├── HttpView.php // 普通页面视图 │ │ │ ├── JsonViewTrait.php // Json视图 │ │ │ └── TeamoneViewTrait.php // 霆万模板引擎视图 │ ├── Infrastructure/ // 基础设施层 │ │ │ ├── Components/ // 通用组件 │ │ │ ├── Models/ // 数据表模型 │ │ │ ├── Providers/ // 服务提供者，用于扩展第三方服务支持 │ │ │ │ ├── HoTemplateServiceProvider.php // 引入Ho模板引擎 │ │ │ └── Repositories/ // 仓储层 │ ├── Services/ // 应用服务层 │ ├── WPProviders/ // WP功能服务提供者 │ │ │ ├── AddAdminMenuPage.php // 注册后台管理菜单 │ │ │ ├── RegisterAdminScripts.php // 加载后台静态资源文件 │ │ │ └── RegisterRoute.php // 注册WP路由 │ └── Pages/ // WP后台菜单对应的页面 │ ├── Dashboard.php // 首页 │ ├── Settings.php // 设置 │ └── Hosting.php // 语言托管 ├── resources/ // 静态资源目录 │ ├── css/ │ └── js / ├── templates/ // 页面模板文件目录 ├── htranslate.php // 插件入口文件 └── composer.json 架构设计图 ","date":"2024-05-26T10:23:04+08:00","permalink":"https://hollisho.github.io/p/wordpress%E6%8F%92%E4%BB%B6%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","title":"Wordpress插件架构设计"},{"content":"Singular Page:详情页 Single Post Page：Attachment Post、Custom Post、Blog Post\nStatic Page：Page Template\npost模板文件加载顺序 $customer.php-\u0026gt;single-post.php-\u0026gt;single.php-\u0026gt;singular.php-\u0026gt;index.php\npage模板文件加载顺序 $customer.php-\u0026gt;page-$slug.php-\u0026gt;page-$id.php-\u0026gt;page.php-\u0026gt;singular.php-\u0026gt;index.php\nattachment模板文件加载顺序 $mimetype-$subtype.php-\u0026gt;$subtype.php-\u0026gt;$mimetype.php-\u0026gt;attachment.php-\u0026gt;single.php-\u0026gt;singular.php-\u0026gt;index.php\nArchive Page：归档页 Category Archive分类目录模板加载顺序 category-$slug.php-\u0026gt;category-$id.php-\u0026gt;category.php-\u0026gt;archive.php-\u0026gt;index.php\nTag Archive标签模板加载顺序 tag-$slug.php-\u0026gt;tag-$id.php-\u0026gt;tag.php-\u0026gt;archive.php-\u0026gt;index.php\nAuthor Archive作者归档页模板加载顺序 author-$nicename.php-\u0026gt;author-$id.php-\u0026gt;author.php-\u0026gt;archive.php-\u0026gt;index.php\nDate Archive日期归档页模板加载顺序 YearArchive-\u0026gt;date.php-\u0026gt;archive.php-\u0026gt;index.php\nMonthArchive-\u0026gt;date.php-\u0026gt;archive.php-\u0026gt;index.php\nDayArchive-\u0026gt;date.php-\u0026gt;archive.php-\u0026gt;index.php\nSite Front Page：首页 Page Shown On Front 表示在设置-\u0026gt;阅读设置-\u0026gt;首页指定为静态页面\nPosts Shown On Front 表示在设置-\u0026gt;阅读设置-\u0026gt;首页指定为最新文章\nBlog Posts Index Page 表示在设置-\u0026gt;阅读设置-\u0026gt;指定的文章页\nFront-page.php-\u0026gt;Posts Shown On Front-\u0026gt;home.php-\u0026gt;index.php\nFront-page.php-\u0026gt;Page Shown On Front-\u0026gt;page-$slug.php-\u0026gt;page-$id.php-\u0026gt;page.php-\u0026gt;singular.php-\u0026gt;index.php\nBlog Posts Index Page-\u0026gt;home.php-\u0026gt;index.php\n404 Page 404.php-\u0026gt;index.php\nSearch Page search.php-\u0026gt;index.php\nEmbed Page嵌入页面 embed-$post-type-$post-format.php-\u0026gt;embed-$post-type.php-\u0026gt;embed.php-\u0026gt;wp-include/theme-compat/embed.php\n自定义内容详情页 $customer.php-\u0026gt;single-$posttype-$slug.php-\u0026gt;single-$posttype.php-\u0026gt;single.php-\u0026gt;singular.php-\u0026gt;index.php\n自定义内容归档页 archvice-$posttype.php-\u0026gt;archive.php-\u0026gt;index.php\n自定义分类项目归档页 taxonomy-$taxonomy-$term.php-\u0026gt;taxonomy-$taxonomy.php-\u0026gt;taxonomy.php-\u0026gt;archive.php-\u0026gt;index.php\nwordpress模板层级图 ","date":"2024-04-20T12:14:46+08:00","permalink":"https://hollisho.github.io/p/wordpress%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%B1%82%E7%BA%A7/","title":"Wordpress主题模板层级"},{"content":"","date":"2024-04-18T13:36:19+08:00","permalink":"https://hollisho.github.io/p/wordpress%E9%A1%B5%E9%9D%A2%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","title":"Wordpress页面生命周期"},{"content":"内容类型和分类方式 Debug Bar插件 Queries WP Query Object Cache Post Types Post Type 内容类型 Taxonomy 分类方式 category 分类目录 post_tag 标签 Debug Bar Taxonomy插件可以查看所有分类方式 最小主题 style.css 必填字段: Theme Name、Author、Description、Version、License、License URI、Text Domain\n1 2 3 4 5 6 7 8 9 10 11 12 13 /* Theme Name: Mini Theme Theme URI: 主题的详细介绍的网址，仅在官方主题库中才会用到 Author: Hollis Author URI: http://www.1024plus.com Description: 最小主题 Version: 1.0.0 License: 主题的版权信息 License URI: 版权详情网址 Text Domain: 国际化相关 Tags: 标签，方便用于在官方主题库中筛选 Domain Paths: 语言包路径 */ index.php 详情页模板层级 文章详情页 1 2 3 4 5 $custom.php single-post.php single.php singular.php index.php 附件详情页 wp_posts表中post_mime_type记录了attachment的mimetype\n如：image/png，其中mimetype是image，subtype是png\n上传附件可能有大小限制，可以修改php.ini中的post_max_size\n1 2 3 4 5 6 7 $mimetype-$subtype.php $subtype.php $mimetype.php attachment.php single.php singular.php index.php 自定义内容类型详情页 1 2 3 4 5 6 $custom.php single-$posttype-$slug.php single-$posttype.php single.php singular.php index.php 页面详情页 Custom Template 采用了自定义模板 1 $custom.php 如果页面对应的自定义模板被删除了，但是数据中的对应关系还在，则按以下规则加载模板\n1 2 3 page.php singular.php index.php Default Template 采用了默认模板 1 2 3 4 5 page-$slug.php page-$id.php page.php singular.php index.php 自定义模板文件 Template Post Type 可以为空，默认只支持page\n1 2 3 4 5 6 7 \u0026lt;?php /* Template Name: 自定义模板 Template Post Type: post,page,product */ ?\u0026gt; 分类目录归档页 Category Archice 1 2 3 4 5 category-$slug.php category-$id.php category.php archive.php index.php Tag Archive 1 2 3 4 5 tag-$slug.php tag-$id.php tag.php archive.php index.php Author Archive 1 2 3 4 5 author-$nicename.php author-$id.php author.php archive.php index.php Date Archive (Year Archive、Month Archive、Day Archive) 可以通过小工具，进入到日期归档页\n1 2 3 date.php archive.php index.php 自定义内容归档页(custom post type) 1 2 3 archive-$posttype.php archive.php index.php 自定义分类方式归档页(custom taxonomy) 如：自定义产品分类product_cat，其中有phone、pc两个分类项目，则$taxonomy为product_cat、$term为phone和pc\n1 2 3 4 5 taxonomy-$taxonomy-$term.php taxonomy-$taxonomy.php taxonomy.php archive.php index.php 站点首页模板层级 Posts show on front（默认设置） 1 2 3 front-page.php home.php index.php Page show on front（一个静态页面） 1 2 front-page.php 后面的模板层级和页面详情页一致 Blog Post Index Page(指定为文章页的页面) 1 2 home.php index.php 404错误页、搜索结果页、被嵌入内容页 404错误页 1 2 404.php index.php 搜索结果页 1 2 search.php index.php 归档页默认查询结果 分类目录归档页 queried_object (WP_Term) 分类目录信息 - 日期分类归档页没有queried_object字段 queried_object_id 分类目录id posts 归档页的文章信息数组 post (WP_Post) 当前文章信息 is_archive = 1 归档页 is_category = 1 分类目录归档页 详情页默认查询结果 文章详情页 queried_object 文章信息 queried_object_id 文章id posts 数组里面只有一个文章信息 post 当前文章信息 is_single = 1 内容详情页 is_singular = 1 详情页 首页和其他页面默认查询结果 首页（默认） posts 最新发布的文章信息数组 post 当前文章信息 is_home = 1 首页（设置了自定义页面） posts 自定义页面的信息，数组只有一个元素 post 自定义页面的信息 queried_object 自定义页面的信息 queried_object_id 自定义页面id is_page = 1 is_singular = 1 详情页 Blog文章索引页（就是在阅读设置中，文章页指定了自定义页面） queried_object 自定义页面的信息 queried_object_id 自定义页面id posts 最新发布的文章信息数组 post 当前文章信息 is_home = 1 is_posts_page = 1 搜索结果页 posts 搜索结果的所有文章信息数组 post 当前文章信息 is_search = 1 404错误页 is_404 = 1 获取文章各种数据的模板标签 获取内容并输出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //文章ID the_ID(); //文章标题 the_title(); //文章内容 the_content(); //文章摘要。如果没有设置摘要，会自动截取一部分内容作为摘要 the_excerpt(); //获取作者信息 the_author(); //获取文章的网址 the_permalink(); //发布时间。 //时间格式可以在设置-\u0026gt;常规中设置 //也可以指定格式the_time(\u0026#39;Y-m-d H:i:s\u0026#39;); the_time(); 获取内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 //文章ID get_the_ID(); //文章标题 get_the_title(); //文章内容 get_the_content(); //文章摘要。如果没有设置摘要，会自动截取一部分内容作为摘要 get_the_excerpt(); //获取作者信息 get_the_author(); //作者归档页超链接。用户名+超链接 get_the_author_link(); //获取文章别名。自带了urlencode。使用的时候需要urldecode global $post; $post-\u0026gt;post_name; //获取文章的网址 get_the_permalink(); //发布时间。 //时间格式可以在设置-\u0026gt;常规中设置 //也可以指定格式get_the_time(\u0026#39;Y-m-d H:i:s\u0026#39;); get_the_time(); //获取文章评论数量 get_comments_number(); 获取文章所属的分类目录信息 the_category 获取内容并输出 get_the_category_list 获取内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * @param string $separator 默认以⽆序列表输出分类链接，当⽂章指定了多个分类时，提供⼀个字符⽤于分隔这些分类链接。 * @param string $parents \u0026#39;\u0026#39;：不显示父类信息； \u0026#39;multiple\u0026#39;：显示父类信息，分开显示(有各自的超链接)； \u0026#39;single\u0026#39;：显示父类信息，与子类合并显示(公用一个超链接) * @param int $post_id 在have_posts() 循环中使用时，不要传值，否则需要传入指定post_id * * 例子: * the_category(\u0026#39;,\u0026#39;, \u0026#39;multiple\u0026#39;); * 输出：\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;体育\u0026lt;/a\u0026gt;,\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;篮球\u0026lt;/a\u0026gt; * the_category(\u0026#39;,\u0026#39;, \u0026#39;single\u0026#39;); * 输出：\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;体育,篮球\u0026lt;/a\u0026gt; * */ function the_category( $separator = \u0026#39;\u0026#39;, $parents = \u0026#39;\u0026#39;, $post_id = false ) { echo get_the_category_list( $separator, $parents, $post_id ); } get_the_category（纯数据，不带html标签） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * WP_Term Object * * term_id 分类ID * name 分类名称 * slug 分类别名 * description 分类描述 * taxonomy 分类项目的分类方式 category * ...... */ $categorys = get_the_category(); foreach ($categorys as $category) { \u0026lt;p\u0026gt;编号：\u0026lt;?php echo $category-\u0026gt;term_id; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;名称：\u0026lt;?php echo $category-\u0026gt;name; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;别名：\u0026lt;?php echo $category-\u0026gt;slug; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;描述：\u0026lt;?php echo $category-\u0026gt;description; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;⽹址：\u0026lt;?php echo get_category_link($category); ?\u0026gt;\u0026lt;/p\u0026gt; } 获取文章所属标签信息 the_tags 获取标签并输出 get_the_tag_list 获取标签 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * @param string $before 标签链接前的内容 * @param string $sep 多个标签之间的分隔符，默认为\u0026#39;,\u0026#39; * @param string $after 标签链接后的内容 */ function the_tags( $before = null, $sep = \u0026#39;, \u0026#39;, $after = \u0026#39;\u0026#39; ) { if ( null === $before ) { $before = __( \u0026#39;Tags: \u0026#39; ); } $the_tags = get_the_tag_list( $before, $sep, $after ); if ( ! is_wp_error( $the_tags ) ) { echo $the_tags; } } /** * $post_id 文章id */ function get_the_tag_list( $before = \u0026#39;\u0026#39;, $sep = \u0026#39;\u0026#39;, $after = \u0026#39;\u0026#39;, $post_id = 0 ) get_the_tags（纯数据，不带html标签） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * WP_Term Object * * term_id 分类ID * name 分类名称 * slug 分类别名 * description 分类描述 * taxonomy 分类项目的分类方式 post_tag * ...... */ $posttags = get_the_tags(); if ($posttags) foreach($posttags as $tag) { echo \u0026#39;标签ID：\u0026#39; . $tag-\u0026gt;term_id; echo \u0026#39;\u0026lt;br /\u0026gt;标签名称：\u0026#39; . $tag-\u0026gt;name; echo \u0026#39;\u0026lt;br /\u0026gt;标签描述：\u0026#39; . $tag-\u0026gt;description; echo \u0026#39;\u0026lt;br /\u0026gt;标签网址：\u0026#39; . get_tag_link($tag); } 分类归档页中调用和显示数据 Category Archive 分类目录归档页 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //获取分类目录信息 $category = get_queried_object(); \u0026lt;p\u0026gt;编号：\u0026lt;?php echo $category-\u0026gt;term_id; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;名称：\u0026lt;?php echo $category-\u0026gt;name; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;别名：\u0026lt;?php echo $category-\u0026gt;slug; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;描述：\u0026lt;?php echo $category-\u0026gt;description; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;⽹址：\u0026lt;?php echo get_category_link($category); ?\u0026gt;\u0026lt;/p\u0026gt; //获取分类目录下面的文章信息 \u0026lt;?php if( have_posts() ): ?\u0026gt; \u0026lt;?php while( have_posts() ): the_post(); ?\u0026gt; \u0026lt;?php the_author(); //作者名称 ?\u0026gt; \u0026lt;?php the_title(); //标题 ?\u0026gt; \u0026lt;?php the_content(); //正文 ?\u0026gt; \u0026lt;?php echo get_comments_number(); //评论数量 ?\u0026gt; \u0026lt;?php endwhile; ?\u0026gt; \u0026lt;?php endif; ?\u0026gt; Tag Archive 标签归档页 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //获取标签信息 $tag = get_queried_object(); \u0026lt;p\u0026gt;编号：\u0026lt;?php echo $tag-\u0026gt;term_id; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;名称：\u0026lt;?php echo $tag-\u0026gt;name; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;别名：\u0026lt;?php echo $tag-\u0026gt;slug; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;描述：\u0026lt;?php echo $tag-\u0026gt;description; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;⽹址：\u0026lt;?php echo get_tag_link($tag); ?\u0026gt;\u0026lt;/p\u0026gt; //获取标签目录下面的文章信息 \u0026lt;?php if( have_posts() ): ?\u0026gt; \u0026lt;?php while( have_posts() ): the_post(); ?\u0026gt; \u0026lt;?php the_author(); //作者名称 ?\u0026gt; \u0026lt;?php the_title(); //标题 ?\u0026gt; \u0026lt;?php the_content(); //正文 ?\u0026gt; \u0026lt;?php echo get_comments_number(); //评论数量 ?\u0026gt; \u0026lt;?php endwhile; ?\u0026gt; \u0026lt;?php endif; ?\u0026gt; Author Archive 作者归档页 1 2 3 4 5 6 7 8 9 //获取作者信息 $author = get_queried_object(); \u0026lt;p\u0026gt;作者用户名：\u0026lt;?php echo $author-\u0026gt;user_login; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;作者ID：\u0026lt;?php echo $author-\u0026gt;ID; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;作者邮箱：\u0026lt;?php echo $author-\u0026gt;user_email; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;作者显示名：\u0026lt;?php echo $author-\u0026gt;user_display; ?\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;作者归档页网址：\u0026lt;?php echo get_the_author_posts_link(); ?\u0026gt;\u0026lt;/p\u0026gt; //获取文章信息同上 Date Archive 日期归档页 1 2 3 4 5 6 7 //日期归档页无法获取get_queried_object //获取日期信息 echo get_the_date(); //可以自定义日期格式 echo get_the_date(\u0026#39;Y-d-m\u0026#39;); //获取文章信息同上 通用获取分类title 1 2 3 4 //直接使用 the_archive_title(); //或者 echo get_the_archive_title(); 搜索结果归档页 1 2 3 4 5 //日期归档页无法获取get_queried_object //获取搜索结果页搜索关键字 $key = get_search_query(); //获取文章信息同上 模板标签所在的文件 模板标签所在的文件，都有一个相同的后缀*-template.php，用于区分模板文件和其他文件。\n总共有9个模板文件：\n1 2 3 4 5 6 7 8 9 wp-includes/general-template.php wp-includes/author-template.php wp-includes/bookmark-template.php wp-includes/category-template.php wp-includes/comment-template.php wp-includes/link-template.php wp-includes/post-template.php wp-includes/post-thumbnail-template.php wp-includes/nav-menu-template.php 条件标签使用举例 1 2 3 4 5 6 7 8 9 \u0026lt;?php if (is_year()) { echo get_the_date(\u0026#39;Y\u0026#39;); } elseif (is_month()) { echo get_the_date(\u0026#39;Y-m\u0026#39;); } elseif (is_day()) { echo get_the_date(\u0026#39;Y-m-d\u0026#39;); } ?\u0026gt; 首页相关条件标签 is_home is_front_page 如果首页采用了默认页面，则：\n1 2 is_home: true is_front_page: true 如果首页设置了指定页面，则：\n1 2 is_home: false is_front_page: true 获取其他信息 获取站点信息 关键函数 1 2 3 4 5 6 7 /** * @see get_bloginfo() For possible `$show` values * @param string $show Optional. Site information to display. Default empty. */ function bloginfo( $show = \u0026#39;\u0026#39; ) { echo get_bloginfo( $show, \u0026#39;display\u0026#39; ); } 通用信息 1 2 3 4 5 6 7 8 9 10 11 //站点标题 get_bloginfo(\u0026#39;name\u0026#39;); get_bloginfo(\u0026#39;blogname\u0026#39;); //站点描述 get_bloginfo(\u0026#39;description\u0026#39;); //站点首页网址，等同于site_url() get_bloginfo(\u0026#39;wpurl\u0026#39;); //站点首页网址，等同于home_url() get_bloginfo(\u0026#39;url\u0026#39;); //站点管理员邮箱 get_bloginfo(\u0026#39;admin_email\u0026#39;); 评论信息 1 2 3 4 5 6 \u0026lt;?php if (comments_open() || get_commments_number()) { //如果文章允许评论被关闭，则只显示历史评论列表，不显示评论发表框 comments_template(); } ?\u0026gt; 主题路径及url信息 1 2 3 4 //获取当前主题所在目录的网址 get_theme_file_uri() //获取当前主题所在目录的绝对路径 get_theme_file_path() 钩子机制 动作钩子 1 add_action(\u0026#39;hook_name\u0026#39;, \u0026#39;your_func\u0026#39;); 过滤器钩子 1 add_filter(\u0026#39;hook_name\u0026#39;, \u0026#39;your_func\u0026#39;); 传统引入css和js文件的方式 内联 1 \u0026lt;div style=\u0026#34;width: 65px;height: 20px;border: 1px solid;\u0026#34;\u0026gt;测试元素\u0026lt;/div\u0026gt; 页联 1 2 3 4 5 6 7 8 \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; div { width: 65px; height: 20px; border: 1px solid; background: greenyellow; } \u0026lt;/style\u0026gt; 外联 1 \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;*.css\u0026#34; /\u0026gt; 推荐的引入css和js文件的方式 引入css文件 1 2 3 4 5 6 7 8 9 /** * 引入css文件 * @param string $handle Name of the stylesheet. Should be unique. * @param string $src * @param string[] $deps * @param string|bool|null $ver * @param string $media */ function wp_enqueue_style( $handle, $src = \u0026#39;\u0026#39;, $deps = array(), $ver = false, $media = \u0026#39;all\u0026#39; ) 引入js文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /** * 引入js文件 wp 6.3.0版本之后，$in_footer参数改成了$args * @since 6.3.0 The $in_footer parameter of type boolean was overloaded to be an $args parameter of type array. * @param string $handle Name of the script. Should be unique. * @param string $src Default empty. * @param string[] $deps * @param string|bool|null $ver * @param array|bool $args { * Optional. An array of additional script loading strategies. Default empty array. * Otherwise, it may be a boolean in which case it determines whether the script is printed in the footer. Default false. * * @type string $strategy Optional. If provided, may be either \u0026#39;defer\u0026#39; or \u0026#39;async\u0026#39;. * @type bool $in_footer Optional. Whether to print the script in the footer. Default \u0026#39;false\u0026#39;. * } */ function wp_enqueue_script( $handle, $src = \u0026#39;\u0026#39;, $deps = array(), $ver = false, $args = array() ) 使用案例 1 2 3 4 add_action(\u0026#39;wp_enqueue_scripts\u0026#39;, function () { wp_enqueue_style(\u0026#39;common-style\u0026#39;, get_theme_file_uri() . \u0026#39;/css/commom.css\u0026#39;); wp_enqueue_script(\u0026#39;commmon-js\u0026#39;, get_theme_file_uri() . \u0026#39;/js/common.js\u0026#39;, array(), \u0026#39;\u0026#39;, true); }) 模板文件拆分和引入 传统的引入方式 1 2 3 include \u0026#39;template-part.php\u0026#39;; //or require \u0026#39;template-part.php\u0026#39;; wp推荐方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 //加载任意模板文件 get_template_part(\u0026#39;template-part\u0026#39;); //加载主题中header.php or header-$name.php get_header($name = \u0026#39;\u0026#39;) //加载主题中footer.php or footer-$name.php get_footer($name = \u0026#39;\u0026#39;) //加载主题中sidebar.php or sidebar-$name.php get_sidebar($name = \u0026#39;\u0026#39;) 分页导航 内容分页 1 2 3 //1.手动插入分页符 //2.通过wp_link_pages()显示页码 wp_link_pages(); 关联分页 获取上一篇文章链接 1 2 3 4 5 6 7 8 9 10 11 12 /** * @see get_previous_post_link() * * @param string $format Optional. Link anchor format. Default \u0026#39;\u0026amp;laquo; %link\u0026#39;. * @param string $link Optional. Link permalink format. Default \u0026#39;%title\u0026#39;. * @param bool $in_same_term Optional. Whether link should be in the same taxonomy term. * Default false. * @param int[]|string $excluded_terms Optional. Array or comma-separated list of excluded term IDs. * Default empty. * @param string $taxonomy Optional. Taxonomy, if `$in_same_term` is true. Default \u0026#39;category\u0026#39;. */ function previous_post_link( $format = \u0026#39;\u0026amp;laquo; %link\u0026#39;, $link = \u0026#39;%title\u0026#39;, $in_same_term = false, $excluded_terms = \u0026#39;\u0026#39;, $taxonomy = \u0026#39;category\u0026#39; ) 获取下一篇文章链接 1 2 3 4 5 6 7 8 9 10 11 12 /** * @see get_next_post_link() * * @param string $format Optional. Link anchor format. Default \u0026#39;\u0026amp;laquo; %link\u0026#39;. * @param string $link Optional. Link permalink format. Default \u0026#39;%title\u0026#39;. * @param bool $in_same_term Optional. Whether link should be in the same taxonomy term. * Default false. * @param int[]|string $excluded_terms Optional. Array or comma-separated list of excluded term IDs. * Default empty. * @param string $taxonomy Optional. Taxonomy, if `$in_same_term` is true. Default \u0026#39;category\u0026#39;. */ function next_post_link( $format = \u0026#39;%link \u0026amp;raquo;\u0026#39;, $link = \u0026#39;%title\u0026#39;, $in_same_term = false, $excluded_terms = \u0026#39;\u0026#39;, $taxonomy = \u0026#39;category\u0026#39; ) 使用举例 1 2 3 4 5 6 7 8 9 \u0026lt;?php if (have_posts()) :?\u0026gt; \u0026lt;?php while (have_posts()) : the_post(); ?\u0026gt; \u0026lt;?php the_content(); ?\u0026gt; \u0026lt;?php wp_link_pages(); ?\u0026gt; \u0026lt;?php endwhile; ?\u0026gt; \u0026lt;?php endif; ?\u0026gt; \u0026lt;?php previous_post_link(\u0026#39;上⼀篇：%link\u0026#39;); ?\u0026gt; \u0026lt;?php next_post_link(\u0026#39;下⼀篇：%link\u0026#39;); ?\u0026gt; 列表分页 简单分页 1 2 3 4 5 6 7 8 9 10 \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;分别获取上⼀⻚和下⼀⻚的链接\u0026lt;/p\u0026gt; \u0026lt;?php previous_posts_link(); ?\u0026gt; \u0026lt;?php next_posts_link(); ?\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;同时获取上下⻚的链接\u0026lt;/p\u0026gt; \u0026lt;?php posts_nav_link(); ?\u0026gt; \u0026lt;/div\u0026gt; 数字分页 1 2 3 4 5 6 7 \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;推荐的数字分⻚函数执⾏的效果\u0026lt;/p\u0026gt; \u0026lt;?php the_posts_pagination(); ?\u0026gt; \u0026lt;/div\u0026gt; //wp 4.1之前的方式 \u0026lt;?php echo paginate_links(); ?\u0026gt; 开启自动生成页面标题功能 1 2 3 4 5 add_action(\u0026#39;after_setup_theme\u0026#39;, function () { add_theme_support(\u0026#39;title-tag\u0026#39;); }); //通过wp_head();触发显示 导航菜单功能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 //1.主题的functions.php中注册菜单 add_action(\u0026#39;after_setup_theme\u0026#39;, function () { //注册导航菜单，用于关联后台设置的菜单，这里nav-1相当于一个标识符，和前台wp_nav_menu的theme_location对应 register_nav_menus([ \u0026#39;nav-1\u0026#39; =\u0026gt; \u0026#39;顶部导航\u0026#39; ]); }) //2.前台显示菜单 \u0026lt;?php wp_nav_menu([ \u0026#39;theme_location\u0026#39; =\u0026gt; \u0026#39;nav-1\u0026#39; ]); ?\u0026gt; wp_nav_menu详细参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $defaults = array( \u0026#39;theme_location\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //调⽤菜单的名称，名称是你⾃⼰注册菜单的时候⾃定义的 \u0026#39;menu\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //使⽤导航菜单的名称调⽤菜单，可以是 ID、别名和名字（按顺序匹配） \u0026#39;container\u0026#39; =\u0026gt; \u0026#39;div\u0026#39;, //最外层容器的标签，只⽀持 div 和 nav 标签 \u0026#39;container_class\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //外层容器的class \u0026#39;container_id\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //外层容器的 ID \u0026#39;menu_class\u0026#39; =\u0026gt; \u0026#39;menu\u0026#39;, //ul ⽗节点的 class 属性 \u0026#39;menu_id\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //ul ⽗节点的 id 属性 \u0026#39;echo\u0026#39; =\u0026gt; true, //布尔值，是否输出菜单，为false是可以⽤于赋值 \u0026#39;fallback_cb\u0026#39; =\u0026gt; \u0026#39;wp_page_menu\u0026#39;, //当前设置的菜单不存在时，显⽰此处设置的菜单 \u0026#39;before\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //显⽰在每个菜单链接前的⽂本 \u0026#39;after\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //显⽰在每个菜单链接后的⽂本 \u0026#39;link_before\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //显⽰在每个菜单链接⽂本前的⽂本 \u0026#39;link_after\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, //显⽰在每个菜单链接⽂本后的⽂本 \u0026#39;items_wrap\u0026#39; =\u0026gt; \u0026#39;\u0026lt;ul class=\u0026#34;%1$s\u0026#34; id=\u0026#34;%2$s\u0026#34;\u0026gt;%3$s \u0026lt;/ul\u0026gt;\u0026#39;, //菜单的输出结构， \u0026#39;depth\u0026#39; =\u0026gt; 0, //显⽰菜单深度，0为显⽰所有 \u0026#39;walker\u0026#39; =\u0026gt; \u0026#39;\u0026#39; //菜单的结构对象 通过改参数可以制作任意结构的导航菜单 ); wp_nav_menu( $defaults); 边栏工具功能 开启边栏工具 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 add_action(\u0026#39;widgets_init\u0026#39;, function () { register_sidebar([ \u0026#39;name\u0026#39; =\u0026gt; \u0026#39;边栏1\u0026#39;, //⼩⼯具的区域名称，默认是 \u0026#39;sidebar\u0026#39; 加 数字 ID,如：sidebar-1 \u0026#39;id\u0026#39;=\u0026gt; \u0026#39;footer_area_one\u0026#39;, //区域的ID，默认是⼀个⾃动递增的数字 ID \u0026#39;description\u0026#39;=\u0026gt; \u0026#39;第1个边栏\u0026#39;, //区域的描述，默认为空 \u0026#39;before_widget\u0026#39; =\u0026gt; \u0026#39;\u0026lt;section id=\u0026#34;%1$s\u0026#34; class=\u0026#34;%2$s widget\u0026#34;\u0026gt;\u0026#39;, //区域的内容前的HTML代码，默认： \u0026#39;\u0026#39;） \u0026#39;after_widget\u0026#39;=\u0026gt; \u0026#39;\u0026#39;, //区域内容后的HTML代码，默认： \u0026#34;\\n\u0026#34; \u0026#39;before_title\u0026#39;=\u0026gt; \u0026#39;\u0026#39;, //区域标题前的HTML代码，默认： \u0026#39;after_title\u0026#39;=\u0026gt; \u0026#39;\u0026#39;, //区域标题后的HTML代码，默认：\u0026#34;\\n\u0026#34; ]); }); 前台显示指定边栏 1 2 3 \u0026lt;ul class=\u0026#34;sidebar\u0026#34;\u0026gt; \u0026lt;?php dynamic_sidebar(\u0026#39;sidebar-1\u0026#39;); //通过id获取指定边栏信息 ?\u0026gt; \u0026lt;/ul\u0026gt; 判断边栏内是否包含小工具 is_active_sidebar() 1 2 3 4 5 \u0026lt;?php if(is_active_sidebar(\u0026#39;left-sidebar\u0026#39;)):?\u0026gt; \u0026lt;ul class=\u0026#34;sidebar\u0026#34;\u0026gt; \u0026lt;?php dynamic_sidebar(\u0026#39;left-sidebar\u0026#39;); ?\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;?php endif;?\u0026gt; 特色图像功能 开启特色图像 1 2 3 add_action(\u0026#39;after_setup_theme\u0026#39;, function () { add_theme_support(\u0026#39;post-thumbnails\u0026#39;); }); 获取特色图像 1 2 3 4 5 6 7 8 9 10 11 /** * @see get_the_post_thumbnail() * * @param string|int[] $size Default \u0026#39;post-thumbnail\u0026#39;. * 系统内置的$size有 thumbnail：缩略图; meduim：中图; large：大图; full：原图 * 如果$size的尺寸找不到，则显示full原图. * @param string|array $attr Optional. Query string or array of attributes. Default empty. */ function the_post_thumbnail( $size = \u0026#39;post-thumbnail\u0026#39;, $attr = \u0026#39;\u0026#39; ) { echo get_the_post_thumbnail( null, $size, $attr ); } 定义更多图像尺寸 1 2 3 4 5 6 7 8 9 add_action(\u0026#39;after_setup_theme\u0026#39;, function () { add_theme_support(\u0026#39;post-thumbnails\u0026#39;); //post-thumbnail尺寸默认是不存在的，可以通过代码设置 set_post_thumbnail_size(100, 100, true); //新增自定义尺寸 add_image_size(\u0026#39;category-thumbnail\u0026#39;, 50, 50); }); 常用函数 1 2 3 4 5 6 7 8 9 10 11 //获取图片说明信息 the_post_thumbnail_caption(); //判断文章是否包含特色图片 has_post_thumbnail(); //获取特色图像id get_the_post_thumbnail_id(); //获取特色图像链接 get_the_post_thumbnail_url(); 自定义栏目功能 后台设置 获取自定义栏目信息 1 2 3 4 5 6 7 8 9 10 11 /** * @param int $post_id Post ID. * @param string $key Optional. The meta key to retrieve. By default, * returns data for all keys. Default empty. * @param bool $single Optional. Whether to return a single value. * This parameter has no effect if `$key` is not specified. * Default false. */ function get_post_meta( $post_id, $key = \u0026#39;\u0026#39;, $single = false ) { return get_metadata( \u0026#39;post\u0026#39;, $post_id, $key, $single ); } 使用示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;?php if( have_posts() ): ?\u0026gt; \u0026lt;?php while( have_posts() ): the_post(); ?\u0026gt; \u0026lt;div\u0026gt; \u0026lt;strong\u0026gt;⽂章相册信息（⾃定义的）：get_post_meta\u0026lt;/strong\u0026gt; \u0026lt;?php print_r( get_post_meta( get_the_ID(), \u0026#39;gallary_img\u0026#39;, false ) ); ?\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;strong\u0026gt;⽂章价格信息（⾃定义的）：get_post_meta\u0026lt;/strong\u0026gt; \u0026lt;strong\u0026gt;因为价格信息就1个值，通过第3个个参数可以直接获取到值\u0026lt;/strong\u0026gt; \u0026lt;?php print_r( get_post_meta( get_the_ID(), \u0026#39;price\u0026#39;, true ) ); ?\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;strong\u0026gt;⽂章价格信息（⾃定义的）：get_post_meta\u0026lt;/strong\u0026gt; \u0026lt;?php print_r( get_post_meta( get_the_ID(), \u0026#39;price\u0026#39; ) ); ?\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;?php endwhile; ?\u0026gt; \u0026lt;?php endif; ?\u0026gt; 通过代码设置 添加add_post_meta 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * @param int $post_id Post ID. * @param string $meta_key Metadata name. * @param mixed $meta_value Metadata value. Must be serializable if non-scalar. * @param bool $unique Optional. Whether the same key should not be added. * Default false. * @return int|false Meta ID on success, false on failure. */ function add_post_meta( $post_id, $meta_key, $meta_value, $unique = false ) { // Make sure meta is added to the post, not a revision. $the_post = wp_is_post_revision( $post_id ); if ( $the_post ) { $post_id = $the_post; } return add_metadata( \u0026#39;post\u0026#39;, $post_id, $meta_key, $meta_value, $unique ); } 更新update_post_meta，不存在则新增 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * @param int $post_id Post ID. * @param string $meta_key Metadata key. * @param mixed $meta_value Metadata value. Must be serializable if non-scalar. * @param mixed $prev_value Optional. Previous value to check before updating. * If specified, only update existing metadata entries with * this value. Otherwise, update all entries. Default empty. * @return int|bool Meta ID if the key didn\u0026#39;t exist, true on successful update, * false on failure or if the value passed to the function * is the same as the one that is already in the database. */ function update_post_meta( $post_id, $meta_key, $meta_value, $prev_value = \u0026#39;\u0026#39; ) { // Make sure meta is updated for the post, not for a revision. $the_post = wp_is_post_revision( $post_id ); if ( $the_post ) { $post_id = $the_post; } return update_metadata( \u0026#39;post\u0026#39;, $post_id, $meta_key, $meta_value, $prev_value ); } 删除delete_post_meta 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * @param int $post_id Post ID. * @param string $meta_key Metadata name. * @param mixed $meta_value Optional. Metadata value. If provided, * rows will only be removed that match the value. * Must be serializable if non-scalar. Default empty. * @return bool True on success, false on failure. */ function delete_post_meta( $post_id, $meta_key, $meta_value = \u0026#39;\u0026#39; ) { // Make sure meta is deleted from the post, not from a revision. $the_post = wp_is_post_revision( $post_id ); if ( $the_post ) { $post_id = $the_post; } return delete_metadata( \u0026#39;post\u0026#39;, $post_id, $meta_key, $meta_value ); } 隐藏的自定义栏目，后台无法设置 1 2 3 //下滑线开头的字段，后台不展示，用户无法设置 add_post_meta($post_id, \u0026#39;_myKey\u0026#39;, \u0026#39;隐藏的值\u0026#39;); get_post_meta($post_id, \u0026#39;_mykey\u0026#39;, true); 常用功能 设置浏览次数 定义函数 通过 隐藏的(下划线开头的key)自定义栏目实现浏览次数。functions.php中定义以下函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 设置⽂章/⻚⾯ 浏览次数 * _wphollis_postviews是⾃定义栏⽬的名字 * @param int $post_id ⽂章的ID编号 */ function wphollis_set_postviews($post_id) { // 详情⻚才处理 if ( is_singular() \u0026amp;\u0026amp; ! empty( $post_id ) ) { $views = get_post_meta($post_id, \u0026#39;_wphollis_postviews\u0026#39;, true); $views = ! empty( $views ) ? $views : 0; $views++; update_post_meta($post_id, \u0026#39;_wphollis_postviews\u0026#39;, $views); } } /** * 获取⽂章/⻚⾯ 浏览次数 * @param int ⽂章的ID编号 * @return int 浏览次数 */ function wphollis_get_postviews( $post_id ) { if ( ! empty( $post_id ) ) { $views = get_post_meta($post_id, \u0026#39;_wphollis_postviews\u0026#39;, true); $views = ! empty( $views ) ? (int)$views : 0; return $views; } } 前台使用 （在内容详情页中添加以下代码） 1 2 3 4 5 6 7 8 \u0026lt;?php wphollis_set_postviews(get_queried_object_id());//更新文章浏览次数 ?\u0026gt; \u0026lt;?php if (have_posts()) :?\u0026gt; \u0026lt;?php while (have_posts()) : the_post(); ?\u0026gt; \u0026lt;?php the_title(); ?\u0026gt; \u0026lt;?php wphollis_get_postviews(get_the_ID());//获取文章浏览次数 ?\u0026gt; \u0026lt;?php endwhile; ?\u0026gt; \u0026lt;?php endif; ?\u0026gt; 获取当前用户访问的网页网址 在当前主题functions.php文件中定义以下函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * 获取⽤⼾当前访问的⽹址 */ function wphollis_get_current_url() { global $wp, $wp_rewrite; // 获取重写规则，朴素模式规则为空 $rewrite = $wp_rewrite-\u0026gt;wp_rewrite_rules(); // ⾮朴素模式下，返回当前⽹址 if ( !empty($rewrite) ) { return home_url( $wp-\u0026gt;request ); } // 在朴素模式下，返回当前⽹址 return home_url( \u0026#39;?\u0026#39; . $wp-\u0026gt;query_string ); } 正文自动截取 在当前主题functions.php文件中定义以下函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /** * @params $len 要截取的字符长度 * @params $suffix 后缀标记 * */ function hollis_strim_post_content($len = 100, $suffix = \u0026#39;...\u0026#39;) { //获取正文信息，并做必要处理 $content = get_the_content(); //这里触发the_content的钩子，执行挂载该钩子的所有方法 //这里不写这个语句也可以，但是为了兼容wp的扩展性要求加上 $content = apply_filters(\u0026#39;the_content\u0026#39;, $content); $content = str_replace(\u0026#39;]]\u0026gt;\u0026#39;, \u0026#39;]]\u0026amp;gt;\u0026#39;, $content); //去除正文中的HTML标签 $content = strip_tags($content); if (mb_strlen($content) \u0026lt;= $len) { //字符数量少于要截取的长度，则展示全部 return $content; } else { return $content = mb_substr($content, 0, $len) . $suffix; } } 给嵌套评论添加回复关系信息 原理就是通过get_comment_author_link钩子，把评论者的link扩展成带回复关系的两个link\n在当前主题functions.php文件中定义以下函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /** * 增加谁回复谁 * 所有⽤到的钩⼦信息⸺ * apply_filters( \u0026#39;get_comment_author_link\u0026#39;, $return, $author, $comment-\u0026gt;comment_ID ); * @param string $out 未修改的评论数据，即wordpress默认提供的数据 * @param int $comment_id 评论的编号 * @return string */ function wphollis_who_resp_who($out, $author, $comment_id) { $comment = get_comment($comment_id); // 如果没有⽗级评论，则正常返回，因为没有回复关系 if ( empty($comment-\u0026gt;comment_parent) ) { return $out; } /** * 如果有⽗级评论，则添加回复关系 */ // 获取⽗（原）评论 $parent = get_comment($comment-\u0026gt;comment_parent); // 获取⽗（原）评论作者 $pauthor = get_comment_author($parent); // 构件回复关系 $pcid = \u0026#39;#comment-\u0026#39; . $parent-\u0026gt;comment_ID; $new = $out . \u0026#39; 回复 \u0026#39;. \u0026#34;\u0026lt;a href=\u0026#39;{$pcid}\u0026#39;\u0026gt;{$pauthor}\u0026lt;/a\u0026gt;\u0026#34;; // 返回修改后的评论数据 return $new; } add_filter(\u0026#39;get_comment_author_link\u0026#39;, \u0026#39;wphollis_who_resp_who\u0026#39;, 10, 3); 解决评论模板notice提示 调用comments_template()方法的时候，wp会优先查找当前主题下有没有comments.php文件，如果没有则采用wp自带的模板wp-includes/theme-compat/comments.php\n修改菜单输出结构 添加并定义⼀个⾃定义函数⽂件（名称随意）：class-my-nav-walker.php 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class wphollis_Nav_Walker extends Walker_Nav_Menu { /** * 修改⼆级菜单 */ public function end_lvl( \u0026amp;$output, $depth = 0, $args = array() ) { if ( isset( $args-\u0026gt;item_spacing ) \u0026amp;\u0026amp; \u0026#39;discard\u0026#39; === $args-\u0026gt;item_spacing ) { $t = \u0026#39;\u0026#39;; $n = \u0026#39;\u0026#39;; } else { $t = \u0026#34;\\t\u0026#34;; $n = \u0026#34;\\n\u0026#34;; } $indent = str_repeat( $t, $depth ); $suffix = \u0026#39;\u0026lt;span class=\u0026#34;fa fa-angle-down\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026#39;; // 添加的按钮对应的HTML $output .= \u0026#34;$indent\u0026lt;/ul\u0026gt;{$suffix}{$n}\u0026#34;; } } 在funcitons.php中加载这个类 1 2 3 add_action(\u0026#39;after_setup_theme\u0026#39;, function () { include get_theme_file_path() . \u0026#39;/inc/class-my-nav-walker.php\u0026#39;; }); 前台页面中调用菜单 1 2 3 4 5 6 7 \u0026lt;?php wp_nav_menu([ \u0026#39;theme_location\u0026#39; =\u0026gt; \u0026#39;nav-1\u0026#39;, \u0026#39;walker\u0026#39; =\u0026gt; new wphollis_Nav_Walker() ]); ?\u0026gt; 实战案例 导入测试数据 下载好 xml的数据⽂件, 在 后台 ⼯具 \u0026mdash;-\u0026gt; 导⼊ \u0026mdash;-\u0026gt; WordPress导⼊器安装 \u0026mdash;-\u0026gt; 选择xml⽂件导⼊数\n据\n开启所需功能并引入所需的样式文件 functions.php文件中定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 add_action(\u0026#39;after_setup_theme\u0026#39;, function () { // 开启⻚⾯标题功能 add_theme_support(\u0026#39;title-tag\u0026#39;); // 开启特色图像 add_theme_support(\u0026#39;post-thumbnails\u0026#39;); // 定义导航菜单 register_nav_menus([ \u0026#39;header_menu\u0026#39; =\u0026gt; \u0026#39;顶部导航\u0026#39;, \u0026#39;footer_menu\u0026#39; =\u0026gt; \u0026#39;底部导航\u0026#39;, ]); }); // 定义边栏 add_action(\u0026#39;widgets_init\u0026#39;, function () { register_sidebar([ \u0026#39;name\u0026#39; =\u0026gt; \u0026#39;边栏1\u0026#39;, \u0026#39;id\u0026#39; =\u0026gt; \u0026#39;sidebar1\u0026#39;, \u0026#39;decsription\u0026#39; =\u0026gt; \u0026#39;边栏1\u0026#39;, ]); }); // 引入所需的样式文件 add_action(\u0026#39;wp_enqueue_scripts\u0026#39;, function () { wp_enqueue_style(\u0026#39;main-css\u0026#39;, get_theme_file_uri() . \u0026#39;/main.css\u0026#39;, [], \u0026#39;1.0\u0026#39;); wp_enqueue_script(\u0026#39;main-js\u0026#39;, get_theme_file_uri() . \u0026#39;/main.js\u0026#39;, [], \u0026#39;1.0\u0026#39;); }); 获取登录和注册的URL 注册地址 1 wp_registration_url(); 登录地址 1 wp_login_url(wphollis_get_current_url()); 获取文章作者 1 2 3 4 5 6 7 8 9 10 11 // 获取文章作者归档页。 作者名称+链接 get_the_author_posts_link(); // 获取文章作者归档页url get_author_posts_url(); // 获取作者id get_the_author_meta(\u0026#39;ID\u0026#39;); // 获取用户头像。get_avatar($id_or_email, $size); get_avatar(get_the_author_meta(\u0026#39;ID\u0026#39;), 24); 回复评论，不刷新定位到回复框 在functions.php中添加：\n1 2 3 4 5 //（是否是详情页 \u0026amp;\u0026amp; ⽂章是否开启评论 \u0026amp;\u0026amp; 后台是否开启嵌套评论） // 调取官⽅原⽣回复评论跳转函数 if(is_singular() \u0026amp;\u0026amp; comments_open() \u0026amp;\u0026amp; get_option(\u0026#39;thread_comments\u0026#39;)){ wp_enqueue_script(\u0026#39;comment-reply\u0026#39;); } 设置wp指定的class属性值 在body ⾥⾯设置class属性值 1 \u0026lt;body \u0026lt;?php body_class() ?\u0026gt; \u0026gt; 在article ⾥⾯设置class属性值 1 \u0026lt;article \u0026lt;?php post_class() ?\u0026gt; \u0026gt; 归档页标题调取以及获取文章的缩略图 1 2 3 4 5 6 \u0026lt;!-- 归档页标题 --\u0026gt; \u0026lt;header class=\u0026#34;list-header\u0026#34;\u0026gt; \u0026lt;h1\u0026gt; \u0026lt;span\u0026gt;\u0026lt;?php the_archivce_title(); ?\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/h1\u0026gt; \u0026lt;/header\u0026gt; 1 2 3 4 5 6 7 8 \u0026lt;!-- 获取文章缩略图 --\u0026gt; \u0026lt;a href=\u0026#34;\u0026lt;?php the_permalink() ?\u0026gt;\u0026#34;\u0026gt; \u0026lt;?php if (has_post_thumbnail()) : ?\u0026gt; \u0026lt;?php the_post_thumbnail(\u0026#39;thumbnail\u0026#39;); ?\u0026gt; \u0026lt;?php else : ?\u0026gt; \u0026lt;img src=\u0026#34;\u0026lt;?php echo get_theme_file_uri(); ?\u0026gt;/default.png\u0026#34;\u0026gt; \u0026lt;?php endif; ?\u0026gt; \u0026lt;/a\u0026gt; 首页模板文件开发 1 2 3 4 5 6 7 8 9 \u0026lt;!-- 判断置顶⽂章显⽰ is_sticky()--\u0026gt; \u0026lt;?php if(is_sticky()) :?\u0026gt; \u0026lt;span class=\u0026#34;sticky\u0026#34;\u0026gt;置顶\u0026lt;/span\u0026gt; \u0026lt;?php endif; ?\u0026gt; \u0026lt;!--调取分⻚--\u0026gt; \u0026lt;div class=\u0026#34;posts-nav\u0026#34;\u0026gt; \u0026lt;?php echo the_posts_pagination(); ?\u0026gt; \u0026lt;/div\u0026gt; ","date":"2024-03-23T02:17:45+08:00","permalink":"https://hollisho.github.io/p/wordpress%E4%B8%BB%E9%A2%98%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/","title":"Wordpress主题核心知识点梳理"},{"content":"Rabbitmq 简介 Rabbitmq 是一个开源的消息代理，实现了高级消息队列协议（AMQP）。它具有高可用性、可扩展性和可靠性的特点，被广泛应用于分布式系统、微服务架构、事件驱动的应用程序等场景。\n应用场景 异步处理：将耗时操作异步化，提高系统响应速度。例如，电商平台下单后，订单处理、库存更新、物流通知等操作可以异步进行。\n系统解耦：各个服务之间通过消息队列通信，降低系统间的直接依赖。例如，用户服务和订单服务可以通过RabbitMQ进行通信，而不是直接调用。\n流量削峰：在高并发场景下，通过消息队列缓存请求，平滑处理峰值流量。例如，秒杀系统中，大量的下单请求可以先写入消息队列，然后逐步处理。\n日志处理：收集分布式系统的日志信息，统一处理和分析。例如，多个服务的日志可以发送到RabbitMQ，然后由专门的日志服务进行处理。\n事件驱动架构：基于事件的通信模式，实现系统间的松耦合。例如，用户注册成功后，发送一个事件，触发邮件服务发送欢迎邮件、积分服务发放初始积分等操作。\n实际案例 案例1：电商订单处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 生产者：下单服务 public void createOrder(Order order) { // 保存订单基本信息 orderRepository.save(order); // 发送消息到RabbitMQ OrderMessage message = new OrderMessage(order.getId(), order.getUserId(), order.getItems()); rabbitTemplate.convertAndSend(\u0026#34;order.exchange\u0026#34;, \u0026#34;order.created\u0026#34;, message); return \u0026#34;订单创建成功，订单号：\u0026#34; + order.getId(); } // 消费者：库存服务 @RabbitListener(queues = \u0026#34;order.inventory.queue\u0026#34;) public void processInventory(OrderMessage message) { // 处理库存逻辑 for (OrderItem item : message.getItems()) { inventoryService.reduceStock(item.getProductId(), item.getQuantity()); } } // 消费者：物流服务 @RabbitListener(queues = \u0026#34;order.logistics.queue\u0026#34;) public void processLogistics(OrderMessage message) { // 处理物流逻辑 logisticsService.createShipment(message.getOrderId(), message.getUserId()); } 案例2：用户注册事件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 生产者：用户服务 public void registerUser(User user) { // 保存用户信息 userRepository.save(user); // 发送用户注册事件 UserRegisteredEvent event = new UserRegisteredEvent(user.getId(), user.getEmail(), user.getUsername()); rabbitTemplate.convertAndSend(\u0026#34;user.exchange\u0026#34;, \u0026#34;user.registered\u0026#34;, event); return \u0026#34;注册成功\u0026#34;; } // 消费者：邮件服务 @RabbitListener(queues = \u0026#34;user.email.queue\u0026#34;) public void sendWelcomeEmail(UserRegisteredEvent event) { // 发送欢迎邮件 emailService.sendWelcomeEmail(event.getEmail(), event.getUsername()); } // 消费者：积分服务 @RabbitListener(queues = \u0026#34;user.points.queue\u0026#34;) public void assignInitialPoints(UserRegisteredEvent event) { // 分配初始积分 pointsService.assignPoints(event.getUserId(), 100); // 新用户赠送100积分 } Rabbitmq 架构设计 Rabbitmq 的核心架构包含以下几个关键组件：\nBroker Broker 是 Rabbitmq 集群中的服务器节点，负责接收和处理客户端请求，存储消息数据。每个 Broker 都有一个唯一的 ID，可以独立运行。\n实际应用：在高可用部署中，通常会部署多个Broker节点组成集群，并通过负载均衡器分发客户端连接。例如，一个生产环境可能有3个Broker节点，通过HAProxy进行负载均衡，当一个节点故障时，客户端可以自动连接到其他可用节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # RabbitMQ集群配置示例（Docker Compose） version: \u0026#39;3\u0026#39; services: rabbitmq1: image: rabbitmq:3.9-management hostname: rabbitmq1 environment: - RABBITMQ_ERLANG_COOKIE=SWQOKODSQALRPCLNMEQG ports: - \u0026#34;5672:5672\u0026#34; - \u0026#34;15672:15672\u0026#34; rabbitmq2: image: rabbitmq:3.9-management hostname: rabbitmq2 environment: - RABBITMQ_ERLANG_COOKIE=SWQOKODSQALRPCLNMEQG depends_on: - rabbitmq1 rabbitmq3: image: rabbitmq:3.9-management hostname: rabbitmq3 environment: - RABBITMQ_ERLANG_COOKIE=SWQOKODSQALRPCLNMEQG depends_on: - rabbitmq1 Producer Producer 是消息生产者，负责将消息发送到 Rabbitmq 集群中的特定 Exchange。Producer 可以选择同步或异步的方式发送消息。\n实际应用：生产者通常是业务系统中的一部分，负责在特定业务事件发生时发送消息。例如，支付服务在用户完成支付后，发送支付成功消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // Spring Boot中的Producer示例 @Service public class PaymentService { @Autowired private RabbitTemplate rabbitTemplate; public void processPayment(Payment payment) { // 处理支付逻辑 paymentRepository.save(payment); // 发送支付成功消息 PaymentCompletedEvent event = new PaymentCompletedEvent( payment.getId(), payment.getOrderId(), payment.getAmount(), payment.getTimestamp() ); // 同步发送 rabbitTemplate.convertAndSend(\u0026#34;payment.exchange\u0026#34;, \u0026#34;payment.completed\u0026#34;, event); // 异步发送（带确认回调） rabbitTemplate.convertAndSend(\u0026#34;payment.exchange\u0026#34;, \u0026#34;payment.completed\u0026#34;, event, new CorrelationData(payment.getId())); } // 确认回调 @Bean public RabbitTemplate.ConfirmCallback confirmCallback() { return (correlationData, ack, cause) -\u0026gt; { if (ack) { log.info(\u0026#34;消息发送成功: {}\u0026#34;, correlationData.getId()); } else { log.error(\u0026#34;消息发送失败: {}, 原因: {}\u0026#34;, correlationData.getId(), cause); // 处理失败逻辑，如重试或记录日志 } }; } } Consumer Consumer 是消息消费者，负责从 Rabbitmq 集群中消费消息。Consumer 可以选择手动确认或自动确认消息。\n实际应用：消费者通常是独立的服务或进程，专门处理特定类型的消息。例如，通知服务可以消费各种需要发送通知的事件消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // Spring Boot中的Consumer示例 @Service public class NotificationService { @Autowired private EmailService emailService; @Autowired private SmsService smsService; // 自动确认模式 @RabbitListener(queues = \u0026#34;notification.email.queue\u0026#34;) public void processEmailNotification(NotificationEvent event) { try { emailService.sendEmail(event.getRecipient(), event.getSubject(), event.getContent()); log.info(\u0026#34;邮件发送成功: {}\u0026#34;, event.getId()); } catch (Exception e) { log.error(\u0026#34;邮件发送失败: {}\u0026#34;, event.getId(), e); // 自动确认模式下，即使处理失败，消息也会被确认 // 可以将失败消息记录到数据库，后续重试 } } // 手动确认模式 @RabbitListener(queues = \u0026#34;notification.sms.queue\u0026#34;, ackMode = \u0026#34;MANUAL\u0026#34;) public void processSmsNotification(NotificationEvent event, Channel channel, @Header(AmqpHeaders.DELIVERY_TAG) long tag) { try { smsService.sendSms(event.getRecipient(), event.getContent()); log.info(\u0026#34;短信发送成功: {}\u0026#34;, event.getId()); // 手动确认消息 channel.basicAck(tag, false); } catch (Exception e) { log.error(\u0026#34;短信发送失败: {}\u0026#34;, event.getId(), e); try { // 消息重新入队 channel.basicNack(tag, false, true); } catch (IOException ex) { log.error(\u0026#34;消息拒绝失败\u0026#34;, ex); } } } } Exchange Exchange 是消息路由和转发的组件，根据消息的路由键（Routing Key）将消息转发到一个或多个 Queue。常见的 Exchange 类型包括 Direct、Topic、Fanout 等。\n实际应用：不同类型的Exchange适用于不同的消息分发场景。例如，在微服务架构中，可以使用Topic Exchange根据消息的不同属性将其路由到不同的服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 // Spring Boot中配置不同类型的Exchange @Configuration public class RabbitMQConfig { // Direct Exchange配置 @Bean public DirectExchange orderDirectExchange() { return new DirectExchange(\u0026#34;order.direct\u0026#34;); } @Bean public Queue orderProcessQueue() { return new Queue(\u0026#34;order.process\u0026#34;); } @Bean public Binding orderProcessBinding(Queue orderProcessQueue, DirectExchange orderDirectExchange) { return BindingBuilder.bind(orderProcessQueue).to(orderDirectExchange).with(\u0026#34;order.new\u0026#34;); } // Topic Exchange配置 @Bean public TopicExchange notificationTopicExchange() { return new TopicExchange(\u0026#34;notification.topic\u0026#34;); } @Bean public Queue emailNotificationQueue() { return new Queue(\u0026#34;notification.email\u0026#34;); } @Bean public Queue smsNotificationQueue() { return new Queue(\u0026#34;notification.sms\u0026#34;); } @Bean public Binding emailNotificationBinding(Queue emailNotificationQueue, TopicExchange notificationTopicExchange) { // 匹配所有email相关的通知 return BindingBuilder.bind(emailNotificationQueue).to(notificationTopicExchange).with(\u0026#34;notification.*.email\u0026#34;); } @Bean public Binding smsNotificationBinding(Queue smsNotificationQueue, TopicExchange notificationTopicExchange) { // 匹配所有sms相关的通知 return BindingBuilder.bind(smsNotificationQueue).to(notificationTopicExchange).with(\u0026#34;notification.*.sms\u0026#34;); } // Fanout Exchange配置 @Bean public FanoutExchange auditFanoutExchange() { return new FanoutExchange(\u0026#34;audit.fanout\u0026#34;); } @Bean public Queue auditLogQueue() { return new Queue(\u0026#34;audit.log\u0026#34;); } @Bean public Queue auditArchiveQueue() { return new Queue(\u0026#34;audit.archive\u0026#34;); } @Bean public Binding auditLogBinding(Queue auditLogQueue, FanoutExchange auditFanoutExchange) { return BindingBuilder.bind(auditLogQueue).to(auditFanoutExchange); } @Bean public Binding auditArchiveBinding(Queue auditArchiveQueue, FanoutExchange auditFanoutExchange) { return BindingBuilder.bind(auditArchiveQueue).to(auditFanoutExchange); } } Queue Queue 是消息存储的组件，用于存储消息数据。每个 Queue 都有一个唯一的名称，可以绑定多个 Exchange。\n实际应用：队列可以配置多种属性以满足不同的业务需求，如持久化、消息TTL、死信队列等。例如，对于重要的业务消息，可以配置持久化队列和死信队列，确保消息不会丢失。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // 队列配置示例 @Configuration public class QueueConfig { // 普通队列 @Bean public Queue standardQueue() { return new Queue(\u0026#34;standard.queue\u0026#34;, true); // 第二个参数为true表示持久化 } // 带TTL的队列（消息过期时间） @Bean public Queue ttlQueue() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;x-message-ttl\u0026#34;, 60000); // 消息60秒后过期 return new Queue(\u0026#34;ttl.queue\u0026#34;, true, false, false, args); } // 死信队列配置 @Bean public DirectExchange deadLetterExchange() { return new DirectExchange(\u0026#34;dead.letter.exchange\u0026#34;); } @Bean public Queue deadLetterQueue() { return new Queue(\u0026#34;dead.letter.queue\u0026#34;, true); } @Bean public Binding deadLetterBinding() { return BindingBuilder.bind(deadLetterQueue()).to(deadLetterExchange()).with(\u0026#34;dead.letter\u0026#34;); } // 主队列（配置死信交换机） @Bean public Queue mainQueue() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;x-dead-letter-exchange\u0026#34;, \u0026#34;dead.letter.exchange\u0026#34;); args.put(\u0026#34;x-dead-letter-routing-key\u0026#34;, \u0026#34;dead.letter\u0026#34;); args.put(\u0026#34;x-message-ttl\u0026#34;, 30000); // 30秒未消费则进入死信队列 return new Queue(\u0026#34;main.queue\u0026#34;, true, false, false, args); } } Rabbitmq 消息模型 Rabbitmq 消息模型主要包括以下几个部分：\n消息 消息是 Rabbitmq 中最小的传输单元，包含消息头和消息体。消息头包含消息的元数据信息，如消息的路由键、消息的优先级等。消息体包含实际的数据内容。\n消息队列 消息队列是 Rabbitmq 中消息的存储和转发组件。每个消息队列都有一个唯一的名称，可以绑定多个 Exchange。消息队列可以设置为持久化或非持久化，以保证消息的可靠性。\n消息路由 消息路由是 Rabbitmq 中消息的转发组件。根据消息的路由键，消息会被转发到一个或多个 Queue。消息路由可以设置为直接路由、通配符路由、主题路由等。\n消息确认 消息确认是 Rabbitmq 中消息的确认机制。当消息被消费者消费后，消费者需要向 Rabbitmq 发送确认消息，以保证消息的可靠性。\nRabbitmq 如何保证消息的可靠性 Rabbitmq 如何保证消息的可靠性主要包括以下几个方面：\n消息持久化 Rabbitmq 可以将消息持久化到磁盘上，以保证消息的可靠性。当 Broker 重启后，消息不会丢失。\n实际应用：对于重要的业务消息，如订单、支付等，通常需要配置消息持久化，确保系统故障后消息不会丢失。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // 消息持久化配置示例 @Configuration public class RabbitPersistenceConfig { // 1. 配置持久化的交换机 @Bean public DirectExchange persistentExchange() { return new DirectExchange(\u0026#34;persistent.exchange\u0026#34;, true, false); // 第二个参数true表示持久化，第三个参数false表示不自动删除 } // 2. 配置持久化的队列 @Bean public Queue persistentQueue() { return new Queue(\u0026#34;persistent.queue\u0026#34;, true); // true表示持久化 } // 3. 绑定关系 @Bean public Binding persistentBinding() { return BindingBuilder.bind(persistentQueue()).to(persistentExchange()).with(\u0026#34;persistent.key\u0026#34;); } // 4. 配置消息属性 @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) { RabbitTemplate template = new RabbitTemplate(connectionFactory); // 设置消息属性 template.setMessageConverter(new Jackson2JsonMessageConverter()); template.setMandatory(true); // 开启强制性标志 // 设置消息持久化 template.setBeforePublishPostProcessors(message -\u0026gt; { MessageProperties props = message.getMessageProperties(); props.setDeliveryMode(MessageDeliveryMode.PERSISTENT); // 设置消息持久化 return message; }); return template; } } 持久化的三个层面：\nExchange持久化：交换机持久化，重启后交换机不会丢失 Queue持久化：队列持久化，重启后队列不会丢失 Message持久化：消息持久化，重启后消息不会丢失（需要设置消息的delivery_mode=2） 消息确认 Rabbitmq 可以将消息确认机制设置为手动确认或自动确认。手动确认可以保证消息的可靠性，自动确认可以提高消息的吞吐量。\n实际应用：在处理重要业务消息时，通常使用手动确认模式，确保消息被正确处理后再确认；对于非关键消息，可以使用自动确认提高处理速度。\n生产者确认机制：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 生产者确认机制配置 @Configuration public class ProducerConfirmConfig { @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) { RabbitTemplate template = new RabbitTemplate(connectionFactory); // 开启发布者确认 template.setConfirmCallback((correlationData, ack, cause) -\u0026gt; { if (ack) { log.info(\u0026#34;消息已成功发送到交换机, id: {}\u0026#34;, correlationData != null ? correlationData.getId() : \u0026#34;\u0026#34;); } else { log.error(\u0026#34;消息发送到交换机失败, id: {}, 原因: {}\u0026#34;, correlationData != null ? correlationData.getId() : \u0026#34;\u0026#34;, cause); // 处理失败逻辑，如重试或记录日志 } }); // 开启发布者返回（消息从交换机路由到队列的确认） template.setReturnsCallback(returned -\u0026gt; { log.error(\u0026#34;消息从交换机路由到队列失败: exchange: {}, routingKey: {}, replyCode: {}, replyText: {}\u0026#34;, returned.getExchange(), returned.getRoutingKey(), returned.getReplyCode(), returned.getReplyText()); // 处理失败逻辑 }); return template; } } 消费者确认机制：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 消费者手动确认示例 @Component public class ManualAckConsumer { @RabbitListener(queues = \u0026#34;manual.ack.queue\u0026#34;, ackMode = \u0026#34;MANUAL\u0026#34;) public void receiveMessage(Message message, Channel channel) throws IOException { long deliveryTag = message.getMessageProperties().getDeliveryTag(); try { // 处理消息 String content = new String(message.getBody()); log.info(\u0026#34;接收到消息: {}\u0026#34;, content); // 模拟业务处理 processMessage(content); // 手动确认消息 channel.basicAck(deliveryTag, false); } catch (Exception e) { log.error(\u0026#34;处理消息失败\u0026#34;, e); // 判断是否已经重试过 Boolean redelivered = message.getMessageProperties().getRedelivered(); if (redelivered) { log.error(\u0026#34;消息已重试过，拒绝消息: {}\u0026#34;, deliveryTag); // 拒绝消息，不重新入队 channel.basicReject(deliveryTag, false); // 可以将失败消息记录到数据库或发送到死信队列 } else { log.warn(\u0026#34;消息首次处理失败，重新入队: {}\u0026#34;, deliveryTag); // 拒绝消息，重新入队 channel.basicNack(deliveryTag, false, true); } } } private void processMessage(String content) { // 业务处理逻辑 } } 消息重试 Rabbitmq 可以将消息重试机制设置为自动重试或手动重试。自动重试可以保证消息的可靠性，手动重试可以提高消息的可靠性。\n实际应用：在处理可能因为临时网络问题或服务不可用而失败的消息时，可以配置重试机制，提高消息处理的成功率。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 // Spring Boot中配置消息重试 @Configuration public class RetryConfig { // 配置重试策略 @Bean public RetryOperationsInterceptor retryOperationsInterceptor() { return RetryInterceptorBuilder.stateless() .maxAttempts(3) // 最大重试次数（包括第一次） .backOffOptions(1000, 2.0, 10000) // 初始间隔、乘数、最大间隔 .recoverer(new RejectAndDontRequeueRecoverer()) // 达到最大重试次数后的处理策略 .build(); } // 应用重试拦截器 @Bean public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory( ConnectionFactory connectionFactory, RetryOperationsInterceptor retryOperationsInterceptor) { SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.AUTO); // 配置重试拦截器 Advice[] adviceChain = new Advice[] {retryOperationsInterceptor}; factory.setAdviceChain(adviceChain); return factory; } } // 使用重试机制的消费者 @Component public class RetryableConsumer { @RabbitListener(queues = \u0026#34;retryable.queue\u0026#34;) public void processMessage(String message) { log.info(\u0026#34;处理消息: {}\u0026#34;, message); // 模拟随机失败 if (Math.random() \u0026lt; 0.5) { log.warn(\u0026#34;处理失败，将进行重试\u0026#34;); throw new RuntimeException(\u0026#34;随机失败，触发重试\u0026#34;); } log.info(\u0026#34;处理成功\u0026#34;); } } 自定义重试策略：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 自定义重试策略，根据异常类型决定是否重试 @Bean public RetryOperationsInterceptor customRetryInterceptor() { return RetryInterceptorBuilder.stateless() .retryPolicy(new SimpleRetryPolicy(3, Map.of( TemporaryException.class, true, // 临时异常重试 PermanentException.class, false // 永久异常不重试 ))) .backOffPolicy(new ExponentialBackOffPolicy()) // 指数退避策略 .recoverer((args, cause) -\u0026gt; { // 达到最大重试次数后的处理 String message = new String((byte[]) args.getArguments()[1]); log.error(\u0026#34;消息重试达到最大次数，放入死信队列: {}\u0026#34;, message, cause); // 可以将消息发送到死信队列或记录到数据库 }) .build(); } 消息备份 Rabbitmq 可以将消息备份到多个 Broker 上，以保证消息的可靠性。当某个 Broker 宕机后，消息不会丢失。\n实际应用：在金融、支付等对数据一致性要求高的系统中，通常会部署RabbitMQ集群，并配置镜像队列，确保消息在多个节点间同步。\n1 2 3 4 5 6 7 8 9 10 // 镜像队列配置示例 @Bean public Queue mirroredQueue() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); // 配置镜像策略，all表示所有节点都有完整副本 args.put(\u0026#34;x-ha-policy\u0026#34;, \u0026#34;all\u0026#34;); // 设置镜像队列同步模式 args.put(\u0026#34;x-ha-sync-mode\u0026#34;, \u0026#34;automatic\u0026#34;); return new Queue(\u0026#34;mirrored.queue\u0026#34;, true, false, false, args); } 通过管理命令配置镜像队列：\n1 2 3 4 5 # 为所有队列设置镜像策略 rabbitmqctl set_policy ha-all \u0026#34;.*\u0026#34; \u0026#39;{\u0026#34;ha-mode\u0026#34;:\u0026#34;all\u0026#34;}\u0026#39; --apply-to queues # 为特定队列设置镜像策略 rabbitmqctl set_policy ha-important \u0026#34;^important\\.\u0026#34; \u0026#39;{\u0026#34;ha-mode\u0026#34;:\u0026#34;exactly\u0026#34;,\u0026#34;ha-params\u0026#34;:2,\u0026#34;ha-sync-mode\u0026#34;:\u0026#34;automatic\u0026#34;}\u0026#39; --apply-to queues 集群部署案例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # RabbitMQ集群配置（Kubernetes示例） apiVersion: apps/v1 kind: StatefulSet metadata: name: rabbitmq spec: serviceName: rabbitmq replicas: 3 selector: matchLabels: app: rabbitmq template: metadata: labels: app: rabbitmq spec: containers: - name: rabbitmq image: rabbitmq:3.9-management ports: - containerPort: 5672 - containerPort: 15672 env: - name: RABBITMQ_ERLANG_COOKIE value: \u0026#34;SHARED_SECRET_COOKIE\u0026#34; - name: RABBITMQ_DEFAULT_USER value: \u0026#34;admin\u0026#34; - name: RABBITMQ_DEFAULT_PASS valueFrom: secretKeyRef: name: rabbitmq-secret key: password volumeMounts: - name: data mountPath: /var/lib/rabbitmq volumeClaimTemplates: - metadata: name: data spec: accessModes: [\u0026#34;ReadWriteOnce\u0026#34;] resources: requests: storage: 10Gi Rabbitmq 如何保证消息不被重复消费 Rabbitmq 如何保证消息不被重复消费主要包括以下几个方面：\n消息唯一标识 Rabbitmq 可以为每条消息生成一个唯一的消息 ID，以保证消息的唯一性。\n实际应用：在订单系统中，可以使用订单ID作为消息的唯一标识，确保即使消息被重复消费，也能识别出来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 生产者：设置消息唯一ID public void sendOrderMessage(Order order) { // 创建消息 OrderMessage message = new OrderMessage(order); // 设置消息属性 MessageProperties properties = new MessageProperties(); properties.setMessageId(order.getId()); // 使用订单ID作为消息ID properties.setTimestamp(new Date()); // 设置时间戳 // 发送消息 Message amqpMessage = new Message(objectMapper.writeValueAsBytes(message), properties); rabbitTemplate.send(\u0026#34;order.exchange\u0026#34;, \u0026#34;order.created\u0026#34;, amqpMessage); } 消息状态检查 Rabbitmq 可以将消息的状态存储到数据库中，以保证消息的状态一致性。\n实际应用：在支付系统中，可以将消息处理状态记录到数据库，在消费消息前先检查状态，避免重复处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 消费者：检查消息状态 @RabbitListener(queues = \u0026#34;payment.process.queue\u0026#34;) public void processPayment(Message message) { String messageId = message.getMessageProperties().getMessageId(); // 检查消息是否已处理 if (messageProcessRepository.isProcessed(messageId)) { log.info(\u0026#34;消息已处理，跳过: {}\u0026#34;, messageId); return; } try { // 处理消息 PaymentMessage paymentMessage = objectMapper.readValue(message.getBody(), PaymentMessage.class); paymentService.processPayment(paymentMessage); // 标记消息为已处理 messageProcessRepository.markAsProcessed(messageId); } catch (Exception e) { log.error(\u0026#34;处理支付消息失败\u0026#34;, e); throw e; // 重新抛出异常，触发重试机制 } } 数据库表设计：\n1 2 3 4 5 6 7 8 CREATE TABLE message_process_record ( message_id VARCHAR(50) PRIMARY KEY, process_status VARCHAR(20) NOT NULL, -- PROCESSED, FAILED process_time TIMESTAMP NOT NULL, retry_count INT DEFAULT 0, last_retry_time TIMESTAMP, create_time TIMESTAMP NOT NULL ); 分布式锁 Rabbitmq 可以使用分布式锁机制，以保证消息的一致性。\n实际应用：在高并发场景下，可以使用Redis或Zookeeper实现分布式锁，确保同一时间只有一个消费者处理特定的消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 使用Redis实现分布式锁 @Component public class DistributedLockConsumer { @Autowired private StringRedisTemplate redisTemplate; @Autowired private OrderService orderService; @RabbitListener(queues = \u0026#34;order.payment.queue\u0026#34;) public void processOrderPayment(OrderPaymentMessage message) { String lockKey = \u0026#34;order:payment:lock:\u0026#34; + message.getOrderId(); boolean locked = false; try { // 尝试获取分布式锁，过期时间30秒 locked = redisTemplate.opsForValue().setIfAbsent(lockKey, \u0026#34;1\u0026#34;, 30, TimeUnit.SECONDS); if (locked) { // 获取锁成功，处理订单支付 orderService.processPayment(message.getOrderId(), message.getAmount()); log.info(\u0026#34;订单支付处理成功: {}\u0026#34;, message.getOrderId()); } else { // 获取锁失败，说明消息正在被其他消费者处理 log.info(\u0026#34;订单支付消息正在被处理，跳过: {}\u0026#34;, message.getOrderId()); } } finally { // 释放锁 if (locked) { redisTemplate.delete(lockKey); } } } } 消息幂等性 Rabbitmq 可以实现消息的幂等性，以保证消息的一致性。\n实际应用：在转账系统中，可以通过业务逻辑设计实现幂等性，确保同一笔转账只会执行一次。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 // 幂等性处理示例 @Service public class TransferService { @Autowired private AccountRepository accountRepository; @Autowired private TransferRepository transferRepository; @Transactional public void processTransfer(String transferId, String fromAccount, String toAccount, BigDecimal amount) { // 检查转账记录是否已存在 if (transferRepository.existsById(transferId)) { log.info(\u0026#34;转账已处理，跳过: {}\u0026#34;, transferId); return; } // 执行转账操作 Account from = accountRepository.findById(fromAccount) .orElseThrow(() -\u0026gt; new AccountNotFoundException(fromAccount)); Account to = accountRepository.findById(toAccount) .orElseThrow(() -\u0026gt; new AccountNotFoundException(toAccount)); // 检查余额 if (from.getBalance().compareTo(amount) \u0026lt; 0) { throw new InsufficientBalanceException(fromAccount); } // 更新账户余额 from.setBalance(from.getBalance().subtract(amount)); to.setBalance(to.getBalance().add(amount)); accountRepository.save(from); accountRepository.save(to); // 记录转账流水 Transfer transfer = new Transfer(); transfer.setId(transferId); transfer.setFromAccount(fromAccount); transfer.setToAccount(toAccount); transfer.setAmount(amount); transfer.setStatus(\u0026#34;COMPLETED\u0026#34;); transfer.setCreateTime(new Date()); transferRepository.save(transfer); } } Rabbitmq 如何解决消息积压问题 Rabbitmq 如何解决消息积压问题主要包括以下几个方面：\n增加消费者数量 Rabbitmq 可以增加消费者数量，以提高消息的处理速度。\n实际应用：在电商平台的订单处理系统中，当出现订单峰值（如促销活动）时，可以动态扩展消费者实例数量，提高消息处理能力。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // Spring Boot中配置消费者并发数 @Configuration public class RabbitConsumerConfig { @Bean public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory( ConnectionFactory connectionFactory) { SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setConcurrentConsumers(5); // 初始并发消费者数量 factory.setMaxConcurrentConsumers(20); // 最大并发消费者数量 factory.setPrefetchCount(10); // 每个消费者预取的消息数量 return factory; } } // 在Kubernetes环境中动态扩展消费者Pod数量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 消费者自动扩缩容配置（Kubernetes HPA） apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: order-consumer-hpa spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: order-consumer minReplicas: 3 maxReplicas: 20 metrics: - type: External external: metric: name: rabbitmq_queue_messages selector: matchLabels: queue: order.processing target: type: AverageValue averageValue: 100 # 当每个队列平均消息数超过100时扩容 增加 Broker 数量 Rabbitmq 可以增加 Broker 数量，以提高消息的处理速度。\n实际应用：在大型分布式系统中，可以部署RabbitMQ集群，并根据负载情况动态调整节点数量，提高系统整体吞吐量。\n1 2 3 4 5 6 7 8 # 向现有集群添加新节点 rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster rabbit@rabbit1 rabbitmqctl start_app # 查看集群状态 rabbitmqctl cluster_status 集群负载均衡：\n1 2 3 4 5 6 7 8 9 10 11 12 // 客户端连接工厂配置多个地址 @Bean public ConnectionFactory connectionFactory() { CachingConnectionFactory connectionFactory = new CachingConnectionFactory(); // 配置多个broker地址，实现负载均衡 connectionFactory.setAddresses(\u0026#34;rabbit1:5672,rabbit2:5672,rabbit3:5672\u0026#34;); connectionFactory.setUsername(\u0026#34;guest\u0026#34;); connectionFactory.setPassword(\u0026#34;guest\u0026#34;); // 开启发布确认 connectionFactory.setPublisherConfirms(true); return connectionFactory; } 优化消息路由 Rabbitmq 可以优化消息路由，以提高消息的处理速度。\n实际应用：在复杂业务系统中，可以根据消息类型和优先级设计不同的交换机和队列，实现消息的高效路由和处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 优先级队列配置 @Bean public Queue priorityQueue() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;x-max-priority\u0026#34;, 10); // 设置最大优先级为10 return new Queue(\u0026#34;priority.queue\u0026#34;, true, false, false, args); } // 发送带优先级的消息 public void sendWithPriority(String message, int priority) { MessageProperties properties = new MessageProperties(); properties.setPriority(priority); // 设置消息优先级 Message amqpMessage = new Message(message.getBytes(), properties); rabbitTemplate.send(\u0026#34;priority.exchange\u0026#34;, \u0026#34;priority.key\u0026#34;, amqpMessage); } 消息分片处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // 消息分片处理示例 @Configuration public class ShardingConfig { // 创建多个分片队列 @Bean public List\u0026lt;Queue\u0026gt; shardQueues() { List\u0026lt;Queue\u0026gt; queues = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 4; i++) { queues.add(new Queue(\u0026#34;order.processing.\u0026#34; + i)); } return queues; } // 创建交换机 @Bean public DirectExchange shardExchange() { return new DirectExchange(\u0026#34;order.shard.exchange\u0026#34;); } // 绑定队列到交换机，使用不同的路由键 @Bean public List\u0026lt;Binding\u0026gt; shardBindings(List\u0026lt;Queue\u0026gt; shardQueues, DirectExchange shardExchange) { List\u0026lt;Binding\u0026gt; bindings = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; shardQueues.size(); i++) { bindings.add(BindingBuilder.bind(shardQueues.get(i)) .to(shardExchange).with(\u0026#34;shard.\u0026#34; + i)); } return bindings; } } // 生产者：根据订单ID进行分片路由 public void sendOrderMessage(Order order) { int shardIndex = Math.abs(order.getId().hashCode() % 4); String routingKey = \u0026#34;shard.\u0026#34; + shardIndex; rabbitTemplate.convertAndSend(\u0026#34;order.shard.exchange\u0026#34;, routingKey, order); } 临时队列转储 实际应用：当出现严重消息积压时，可以创建临时队列，将消息快速转储，然后使用更多的消费者并行处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // 消息转储服务 @Service public class MessageDumpService { @Autowired private RabbitAdmin rabbitAdmin; @Autowired private RabbitTemplate rabbitTemplate; public void dumpMessages(String sourceQueue, int dumpCount) { // 创建临时队列 List\u0026lt;String\u0026gt; tempQueues = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; dumpCount; i++) { String queueName = sourceQueue + \u0026#34;.temp.\u0026#34; + i; Queue queue = new Queue(queueName, false, false, true); rabbitAdmin.declareQueue(queue); tempQueues.add(queueName); } // 从源队列获取消息并分发到临时队列 int counter = 0; while (true) { Message message = rabbitTemplate.receive(sourceQueue, 100); if (message == null) { break; // 队列为空，退出循环 } // 将消息发送到临时队列 String tempQueue = tempQueues.get(counter % tempQueues.size()); rabbitTemplate.send(\u0026#34;\u0026#34;, tempQueue, message); counter++; } log.info(\u0026#34;已将{}条消息从{}队列转储到{}个临时队列\u0026#34;, counter, sourceQueue, dumpCount); } } Rabbitmq 交换机类型 Rabbitmq 交换机类型主要包括以下几种：\nDirect Exchange Direct Exchange 是最简单的交换机类型，它根据消息的路由键将消息转发到一个或多个 Queue。\n实际应用：适用于明确知道消息应该发送到哪个队列的场景，如日志系统中根据日志级别路由消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // Direct Exchange配置示例 @Configuration public class DirectExchangeConfig { @Bean public DirectExchange logExchange() { return new DirectExchange(\u0026#34;log.direct\u0026#34;); } @Bean public Queue errorQueue() { return new Queue(\u0026#34;log.error\u0026#34;); } @Bean public Queue warningQueue() { return new Queue(\u0026#34;log.warning\u0026#34;); } @Bean public Queue infoQueue() { return new Queue(\u0026#34;log.info\u0026#34;); } @Bean public Binding errorBinding(Queue errorQueue, DirectExchange logExchange) { return BindingBuilder.bind(errorQueue).to(logExchange).with(\u0026#34;error\u0026#34;); } @Bean public Binding warningBinding(Queue warningQueue, DirectExchange logExchange) { return BindingBuilder.bind(warningQueue).to(logExchange).with(\u0026#34;warning\u0026#34;); } @Bean public Binding infoBinding(Queue infoQueue, DirectExchange logExchange) { return BindingBuilder.bind(infoQueue).to(logExchange).with(\u0026#34;info\u0026#34;); } } // 生产者：发送日志消息 public void sendLog(String level, String message) { LogMessage logMessage = new LogMessage(level, message, new Date()); rabbitTemplate.convertAndSend(\u0026#34;log.direct\u0026#34;, level, logMessage); } // 消费者：处理错误日志 @RabbitListener(queues = \u0026#34;log.error\u0026#34;) public void processErrorLogs(LogMessage message) { log.error(\u0026#34;收到错误日志: {}\u0026#34;, message.getMessage()); // 处理错误日志，如发送告警通知 alertService.sendAlert(message); } 应用场景：\n日志路由：根据日志级别（ERROR、WARNING、INFO）将日志消息路由到不同的处理队列 工作队列：任务分发系统，根据任务类型路由到专门的处理队列 命令处理：根据命令类型将消息路由到对应的命令处理器 Topic Exchange Topic Exchange 是一种多播交换机类型，它根据消息的路由键将消息转发到一个或多个 Queue。Topic Exchange 的路由键支持通配符，* 匹配一个单词，# 匹配零个或多个单词。\n实际应用：适用于消息需要按照多维度分类的场景，如根据地区和业务类型路由消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // Topic Exchange配置示例 @Configuration public class TopicExchangeConfig { @Bean public TopicExchange notificationExchange() { return new TopicExchange(\u0026#34;notification.topic\u0026#34;); } // 按地区分类的队列 @Bean public Queue chinaQueue() { return new Queue(\u0026#34;notification.china\u0026#34;); } @Bean public Queue usaQueue() { return new Queue(\u0026#34;notification.usa\u0026#34;); } // 按业务类型分类的队列 @Bean public Queue orderQueue() { return new Queue(\u0026#34;notification.order\u0026#34;); } @Bean public Queue paymentQueue() { return new Queue(\u0026#34;notification.payment\u0026#34;); } // 绑定关系 @Bean public Binding chinaOrderBinding(Queue chinaQueue, TopicExchange notificationExchange) { // 匹配中国地区的订单消息 return BindingBuilder.bind(chinaQueue).to(notificationExchange).with(\u0026#34;china.order.*\u0026#34;); } @Bean public Binding chinaAllBinding(Queue chinaQueue, TopicExchange notificationExchange) { // 匹配中国地区的所有消息 return BindingBuilder.bind(chinaQueue).to(notificationExchange).with(\u0026#34;china.#\u0026#34;); } @Bean public Binding orderAllBinding(Queue orderQueue, TopicExchange notificationExchange) { // 匹配所有地区的订单消息 return BindingBuilder.bind(orderQueue).to(notificationExchange).with(\u0026#34;*.order.*\u0026#34;); } } // 生产者：发送通知消息 public void sendNotification(String region, String business, String action, String message) { String routingKey = region + \u0026#34;.\u0026#34; + business + \u0026#34;.\u0026#34; + action; NotificationMessage notification = new NotificationMessage(message, new Date()); rabbitTemplate.convertAndSend(\u0026#34;notification.topic\u0026#34;, routingKey, notification); } // 使用示例 sendNotification(\u0026#34;china\u0026#34;, \u0026#34;order\u0026#34;, \u0026#34;created\u0026#34;, \u0026#34;新订单创建通知\u0026#34;); sendNotification(\u0026#34;usa\u0026#34;, \u0026#34;payment\u0026#34;, \u0026#34;completed\u0026#34;, \u0026#34;支付完成通知\u0026#34;); 应用场景：\n多维度消息路由：根据地区、业务类型、操作类型等多个维度路由消息 事件广播：将事件广播给多个关注特定模式的消费者 基于主题的订阅：允许消费者订阅感兴趣的特定主题 Fanout Exchange Fanout Exchange 是一种广播交换机类型，它将消息转发到所有绑定的 Queue，不考虑路由键。\n实际应用：适用于需要将消息广播给多个消费者的场景，如系统公告、配置更新等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // Fanout Exchange配置示例 @Configuration public class FanoutExchangeConfig { @Bean public FanoutExchange systemBroadcastExchange() { return new FanoutExchange(\u0026#34;system.broadcast\u0026#34;); } @Bean public Queue userServiceQueue() { return new Queue(\u0026#34;system.broadcast.user\u0026#34;); } @Bean public Queue orderServiceQueue() { return new Queue(\u0026#34;system.broadcast.order\u0026#34;); } @Bean public Queue inventoryServiceQueue() { return new Queue(\u0026#34;system.broadcast.inventory\u0026#34;); } @Bean public Binding userServiceBinding(Queue userServiceQueue, FanoutExchange systemBroadcastExchange) { return BindingBuilder.bind(userServiceQueue).to(systemBroadcastExchange); } @Bean public Binding orderServiceBinding(Queue orderServiceQueue, FanoutExchange systemBroadcastExchange) { return BindingBuilder.bind(orderServiceQueue).to(systemBroadcastExchange); } @Bean public Binding inventoryServiceBinding(Queue inventoryServiceQueue, FanoutExchange systemBroadcastExchange) { return BindingBuilder.bind(inventoryServiceQueue).to(systemBroadcastExchange); } } // 生产者：广播系统消息 public void broadcastSystemMessage(String message, String type) { SystemMessage systemMessage = new SystemMessage(message, type, new Date()); // 发送到Fanout交换机，路由键被忽略 rabbitTemplate.convertAndSend(\u0026#34;system.broadcast\u0026#34;, \u0026#34;\u0026#34;, systemMessage); } // 使用示例 broadcastSystemMessage(\u0026#34;系统将在10分钟后进行维护\u0026#34;, \u0026#34;MAINTENANCE\u0026#34;); broadcastSystemMessage(\u0026#34;系统配置已更新，请重新加载\u0026#34;, \u0026#34;CONFIG_UPDATE\u0026#34;); 应用场景：\n系统公告：向所有服务广播系统维护、更新通知 配置更新：当系统配置变更时，通知所有相关服务刷新配置 缓存失效：当数据发生变化时，通知所有缓存服务清除相关缓存 Headers Exchange Headers Exchange 是一种根据消息头的属性将消息转发到一个或多个 Queue 的交换机类型，它不使用路由键进行匹配，而是根据消息的头部属性进行匹配。\n实际应用：适用于需要根据多个条件进行路由的场景，特别是当路由条件不适合用字符串表示时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // Headers Exchange配置示例 @Configuration public class HeadersExchangeConfig { @Bean public HeadersExchange documentExchange() { return new HeadersExchange(\u0026#34;document.headers\u0026#34;); } @Bean public Queue pdfProcessQueue() { return new Queue(\u0026#34;document.process.pdf\u0026#34;); } @Bean public Queue imageProcessQueue() { return new Queue(\u0026#34;document.process.image\u0026#34;); } @Bean public Queue highPriorityQueue() { return new Queue(\u0026#34;document.priority.high\u0026#34;); } @Bean public Binding pdfBinding(Queue pdfProcessQueue, HeadersExchange documentExchange) { return BindingBuilder.bind(pdfProcessQueue).to(documentExchange) .where(\u0026#34;format\u0026#34;).matches(\u0026#34;pdf\u0026#34;); } @Bean public Binding imageBinding(Queue imageProcessQueue, HeadersExchange documentExchange) { return BindingBuilder.bind(imageProcessQueue).to(documentExchange) .where(\u0026#34;format\u0026#34;).matches(\u0026#34;jpg\u0026#34;).or(\u0026#34;format\u0026#34;).matches(\u0026#34;png\u0026#34;); } @Bean public Binding highPriorityBinding(Queue highPriorityQueue, HeadersExchange documentExchange) { // 使用whereAll要求所有条件都匹配 return BindingBuilder.bind(highPriorityQueue).to(documentExchange) .whereAll(Map.of( \u0026#34;priority\u0026#34;, \u0026#34;high\u0026#34;, \u0026#34;type\u0026#34;, \u0026#34;document\u0026#34; )).match(); } } // 生产者：发送带头部属性的消息 public void sendDocument(byte[] content, String format, String priority) { MessageProperties properties = new MessageProperties(); properties.setHeader(\u0026#34;format\u0026#34;, format); properties.setHeader(\u0026#34;priority\u0026#34;, priority); properties.setHeader(\u0026#34;type\u0026#34;, \u0026#34;document\u0026#34;); Message message = new Message(content, properties); rabbitTemplate.send(\u0026#34;document.headers\u0026#34;, \u0026#34;\u0026#34;, message); } // 使用示例 sendDocument(pdfContent, \u0026#34;pdf\u0026#34;, \u0026#34;high\u0026#34;); sendDocument(imageContent, \u0026#34;jpg\u0026#34;, \u0026#34;normal\u0026#34;); 应用场景：\n文档处理：根据文档类型、格式、大小等属性路由到不同的处理队列 多条件路由：需要根据多个条件进行路由，且这些条件不适合用路由键表示 特殊消息处理：根据消息的特殊属性（如优先级、安全级别）进行路由 Headers Exchange vs Topic Exchange：\nHeaders Exchange 基于消息头属性匹配，可以使用多个条件，不限于字符串格式 Topic Exchange 基于路由键匹配，使用字符串模式匹配，支持通配符 当路由条件可以用字符串表示时，Topic Exchange 通常更简单高效 当需要基于多个非字符串属性或复杂条件路由时，Headers Exchange 更灵活 交换机类型选择指南 交换机类型 适用场景 优势 示例应用 Direct 精确路由，一对一或一对多 简单高效，路由明确 日志路由、任务分发 Topic 基于模式的路由，多维度分类 灵活的模式匹配，支持通配符 多区域通知、事件分发 Fanout 广播消息，一对所有 最高效的消息分发，不需要路由计算 系统公告、缓存刷新 Headers 基于属性的复杂路由 支持多条件匹配，不限于字符串 文档处理、多条件筛选 RabbitMQ 高级特性 死信队列（Dead Letter Queue） 死信队列用于处理无法被正常消费的消息。当消息被拒绝（reject/nack）且不重新入队、消息过期（TTL）或队列达到最大长度时，消息会被发送到死信队列。\n实际应用：在订单处理系统中，如果订单消息处理失败达到最大重试次数，可以将其发送到死信队列进行特殊处理或人工干预。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 // 死信队列配置 @Configuration public class DeadLetterConfig { // 死信交换机 @Bean public DirectExchange deadLetterExchange() { return new DirectExchange(\u0026#34;order.dead.letter.exchange\u0026#34;); } // 死信队列 @Bean public Queue deadLetterQueue() { return new Queue(\u0026#34;order.dead.letter.queue\u0026#34;); } // 绑定死信队列到死信交换机 @Bean public Binding deadLetterBinding() { return BindingBuilder.bind(deadLetterQueue()) .to(deadLetterExchange()) .with(\u0026#34;order.dead.letter\u0026#34;); } // 业务队列，配置死信交换机 @Bean public Queue orderProcessQueue() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); // 设置死信交换机 args.put(\u0026#34;x-dead-letter-exchange\u0026#34;, \u0026#34;order.dead.letter.exchange\u0026#34;); // 设置死信路由键 args.put(\u0026#34;x-dead-letter-routing-key\u0026#34;, \u0026#34;order.dead.letter\u0026#34;); // 设置消息过期时间（毫秒） args.put(\u0026#34;x-message-ttl\u0026#34;, 60000); // 1分钟 return new Queue(\u0026#34;order.process.queue\u0026#34;, true, false, false, args); } } // 死信队列消费者 @Component public class DeadLetterConsumer { @Autowired private OrderService orderService; @RabbitListener(queues = \u0026#34;order.dead.letter.queue\u0026#34;) public void processDeadLetter(Message message) { try { // 解析消息 OrderMessage orderMessage = objectMapper.readValue(message.getBody(), OrderMessage.class); // 记录死信消息 log.error(\u0026#34;订单处理失败，进入死信队列: {}\u0026#34;, orderMessage.getOrderId()); // 发送告警通知 alertService.sendAlert(\u0026#34;订单处理失败\u0026#34;, \u0026#34;订单ID: \u0026#34; + orderMessage.getOrderId()); // 尝试特殊处理 orderService.handleFailedOrder(orderMessage.getOrderId()); } catch (Exception e) { log.error(\u0026#34;处理死信消息失败\u0026#34;, e); } } } 延迟队列（Delayed Message） 延迟队列用于实现消息的延迟投递，常用于定时任务、延迟处理等场景。\n实际应用：在电商系统中，订单创建后如果30分钟内未支付，需要自动取消并恢复库存。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // 延迟队列配置（需要安装rabbitmq_delayed_message_exchange插件） @Configuration public class DelayedConfig { @Bean public CustomExchange delayedExchange() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;x-delayed-type\u0026#34;, \u0026#34;direct\u0026#34;); return new CustomExchange(\u0026#34;order.delayed.exchange\u0026#34;, \u0026#34;x-delayed-message\u0026#34;, true, false, args); } @Bean public Queue orderTimeoutQueue() { return new Queue(\u0026#34;order.timeout.queue\u0026#34;); } @Bean public Binding orderTimeoutBinding() { return BindingBuilder.bind(orderTimeoutQueue()) .to(delayedExchange()) .with(\u0026#34;order.timeout\u0026#34;) .noargs(); } } // 发送延迟消息 public void createOrder(Order order) { // 保存订单 orderRepository.save(order); // 发送延迟消息，30分钟后检查订单状态 OrderTimeoutMessage message = new OrderTimeoutMessage(order.getId()); MessageProperties properties = new MessageProperties(); // 设置延迟时间（毫秒） properties.setHeader(\u0026#34;x-delay\u0026#34;, 30 * 60 * 1000); // 30分钟 Message amqpMessage = new Message(objectMapper.writeValueAsBytes(message), properties); rabbitTemplate.send(\u0026#34;order.delayed.exchange\u0026#34;, \u0026#34;order.timeout\u0026#34;, amqpMessage); } // 延迟消息消费者 @Component public class OrderTimeoutConsumer { @Autowired private OrderService orderService; @RabbitListener(queues = \u0026#34;order.timeout.queue\u0026#34;) public void processOrderTimeout(OrderTimeoutMessage message) { String orderId = message.getOrderId(); // 检查订单状态 Order order = orderService.getOrder(orderId); if (order != null \u0026amp;\u0026amp; \u0026#34;UNPAID\u0026#34;.equals(order.getStatus())) { // 订单未支付，执行取消操作 orderService.cancelOrder(orderId); log.info(\u0026#34;订单{}超时未支付，已自动取消\u0026#34;, orderId); } } } 优先级队列（Priority Queue） 优先级队列允许根据消息的优先级决定消费顺序，优先级高的消息会被优先消费。\n实际应用：在客服系统中，VIP客户的服务请求应该优先处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 优先级队列配置 @Bean public Queue supportQueue() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;x-max-priority\u0026#34;, 10); // 设置最大优先级为10 return new Queue(\u0026#34;support.queue\u0026#34;, true, false, false, args); } // 发送带优先级的消息 public void createSupportTicket(Ticket ticket) { // 保存工单 ticketRepository.save(ticket); // 根据客户等级设置优先级 int priority = switch (ticket.getCustomerLevel()) { case \u0026#34;VIP\u0026#34; -\u0026gt; 10; case \u0026#34;GOLD\u0026#34; -\u0026gt; 8; case \u0026#34;SILVER\u0026#34; -\u0026gt; 5; default -\u0026gt; 1; }; // 发送消息 MessageProperties properties = new MessageProperties(); properties.setPriority(priority); Message message = new Message(objectMapper.writeValueAsBytes(ticket), properties); rabbitTemplate.send(\u0026#34;support.exchange\u0026#34;, \u0026#34;support.ticket\u0026#34;, message); } RabbitMQ 最佳实践 生产者最佳实践 确认机制：始终使用发布确认（Publisher Confirms）机制确保消息成功发送到RabbitMQ服务器。\n消息持久化：对于重要业务，确保交换机、队列和消息都设置为持久化（durable）。\n消息序列化：使用高效的序列化方式（如JSON、Protocol Buffers）并处理好序列化异常。\n重试机制：实现消息发送失败的重试策略，可以使用指数退避算法。\n批量发送：在高吞吐量场景下，考虑批量发送消息以提高性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 生产者最佳实践示例 @Service public class BestPracticeProducer { @Autowired private RabbitTemplate rabbitTemplate; @Autowired private RetryTemplate retryTemplate; public void sendWithBestPractice(Object message, String exchange, String routingKey) { // 使用重试模板 retryTemplate.execute(context -\u0026gt; { // 创建CorrelationData用于确认回调 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 设置确认回调 correlationData.getFuture().addCallback( confirm -\u0026gt; { if (confirm.isAck()) { log.info(\u0026#34;消息已确认: {}\u0026#34;, correlationData.getId()); } else { log.error(\u0026#34;消息未确认: {}, 原因: {}\u0026#34;, correlationData.getId(), confirm.getReason()); // 可以将未确认的消息保存到数据库，后续重试 } }, ex -\u0026gt; log.error(\u0026#34;消息确认异常\u0026#34;, ex) ); // 发送消息 rabbitTemplate.convertAndSend(exchange, routingKey, message, correlationData); return null; }); } } 消费者最佳实践 手动确认：对于重要业务，使用手动确认模式，确保消息处理成功后再确认。\n幂等性处理：实现消费者的幂等性，确保重复消费不会导致业务问题。\n并发控制：根据业务特性和硬件资源合理设置消费者的并发数。\n异常处理：妥善处理消费过程中的异常，决定是拒绝还是重新入队。\n预取数量：合理设置prefetch count，避免单个消费者负载过重。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // 消费者最佳实践示例 @Component public class BestPracticeConsumer { @Autowired private ProcessRecordRepository recordRepository; @RabbitListener(queues = \u0026#34;best.practice.queue\u0026#34;, ackMode = \u0026#34;MANUAL\u0026#34;, concurrency = \u0026#34;5-10\u0026#34;) public void consume(Message message, Channel channel) throws IOException { long deliveryTag = message.getMessageProperties().getDeliveryTag(); String messageId = message.getMessageProperties().getMessageId(); try { // 检查是否已处理（幂等性检查） if (recordRepository.existsByMessageId(messageId)) { log.info(\u0026#34;消息已处理，跳过: {}\u0026#34;, messageId); channel.basicAck(deliveryTag, false); return; } // 处理消息 Object payload = objectMapper.readValue(message.getBody(), TargetType.class); processMessage(payload); // 记录处理状态 recordRepository.save(new ProcessRecord(messageId, \u0026#34;SUCCESS\u0026#34;)); // 确认消息 channel.basicAck(deliveryTag, false); } catch (Exception e) { log.error(\u0026#34;处理消息失败: {}\u0026#34;, messageId, e); // 判断是否需要重试 if (isRetryable(e)) { // 拒绝消息并重新入队 channel.basicNack(deliveryTag, false, true); } else { // 拒绝消息不重新入队，进入死信队列 channel.basicNack(deliveryTag, false, false); // 记录失败状态 recordRepository.save(new ProcessRecord(messageId, \u0026#34;FAILED\u0026#34;, e.getMessage())); } } } private boolean isRetryable(Exception e) { // 判断异常是否可重试 return e instanceof TemporaryException || e instanceof IOException; } } 监控和运维最佳实践 健康检查：定期检查RabbitMQ集群的健康状态，包括节点状态、队列长度等。\n告警机制：设置关键指标的告警阈值，如队列长度、消息积压、消费者数量等。\n日志记录：记录关键操作和异常情况，便于问题排查。\n资源隔离：为不同业务系统使用不同的vhost，实现资源隔离。\n容量规划：根据业务增长预测，提前规划RabbitMQ集群的容量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // 监控示例 @Component public class RabbitMQMonitor { @Autowired private RabbitTemplate rabbitTemplate; @Scheduled(fixedRate = 60000) // 每分钟执行一次 public void monitorQueueStatus() { // 获取队列信息 Queue queue = rabbitTemplate.execute(channel -\u0026gt; { try { return channel.queueDeclarePassive(\u0026#34;important.queue\u0026#34;); } catch (IOException e) { log.error(\u0026#34;获取队列信息失败\u0026#34;, e); return null; } }); if (queue != null) { int messageCount = queue.getMessageCount(); int consumerCount = queue.getConsumerCount(); log.info(\u0026#34;队列状态 - 消息数: {}, 消费者数: {}\u0026#34;, messageCount, consumerCount); // 检查队列积压 if (messageCount \u0026gt; 1000 \u0026amp;\u0026amp; consumerCount \u0026lt; 5) { log.warn(\u0026#34;队列积压告警 - 消息数: {}, 消费者数: {}\u0026#34;, messageCount, consumerCount); alertService.sendAlert(\u0026#34;队列积压\u0026#34;, \u0026#34;important.queue队列积压，消息数: \u0026#34; + messageCount); } } } } 总结 RabbitMQ作为一个成熟的消息队列中间件，在分布式系统中扮演着重要角色。通过合理使用其交换机类型、队列特性和消息属性，可以构建高效、可靠的消息传递系统。在实际应用中，需要根据业务场景选择合适的消息模型，并遵循最佳实践，确保系统的稳定性和可靠性。\n对于不同的业务场景，RabbitMQ提供了灵活的解决方案：\n异步处理：通过消息队列实现系统解耦，提高响应速度 流量削峰：在高并发场景下缓冲请求，平滑处理峰值流量 可靠通信：通过消息持久化、确认机制等保证消息不丢失 灵活路由：利用不同类型的交换机实现复杂的消息路由逻辑 延时处理：使用延迟队列实现定时任务和延迟处理 在使用RabbitMQ时，应当注意消息的可靠性、幂等性处理、性能优化和监控运维等方面，确保消息队列在系统中发挥最大价值。\n","date":"2024-01-10T13:41:18+08:00","permalink":"https://hollisho.github.io/p/rabbitmq%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/","title":"Rabbitmq知识整理"},{"content":"Kafka 简介 Kafka 是一个分布式的流处理平台，最初由 LinkedIn 开发，后来成为 Apache 项目。它具有高吞吐量、可靠性和可扩展性的特点，被广泛应用于日志收集、消息系统、活动追踪、流式处理等场景。\n应用场景 日志聚合：收集分布式系统中的日志数据，集中存储以便分析和监控\n案例：电商平台将用户行为日志（浏览、点击、购买）通过Kafka收集，用于实时分析用户行为和个性化推荐 消息队列：解耦系统组件，提高系统弹性和可扩展性\n案例：订单系统将新订单发送到Kafka，库存系统、支付系统、物流系统各自消费消息进行处理 流处理：实时处理和转换数据流\n案例：金融机构使用Kafka Streams处理交易数据流，实时检测欺诈行为 事件溯源：记录状态变更事件，用于系统重建和审计\n案例：银行系统记录账户所有操作事件，用于账户状态重建和合规审计 指标监控：收集系统和应用指标，用于监控和告警\n案例：云服务提供商收集基础设施指标，实时监控系统健康状态 Kafka 架构设计 Kafka 的核心架构包含以下几个关键组件：\nBroker Broker 是 Kafka 集群中的服务器节点，负责接收和处理客户端请求，存储消息数据。每个 Broker 都有一个唯一的 ID，可以独立运行。\n应用案例：大型电商平台通常部署多个Broker节点组成集群，每个节点可能处理不同类型的消息流量。例如，用户行为数据可能分配到特定的Broker组，而订单处理数据分配到另一组Broker，以实现负载均衡和资源隔离。\nProducer Producer 是消息生产者，负责将消息发送到 Kafka 集群中的特定 Topic。Producer 可以选择同步或异步的方式发送消息。\n代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 创建Producer配置 Properties props = new Properties(); props.put(\u0026#34;bootstrap.servers\u0026#34;, \u0026#34;kafka1:9092,kafka2:9092\u0026#34;); props.put(\u0026#34;key.serializer\u0026#34;, \u0026#34;org.apache.kafka.common.serialization.StringSerializer\u0026#34;); props.put(\u0026#34;value.serializer\u0026#34;, \u0026#34;org.apache.kafka.common.serialization.StringSerializer\u0026#34;); // 创建Producer实例 KafkaProducer\u0026lt;String, String\u0026gt; producer = new KafkaProducer\u0026lt;\u0026gt;(props); // 发送消息 ProducerRecord\u0026lt;String, String\u0026gt; record = new ProducerRecord\u0026lt;\u0026gt;(\u0026#34;order-topic\u0026#34;, orderId, orderJson); producer.send(record, (metadata, exception) -\u0026gt; { if (exception == null) { System.out.println(\u0026#34;消息发送成功: \u0026#34; + metadata.offset()); } else { exception.printStackTrace(); } }); // 关闭Producer producer.close(); 应用场景：在微服务架构中，订单服务作为Producer，将新创建的订单信息发送到Kafka，实现与库存服务、支付服务等的解耦。\nConsumer Consumer 是消息消费者，负责从 Kafka 集群中订阅并消费消息。Consumer 可以单独消费，也可以组成 Consumer Group 共同消费。\n代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 创建Consumer配置 Properties props = new Properties(); props.put(\u0026#34;bootstrap.servers\u0026#34;, \u0026#34;kafka1:9092,kafka2:9092\u0026#34;); props.put(\u0026#34;group.id\u0026#34;, \u0026#34;inventory-service\u0026#34;); props.put(\u0026#34;key.deserializer\u0026#34;, \u0026#34;org.apache.kafka.common.serialization.StringDeserializer\u0026#34;); props.put(\u0026#34;value.deserializer\u0026#34;, \u0026#34;org.apache.kafka.common.serialization.StringDeserializer\u0026#34;); props.put(\u0026#34;auto.offset.reset\u0026#34;, \u0026#34;earliest\u0026#34;); // 创建Consumer实例 KafkaConsumer\u0026lt;String, String\u0026gt; consumer = new KafkaConsumer\u0026lt;\u0026gt;(props); // 订阅Topic consumer.subscribe(Arrays.asList(\u0026#34;order-topic\u0026#34;)); // 消费消息 while (true) { ConsumerRecords\u0026lt;String, String\u0026gt; records = consumer.poll(Duration.ofMillis(100)); for (ConsumerRecord\u0026lt;String, String\u0026gt; record : records) { System.out.println(\u0026#34;收到订单: \u0026#34; + record.key() + \u0026#34;, 内容: \u0026#34; + record.value()); // 处理订单逻辑 processOrder(record.value()); } // 手动提交偏移量 consumer.commitSync(); } 应用场景：库存服务作为Consumer，消费订单Topic中的消息，实时更新库存数量。多个库存服务实例可以组成Consumer Group，每个实例处理部分分区的消息，实现负载均衡。\nTopic Topic 是消息的逻辑分类，每个 Topic 可以有多个 Partition。Producer 发送消息到特定的 Topic，Consumer 从特定的 Topic 消费消息。\n应用案例：电商平台可能设置多个不同的Topic：\nuser-events：用户行为事件（浏览、搜索、收藏） orders：订单相关事件 inventory-changes：库存变更事件 payment-events：支付相关事件 这种分类使得不同的业务系统可以只关注与自己相关的消息流。\nPartition Partition 是 Topic 的物理分区，每个 Partition 是一个有序的、不可变的消息序列。Partition 的引入使得 Kafka 可以实现水平扩展和并行处理。\n设计考量：\n分区数量决定了Topic的并行度，通常应该至少等于预期的Consumer数量 实际案例：高流量电商平台的订单Topic可能配置32个分区，允许最多32个消费者实例并行处理订单 Segment Segment 是 Partition 的物理存储单元，每个 Partition 由多个 Segment 组成。当 Segment 达到一定大小（默认1GB）或时间阈值时，会创建新的 Segment。\n性能影响：Segment大小设置会影响：\n文件管理效率：较大的Segment减少文件数量 数据清理效率：较小的Segment使过期数据清理更精确 实际案例：日志系统可能使用较小的Segment（如256MB）以便及时清理过期日志 Log Log 是 Kafka 中最基本的数据存储单元，每个 Partition 对应一个 Log，Log 由多个 Segment 文件组成。\n存储结构：\n1 2 3 4 5 6 7 8 9 10 /kafka-logs/ ├── topic1-0/ # topic1的第0个分区 │ ├── 00000000000000000000.log # 数据文件 │ ├── 00000000000000000000.index # 索引文件 │ ├── 00000000000000367104.log # 下一个segment │ └── 00000000000000367104.index ├── topic1-1/ # topic1的第1个分区 │ └── ... └── topic2-0/ # topic2的第0个分区 └── ... ZooKeeper ZooKeeper 用于管理和协调 Kafka 集群，存储元数据信息，如 Broker 节点、Topic 配置、消费者偏移量等。（注：新版本 Kafka 正在逐步减少对 ZooKeeper 的依赖，Kafka 2.8.0引入了KRaft模式，可以完全不依赖ZooKeeper）\nZooKeeper存储的关键信息：\n/brokers/ids/[broker-id]：Broker节点信息 /brokers/topics/[topic]/partitions/[partition]/state：分区状态 /consumers/[group_id]/offsets/[topic]/[partition]：消费者偏移量（旧版本） Kafka 副本同步方式 Kafka 提供了三种不同的副本同步方式，通过 acks 参数控制：\n1. ack=0 (半同步复制) Producer 发送消息后不等待任何确认 最高的吞吐量，但无法保证消息已被接收 可能导致消息丢失 适用于对数据一致性要求不高的场景，如日志收集 2. ack=1 (异步复制) Producer 发送消息后，等待 Leader 副本确认 不等待 Follower 副本同步完成 在 Leader 崩溃时可能丢失数据 吞吐量和可靠性的折中方案 3. ack=all/-1 (同步复制) Producer 发送消息后，等待所有 ISR 中的副本确认 最高的可靠性，但吞吐量最低 只要有一个 ISR 中的副本存活，就不会丢失数据 适用于对数据一致性要求高的场景，如金融交易 ISR 机制 (In-Sync Replicas) ISR 是与 Leader 保持同步的副本集合 AR (Assigned Replicas) = ISR (In-Sync Replicas) + OSR (Out-of-Sync Replicas) 副本滞后超过 replica.lag.time.max.ms 会被踢出 ISR 当副本重新追上 Leader 时，会被重新加入 ISR ISR 机制是 Kafka 实现高可用和数据一致性的核心 Kafka 消息发送流程 Producer 创建 ProducerRecord，指定 Topic 和消息内容 消息经过序列化器、分区器处理 分区器根据 Key 或轮询方式选择目标 Partition 消息被添加到内存中的批次 (Batch) Sender 线程定期将批次发送到对应的 Broker Broker 接收消息并写入对应 Partition 的 Leader 副本 根据 acks 配置，等待副本同步完成 返回响应给 Producer Kafka 消息存储流程 Broker 接收到消息后，将其追加到对应 Partition 的当前活跃 Segment 中 消息以追加写的方式写入磁盘，提高写入效率 消息按照 Offset 顺序存储，每条消息有唯一的 Offset 当 Segment 达到配置的大小或时间阈值，创建新的 Segment 旧的 Segment 会在配置的保留时间后被删除或压缩 Kafka 使用页缓存和零拷贝技术优化 I/O 性能 Kafka 消息消费流程 Consumer 向 Coordinator 发送 JoinGroup 请求加入消费组 Coordinator 选择一个 Consumer 作为 Leader，进行分区分配 分配结果通过 SyncGroup 请求同步给所有 Consumer Consumer 向对应的 Broker 发送 Fetch 请求获取消息 Broker 返回消息给 Consumer Consumer 处理消息并定期提交消费位移 (Offset) 位移提交可以是自动的或手动的，保存在内部 Topic __consumer_offsets 中 主从同步 Kafka 的主从同步基于 Leader-Follower 模型：\n每个 Partition 有一个 Leader 和多个 Follower 所有读写请求都由 Leader 处理 Follower 通过 Fetch 请求从 Leader 拉取消息 HW (High Watermark) 表示所有 ISR 副本都已复制的位置 LEO (Log End Offset) 表示每个副本的日志末端位置 消费者只能消费到 HW 位置的消息，保证数据一致性 当 Leader 失效时，从 ISR 中选举新的 Leader 高可用 Kafka 通过以下机制实现高可用：\n多副本机制：每个 Partition 可以配置多个副本，分布在不同的 Broker 上 Leader 选举：当 Leader 失效时，Controller 会从 ISR 中选择一个 Follower 成为新的 Leader Controller 选举：集群中的一个 Broker 会被选为 Controller，负责分区分配和故障转移 Rebalance 机制：当 Consumer 加入或离开消费组时，会触发 Rebalance，重新分配分区 自动平衡：Kafka 支持自动平衡 Leader 分区，避免单个 Broker 负载过高 消息顺序 Kafka 对消息顺序的保证：\n单个 Partition 内的消息是有序的 不同 Partition 之间的消息无法保证顺序 如果需要全局顺序，可以使用只有一个 Partition 的 Topic 如果需要按 Key 顺序，可以确保相同 Key 的消息路由到同一个 Partition 消息重复 消息重复的原因和处理：\n原因：网络问题、Broker 崩溃、Consumer 崩溃等导致重试或重新消费 Producer 端：启用幂等性 (enable.idempotence=true) 和事务功能 Consumer 端：实现幂等消费，如使用唯一标识、状态检查、分布式锁等 最佳实践：设计业务逻辑时考虑幂等性，确保多次处理同一消息不会产生副作用 消息丢失 消息丢失的场景和防止措施：\nProducer 端：\n使用 acks=all 确保所有 ISR 副本都收到消息 启用重试机制 (retries 参数) 使用回调机制确认消息发送结果 Broker 端：\n配置足够的副本数 (replication.factor\u0026gt;=3) 配置最小 ISR 数量 (min.insync.replicas\u0026gt;=2) 合理配置刷盘策略 (log.flush.* 参数) Consumer 端：\n手动提交位移，确保消息处理成功后再提交 使用事务确保消息处理和位移提交的原子性 避免长时间处理单条消息，防止会话超时 消息积压 消息积压的原因和解决方案：\n原因：\nConsumer 处理能力不足 突发流量高峰 Consumer 异常或宕机 网络问题 解决方案：\n增加 Consumer 实例和 Partition 数量 优化 Consumer 处理逻辑，提高处理效率 实现背压机制，控制生产速度 使用更高性能的硬件 临时将消息转储到其他存储，离线处理 消息延迟 Kafka 中的延迟消息实现：\nKafka 原生不支持延迟消息，但可以通过以下方式实现： 使用定时任务扫描特定 Topic 使用时间轮算法在应用层实现 创建多个 Topic 代表不同的延迟级别 使用外部组件如 Apache Pulsar 或 RocketMQ 的延迟功能 零拷贝 Kafka 使用零拷贝技术提高性能：\n传统 I/O 模型：数据在磁盘、内核空间、用户空间和网络之间多次拷贝 零拷贝技术：利用 sendfile() 系统调用，直接从磁盘到网络接口传输数据 优势： 减少数据拷贝次数 减少上下文切换 降低 CPU 使用率 提高吞吐量 应用场景：Kafka 的日志文件传输、Consumer 消费消息 Kafka 调优 Broker 调优 合理设置 num.network.threads 和 num.io.threads 优化 JVM 参数，如堆大小、GC 策略 配置适当的 log.retention.hours 和 log.segment.bytes 使用 RAID 10 磁盘阵列提高 I/O 性能 Producer 调优 增大 batch.size 和 linger.ms 提高批量发送效率 配置合适的 buffer.memory 避免内存溢出 根据场景选择合适的 compression.type 调整 max.in.flight.requests.per.connection 平衡吞吐量和顺序性 Consumer 调优 合理设置 fetch.min.bytes 和 fetch.max.wait.ms 优化 max.poll.records 控制单次拉取的消息数量 调整 max.poll.interval.ms 避免消费者被踢出消费组 实现并行处理提高消费效率 Kafka 存储结构详解 Kafka 的存储结构是其高性能的关键因素之一，它采用了分层的存储设计，从上到下依次为：Topic、Partition、Segment、Index 和 Log。\nTopic 与 Partition Topic 是消息的逻辑分类，而 Partition 是 Topic 的物理分区。每个 Topic 可以有多个 Partition，这些 Partition 分布在不同的 Broker 上，实现了数据的分布式存储和并行处理。\nPartition 的数量决定了 Topic 的并行度，增加 Partition 数量可以提高吞吐量，但也会增加系统开销和复杂性。Partition 的数量一旦设定，通常不建议减少，因为这可能导致数据丢失。\nSegment 文件 每个 Partition 由多个 Segment 文件组成，Segment 是 Kafka 存储的基本单位。当 Segment 达到一定大小（默认 1GB）或时间阈值时，会创建新的 Segment。\nSegment 文件命名规则为：[baseOffset].[index|log|timeindex]，其中 baseOffset 是该 Segment 中第一条消息的 Offset。\n每个 Segment 包含以下文件：\n.log 文件：存储实际的消息数据 .index 文件：存储消息的物理位置索引 .timeindex 文件：存储时间戳索引（Kafka 0.10.0 版本后引入） 索引机制 Kafka 使用稀疏索引来提高查找效率。索引文件中并不是每条消息都有索引项，而是每隔一定字节数（默认 4KB）的消息才会创建一个索引项。\n索引项包含两个部分：\n相对 Offset：消息的 Offset 相对于 Segment 基准 Offset 的值 物理位置：消息在 .log 文件中的物理位置（字节偏移量） 当需要查找特定 Offset 的消息时，Kafka 首先找到该 Offset 所在的 Segment，然后在索引文件中找到小于等于目标 Offset 的最大索引项，从该位置开始顺序扫描 .log 文件，直到找到目标消息。\n日志清理 Kafka 提供了两种日志清理策略：\n基于时间的删除：通过 log.retention.hours 配置，删除超过保留时间的旧 Segment 基于大小的删除：通过 log.retention.bytes 配置，当 Partition 大小超过阈值时，删除最旧的 Segment 日志压缩：通过 log.cleanup.policy=compact 配置，保留每个 Key 的最新值，删除旧值 日志压缩特别适用于需要保留最新状态的场景，如配置更新、状态变更等。\n文件系统与页缓存 Kafka 直接使用文件系统存储数据，而不是使用数据库。它充分利用操作系统的页缓存（Page Cache）来提高 I/O 性能：\n写入操作：追加写入文件系统，由操作系统负责刷盘 读取操作：优先从页缓存读取，命中率高时可以避免磁盘 I/O 这种设计使得 Kafka 在处理大量数据时仍能保持高性能，同时简化了系统架构。\n存储格式 Kafka 消息的存储格式经过精心设计，包含以下字段：\n8 字节 Offset 4 字节消息大小 4 字节 CRC32 校验和 1 字节魔数（Magic Byte） 1 字节属性（压缩类型等） 4 字节 Key 长度（-1 表示没有 Key） Key 数据（如果存在） 4 字节 Value 长度 Value 数据（实际消息内容） 这种格式设计既保证了数据完整性，又兼顾了存储效率。\n批量写入与压缩 Kafka 支持消息批量写入和压缩，以提高存储效率和网络传输效率：\n批量写入：多条消息组成一个批次（Batch），一次性写入磁盘 压缩：支持 GZIP、Snappy、LZ4、ZStandard 等压缩算法 端到端压缩：Producer 压缩，Broker 保持压缩状态存储，Consumer 解压 压缩率取决于消息内容的特性，对于文本类数据，通常可以达到 3-5 倍的压缩比。\n存储优化最佳实践 合理设置 Partition 数量：\n考虑并行度需求和资源限制 一般建议每个 Broker 的 Partition 数不超过 2000-4000 优化磁盘配置：\n使用 SSD 提高随机读写性能 使用 RAID 10 而非 RAID 5/6 分离操作系统和数据目录 调整 Segment 大小：\n较小的 Segment 有利于及时清理过期数据 较大的 Segment 减少文件数量，降低管理开销 合理配置保留策略：\n根据业务需求设置 log.retention.hours 和 log.retention.bytes 对不同 Topic 设置不同的保留策略 监控磁盘使用率：\n保持足够的磁盘空间（至少 20% 空闲） 设置磁盘使用率告警 总结 Kafka 作为一个高性能、分布式的流处理平台，通过精心设计的架构和机制，实现了高吞吐量、可靠性和可扩展性。理解 Kafka 的核心概念和工作原理，对于构建高效、可靠的消息系统至关重要。\n","date":"2024-01-10T11:34:49+08:00","permalink":"https://hollisho.github.io/p/kafka%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/","title":"Kafka知识整理"}]